{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.bmm(adj, input)\n",
    "        output = torch.matmul(support, self.weight)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, input, adj):\n",
    "        x = F.relu(self.gc1(input, adj))\n",
    "        x = F.dropout(x, self.dropout, training = self.training)\n",
    "        x = F.relu(self.gc2(x, adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "torch.manual_seed(5)\n",
    "if device is not \"cpu\":\n",
    "    torch.cuda.manual_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_BA_dataset(N,n,m=2):\n",
    "    adj = np.empty((N,n,n), dtype=np.float32)\n",
    "    for j in range(N):\n",
    "        g = nx.barabasi_albert_graph(n=n,m=m)\n",
    "        a = np.zeros((n,n), dtype=np.float32)\n",
    "        for i in g.edges:\n",
    "            a[i] = 1\n",
    "            a[i[::-1]] = 1\n",
    "        adj[j] = a\n",
    "    return adj\n",
    "\n",
    "def make_ER_dataset(N,n,p=0.1):\n",
    "    adj = np.empty((N,n,n), dtype=np.float32)\n",
    "    for j in range(N):\n",
    "        g = nx.erdos_renyi_graph(n=n, p=p)\n",
    "        a = np.zeros((n,n), dtype=np.float32)\n",
    "        for i in g.edges:\n",
    "            a[i] = 1\n",
    "            a[i[::-1]] = 1\n",
    "        adj[j] = a\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, units, out_features):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, units)\n",
    "        self.fc2 = nn.Linear(units, out_features)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.fc1(input.view(input.size(0), -1)))\n",
    "        outputs = self.fc2(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, y):\n",
    "        model.train()\n",
    "        yhat = model(x)       \n",
    "        loss = loss_fn(y, yhat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(x, y, batch_size, ratio_train):\n",
    "    x_tensor = torch.from_numpy(x).float()\n",
    "    y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "    dataset = TensorDataset(x_tensor, y_tensor)\n",
    "    vallength = int(ratio_train*x.shape[0])\n",
    "    trainlength = x.shape[0] - vallength\n",
    "    \n",
    "    train_dataset, val_dataset = random_split(dataset, [trainlength, vallength])\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size = trainlength)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size = vallength)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train_step, n_epochs, train_loader, val_loader):\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        batch_losses = []\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            loss = train_step(x_batch, y_batch)\n",
    "            batch_losses.append(loss)\n",
    "        training_loss = np.mean(batch_losses)\n",
    "        training_losses.append(training_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val = x_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                model.eval()           \n",
    "                yhat = model(x_val)\n",
    "                val_loss = loss_fn(y_val, yhat).item()\n",
    "                val_losses.append(val_loss)\n",
    "            validation_loss = np.mean(val_losses)\n",
    "            validation_losses.append(validation_loss)\n",
    "\n",
    "        print(f\"[{epoch+1}] Training loss: {training_loss:.3f}\\t Validation loss: {validation_loss:.3f}\")\n",
    "    return training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 Samples\n",
      "\n",
      "3684 Samples\n",
      "\n",
      "1357 Samples\n",
      "\n",
      "499 Samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for n_samples in np.int0(np.logspace(np.log10(5e2), np.log10(1e4), 4))[::-1]:\n",
    "#     print('%d Samples\\n' % n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5e+02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4e03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 Samples\n",
      "\n",
      "[1] Training loss: 5.487\t Validation loss: 5.309\n",
      "[2] Training loss: 5.296\t Validation loss: 5.078\n",
      "[3] Training loss: 5.064\t Validation loss: 4.830\n",
      "[4] Training loss: 4.814\t Validation loss: 4.581\n",
      "[5] Training loss: 4.564\t Validation loss: 4.342\n",
      "[6] Training loss: 4.323\t Validation loss: 4.113\n",
      "[7] Training loss: 4.092\t Validation loss: 3.887\n",
      "[8] Training loss: 3.865\t Validation loss: 3.661\n",
      "[9] Training loss: 3.637\t Validation loss: 3.433\n",
      "[10] Training loss: 3.409\t Validation loss: 3.208\n",
      "[11] Training loss: 3.184\t Validation loss: 2.994\n",
      "[12] Training loss: 2.970\t Validation loss: 2.795\n",
      "[13] Training loss: 2.772\t Validation loss: 2.612\n",
      "[14] Training loss: 2.590\t Validation loss: 2.445\n",
      "[15] Training loss: 2.424\t Validation loss: 2.292\n",
      "[16] Training loss: 2.273\t Validation loss: 2.157\n",
      "[17] Training loss: 2.139\t Validation loss: 2.039\n",
      "[18] Training loss: 2.023\t Validation loss: 1.939\n",
      "[19] Training loss: 1.925\t Validation loss: 1.852\n",
      "[20] Training loss: 1.839\t Validation loss: 1.774\n",
      "[21] Training loss: 1.762\t Validation loss: 1.703\n",
      "[22] Training loss: 1.692\t Validation loss: 1.640\n",
      "[23] Training loss: 1.630\t Validation loss: 1.587\n",
      "[24] Training loss: 1.578\t Validation loss: 1.542\n",
      "[25] Training loss: 1.533\t Validation loss: 1.504\n",
      "[26] Training loss: 1.496\t Validation loss: 1.472\n",
      "[27] Training loss: 1.463\t Validation loss: 1.444\n",
      "[28] Training loss: 1.436\t Validation loss: 1.423\n",
      "[29] Training loss: 1.414\t Validation loss: 1.406\n",
      "[30] Training loss: 1.397\t Validation loss: 1.392\n",
      "[31] Training loss: 1.383\t Validation loss: 1.381\n",
      "[32] Training loss: 1.371\t Validation loss: 1.371\n",
      "[33] Training loss: 1.361\t Validation loss: 1.363\n",
      "[34] Training loss: 1.353\t Validation loss: 1.358\n",
      "[35] Training loss: 1.347\t Validation loss: 1.354\n",
      "[36] Training loss: 1.343\t Validation loss: 1.351\n",
      "[37] Training loss: 1.340\t Validation loss: 1.348\n",
      "[38] Training loss: 1.337\t Validation loss: 1.347\n",
      "[39] Training loss: 1.336\t Validation loss: 1.346\n",
      "[40] Training loss: 1.335\t Validation loss: 1.345\n",
      "[41] Training loss: 1.334\t Validation loss: 1.344\n",
      "[42] Training loss: 1.332\t Validation loss: 1.342\n",
      "[43] Training loss: 1.331\t Validation loss: 1.340\n",
      "[44] Training loss: 1.329\t Validation loss: 1.338\n",
      "[45] Training loss: 1.327\t Validation loss: 1.335\n",
      "[46] Training loss: 1.325\t Validation loss: 1.333\n",
      "[47] Training loss: 1.322\t Validation loss: 1.331\n",
      "[48] Training loss: 1.320\t Validation loss: 1.329\n",
      "[49] Training loss: 1.318\t Validation loss: 1.326\n",
      "[50] Training loss: 1.316\t Validation loss: 1.324\n",
      "[1] Training loss: 5.154\t Validation loss: 4.955\n",
      "[2] Training loss: 4.909\t Validation loss: 4.696\n",
      "[3] Training loss: 4.651\t Validation loss: 4.424\n",
      "[4] Training loss: 4.382\t Validation loss: 4.164\n",
      "[5] Training loss: 4.124\t Validation loss: 3.924\n",
      "[6] Training loss: 3.886\t Validation loss: 3.701\n",
      "[7] Training loss: 3.664\t Validation loss: 3.493\n",
      "[8] Training loss: 3.457\t Validation loss: 3.301\n",
      "[9] Training loss: 3.266\t Validation loss: 3.125\n",
      "[10] Training loss: 3.091\t Validation loss: 2.961\n",
      "[11] Training loss: 2.927\t Validation loss: 2.803\n",
      "[12] Training loss: 2.770\t Validation loss: 2.650\n",
      "[13] Training loss: 2.617\t Validation loss: 2.502\n",
      "[14] Training loss: 2.469\t Validation loss: 2.359\n",
      "[15] Training loss: 2.327\t Validation loss: 2.224\n",
      "[16] Training loss: 2.192\t Validation loss: 2.098\n",
      "[17] Training loss: 2.066\t Validation loss: 1.983\n",
      "[18] Training loss: 1.951\t Validation loss: 1.880\n",
      "[19] Training loss: 1.848\t Validation loss: 1.790\n",
      "[20] Training loss: 1.757\t Validation loss: 1.712\n",
      "[21] Training loss: 1.680\t Validation loss: 1.647\n",
      "[22] Training loss: 1.613\t Validation loss: 1.591\n",
      "[23] Training loss: 1.557\t Validation loss: 1.545\n",
      "[24] Training loss: 1.510\t Validation loss: 1.506\n",
      "[25] Training loss: 1.470\t Validation loss: 1.474\n",
      "[26] Training loss: 1.438\t Validation loss: 1.448\n",
      "[27] Training loss: 1.411\t Validation loss: 1.428\n",
      "[28] Training loss: 1.390\t Validation loss: 1.412\n",
      "[29] Training loss: 1.374\t Validation loss: 1.399\n",
      "[30] Training loss: 1.360\t Validation loss: 1.388\n",
      "[31] Training loss: 1.349\t Validation loss: 1.379\n",
      "[32] Training loss: 1.340\t Validation loss: 1.371\n",
      "[33] Training loss: 1.331\t Validation loss: 1.363\n",
      "[34] Training loss: 1.323\t Validation loss: 1.354\n",
      "[35] Training loss: 1.316\t Validation loss: 1.346\n",
      "[36] Training loss: 1.308\t Validation loss: 1.338\n",
      "[37] Training loss: 1.300\t Validation loss: 1.329\n",
      "[38] Training loss: 1.292\t Validation loss: 1.322\n",
      "[39] Training loss: 1.286\t Validation loss: 1.316\n",
      "[40] Training loss: 1.280\t Validation loss: 1.311\n",
      "[41] Training loss: 1.276\t Validation loss: 1.307\n",
      "[42] Training loss: 1.273\t Validation loss: 1.304\n",
      "[43] Training loss: 1.270\t Validation loss: 1.301\n",
      "[44] Training loss: 1.267\t Validation loss: 1.298\n",
      "[45] Training loss: 1.265\t Validation loss: 1.295\n",
      "[46] Training loss: 1.262\t Validation loss: 1.292\n",
      "[47] Training loss: 1.260\t Validation loss: 1.289\n",
      "[48] Training loss: 1.257\t Validation loss: 1.286\n",
      "[49] Training loss: 1.254\t Validation loss: 1.283\n",
      "[50] Training loss: 1.251\t Validation loss: 1.280\n",
      "[1] Training loss: 5.072\t Validation loss: 4.481\n",
      "[2] Training loss: 4.494\t Validation loss: 3.801\n",
      "[3] Training loss: 3.811\t Validation loss: 3.132\n",
      "[4] Training loss: 3.138\t Validation loss: 2.602\n",
      "[5] Training loss: 2.604\t Validation loss: 2.336\n",
      "[6] Training loss: 2.336\t Validation loss: 2.302\n",
      "[7] Training loss: 2.299\t Validation loss: 2.307\n",
      "[8] Training loss: 2.301\t Validation loss: 2.226\n",
      "[9] Training loss: 2.217\t Validation loss: 2.055\n",
      "[10] Training loss: 2.044\t Validation loss: 1.852\n",
      "[11] Training loss: 1.840\t Validation loss: 1.681\n",
      "[12] Training loss: 1.669\t Validation loss: 1.577\n",
      "[13] Training loss: 1.565\t Validation loss: 1.538\n",
      "[14] Training loss: 1.526\t Validation loss: 1.540\n",
      "[15] Training loss: 1.528\t Validation loss: 1.554\n",
      "[16] Training loss: 1.543\t Validation loss: 1.562\n",
      "[17] Training loss: 1.552\t Validation loss: 1.562\n",
      "[18] Training loss: 1.553\t Validation loss: 1.551\n",
      "[19] Training loss: 1.542\t Validation loss: 1.527\n",
      "[20] Training loss: 1.519\t Validation loss: 1.495\n",
      "[21] Training loss: 1.486\t Validation loss: 1.461\n",
      "[22] Training loss: 1.451\t Validation loss: 1.432\n",
      "[23] Training loss: 1.421\t Validation loss: 1.412\n",
      "[24] Training loss: 1.399\t Validation loss: 1.396\n",
      "[25] Training loss: 1.382\t Validation loss: 1.380\n",
      "[26] Training loss: 1.365\t Validation loss: 1.361\n",
      "[27] Training loss: 1.344\t Validation loss: 1.339\n",
      "[28] Training loss: 1.321\t Validation loss: 1.317\n",
      "[29] Training loss: 1.297\t Validation loss: 1.299\n",
      "[30] Training loss: 1.278\t Validation loss: 1.287\n",
      "[31] Training loss: 1.266\t Validation loss: 1.279\n",
      "[32] Training loss: 1.257\t Validation loss: 1.271\n",
      "[33] Training loss: 1.250\t Validation loss: 1.260\n",
      "[34] Training loss: 1.239\t Validation loss: 1.246\n",
      "[35] Training loss: 1.226\t Validation loss: 1.231\n",
      "[36] Training loss: 1.212\t Validation loss: 1.217\n",
      "[37] Training loss: 1.199\t Validation loss: 1.205\n",
      "[38] Training loss: 1.187\t Validation loss: 1.195\n",
      "[39] Training loss: 1.177\t Validation loss: 1.185\n",
      "[40] Training loss: 1.168\t Validation loss: 1.175\n",
      "[41] Training loss: 1.158\t Validation loss: 1.163\n",
      "[42] Training loss: 1.146\t Validation loss: 1.152\n",
      "[43] Training loss: 1.134\t Validation loss: 1.140\n",
      "[44] Training loss: 1.123\t Validation loss: 1.131\n",
      "[45] Training loss: 1.112\t Validation loss: 1.122\n",
      "[46] Training loss: 1.103\t Validation loss: 1.115\n",
      "[47] Training loss: 1.096\t Validation loss: 1.108\n",
      "[48] Training loss: 1.088\t Validation loss: 1.101\n",
      "[49] Training loss: 1.080\t Validation loss: 1.092\n",
      "[50] Training loss: 1.072\t Validation loss: 1.084\n",
      "[1] Training loss: 5.331\t Validation loss: 5.023\n",
      "[2] Training loss: 4.970\t Validation loss: 4.539\n",
      "[3] Training loss: 4.491\t Validation loss: 3.953\n",
      "[4] Training loss: 3.912\t Validation loss: 3.342\n",
      "[5] Training loss: 3.309\t Validation loss: 2.803\n",
      "[6] Training loss: 2.778\t Validation loss: 2.419\n",
      "[7] Training loss: 2.400\t Validation loss: 2.186\n",
      "[8] Training loss: 2.171\t Validation loss: 2.049\n",
      "[9] Training loss: 2.036\t Validation loss: 1.953\n",
      "[10] Training loss: 1.941\t Validation loss: 1.860\n",
      "[11] Training loss: 1.850\t Validation loss: 1.767\n",
      "[12] Training loss: 1.758\t Validation loss: 1.693\n",
      "[13] Training loss: 1.684\t Validation loss: 1.655\n",
      "[14] Training loss: 1.647\t Validation loss: 1.652\n",
      "[15] Training loss: 1.643\t Validation loss: 1.662\n",
      "[16] Training loss: 1.651\t Validation loss: 1.663\n",
      "[17] Training loss: 1.651\t Validation loss: 1.648\n",
      "[18] Training loss: 1.634\t Validation loss: 1.615\n",
      "[19] Training loss: 1.600\t Validation loss: 1.568\n",
      "[20] Training loss: 1.553\t Validation loss: 1.519\n",
      "[21] Training loss: 1.505\t Validation loss: 1.480\n",
      "[22] Training loss: 1.465\t Validation loss: 1.454\n",
      "[23] Training loss: 1.439\t Validation loss: 1.436\n",
      "[24] Training loss: 1.421\t Validation loss: 1.421\n",
      "[25] Training loss: 1.405\t Validation loss: 1.404\n",
      "[26] Training loss: 1.387\t Validation loss: 1.385\n",
      "[27] Training loss: 1.367\t Validation loss: 1.365\n",
      "[28] Training loss: 1.346\t Validation loss: 1.346\n",
      "[29] Training loss: 1.327\t Validation loss: 1.329\n",
      "[30] Training loss: 1.309\t Validation loss: 1.312\n",
      "[31] Training loss: 1.293\t Validation loss: 1.299\n",
      "[32] Training loss: 1.279\t Validation loss: 1.287\n",
      "[33] Training loss: 1.268\t Validation loss: 1.277\n",
      "[34] Training loss: 1.259\t Validation loss: 1.268\n",
      "[35] Training loss: 1.249\t Validation loss: 1.256\n",
      "[36] Training loss: 1.237\t Validation loss: 1.242\n",
      "[37] Training loss: 1.223\t Validation loss: 1.228\n",
      "[38] Training loss: 1.208\t Validation loss: 1.216\n",
      "[39] Training loss: 1.195\t Validation loss: 1.205\n",
      "[40] Training loss: 1.183\t Validation loss: 1.194\n",
      "[41] Training loss: 1.172\t Validation loss: 1.184\n",
      "[42] Training loss: 1.160\t Validation loss: 1.173\n",
      "[43] Training loss: 1.149\t Validation loss: 1.163\n",
      "[44] Training loss: 1.138\t Validation loss: 1.154\n",
      "[45] Training loss: 1.130\t Validation loss: 1.148\n",
      "[46] Training loss: 1.123\t Validation loss: 1.141\n",
      "[47] Training loss: 1.116\t Validation loss: 1.133\n",
      "[48] Training loss: 1.108\t Validation loss: 1.124\n",
      "[49] Training loss: 1.099\t Validation loss: 1.115\n",
      "[50] Training loss: 1.090\t Validation loss: 1.106\n",
      "[1] Training loss: 5.537\t Validation loss: 5.167\n",
      "[2] Training loss: 5.146\t Validation loss: 4.740\n",
      "[3] Training loss: 4.722\t Validation loss: 4.201\n",
      "[4] Training loss: 4.185\t Validation loss: 3.585\n",
      "[5] Training loss: 3.572\t Validation loss: 2.953\n",
      "[6] Training loss: 2.942\t Validation loss: 2.409\n",
      "[7] Training loss: 2.401\t Validation loss: 2.072\n",
      "[8] Training loss: 2.064\t Validation loss: 1.988\n",
      "[9] Training loss: 1.979\t Validation loss: 2.051\n",
      "[10] Training loss: 2.039\t Validation loss: 2.089\n",
      "[11] Training loss: 2.074\t Validation loss: 2.018\n",
      "[12] Training loss: 2.000\t Validation loss: 1.865\n",
      "[13] Training loss: 1.844\t Validation loss: 1.701\n",
      "[14] Training loss: 1.677\t Validation loss: 1.585\n",
      "[15] Training loss: 1.558\t Validation loss: 1.542\n",
      "[16] Training loss: 1.514\t Validation loss: 1.561\n",
      "[17] Training loss: 1.531\t Validation loss: 1.612\n",
      "[18] Training loss: 1.580\t Validation loss: 1.662\n",
      "[19] Training loss: 1.629\t Validation loss: 1.692\n",
      "[20] Training loss: 1.658\t Validation loss: 1.693\n",
      "[21] Training loss: 1.658\t Validation loss: 1.666\n",
      "[22] Training loss: 1.631\t Validation loss: 1.620\n",
      "[23] Training loss: 1.584\t Validation loss: 1.566\n",
      "[24] Training loss: 1.530\t Validation loss: 1.515\n",
      "[25] Training loss: 1.479\t Validation loss: 1.478\n",
      "[26] Training loss: 1.441\t Validation loss: 1.456\n",
      "[27] Training loss: 1.419\t Validation loss: 1.447\n",
      "[28] Training loss: 1.410\t Validation loss: 1.443\n",
      "[29] Training loss: 1.407\t Validation loss: 1.436\n",
      "[30] Training loss: 1.401\t Validation loss: 1.422\n",
      "[31] Training loss: 1.387\t Validation loss: 1.401\n",
      "[32] Training loss: 1.367\t Validation loss: 1.378\n",
      "[33] Training loss: 1.345\t Validation loss: 1.359\n",
      "[34] Training loss: 1.327\t Validation loss: 1.347\n",
      "[35] Training loss: 1.316\t Validation loss: 1.343\n",
      "[36] Training loss: 1.312\t Validation loss: 1.342\n",
      "[37] Training loss: 1.312\t Validation loss: 1.342\n",
      "[38] Training loss: 1.312\t Validation loss: 1.338\n",
      "[39] Training loss: 1.308\t Validation loss: 1.329\n",
      "[40] Training loss: 1.298\t Validation loss: 1.315\n",
      "[41] Training loss: 1.284\t Validation loss: 1.299\n",
      "[42] Training loss: 1.267\t Validation loss: 1.283\n",
      "[43] Training loss: 1.251\t Validation loss: 1.270\n",
      "[44] Training loss: 1.237\t Validation loss: 1.261\n",
      "[45] Training loss: 1.227\t Validation loss: 1.255\n",
      "[46] Training loss: 1.220\t Validation loss: 1.250\n",
      "[47] Training loss: 1.214\t Validation loss: 1.244\n",
      "[48] Training loss: 1.207\t Validation loss: 1.236\n",
      "[49] Training loss: 1.199\t Validation loss: 1.227\n",
      "[50] Training loss: 1.190\t Validation loss: 1.219\n",
      "[1] Training loss: 5.328\t Validation loss: 4.704\n",
      "[2] Training loss: 4.734\t Validation loss: 3.971\n",
      "[3] Training loss: 3.993\t Validation loss: 3.203\n",
      "[4] Training loss: 3.216\t Validation loss: 2.613\n",
      "[5] Training loss: 2.618\t Validation loss: 2.381\n",
      "[6] Training loss: 2.380\t Validation loss: 2.313\n",
      "[7] Training loss: 2.310\t Validation loss: 2.192\n",
      "[8] Training loss: 2.189\t Validation loss: 1.994\n",
      "[9] Training loss: 1.992\t Validation loss: 1.777\n",
      "[10] Training loss: 1.776\t Validation loss: 1.611\n",
      "[11] Training loss: 1.613\t Validation loss: 1.537\n",
      "[12] Training loss: 1.541\t Validation loss: 1.543\n",
      "[13] Training loss: 1.550\t Validation loss: 1.584\n",
      "[14] Training loss: 1.591\t Validation loss: 1.614\n",
      "[15] Training loss: 1.622\t Validation loss: 1.618\n",
      "[16] Training loss: 1.626\t Validation loss: 1.597\n",
      "[17] Training loss: 1.606\t Validation loss: 1.562\n",
      "[18] Training loss: 1.570\t Validation loss: 1.521\n",
      "[19] Training loss: 1.528\t Validation loss: 1.481\n",
      "[20] Training loss: 1.487\t Validation loss: 1.447\n",
      "[21] Training loss: 1.451\t Validation loss: 1.416\n",
      "[22] Training loss: 1.419\t Validation loss: 1.389\n",
      "[23] Training loss: 1.389\t Validation loss: 1.363\n",
      "[24] Training loss: 1.362\t Validation loss: 1.340\n",
      "[25] Training loss: 1.336\t Validation loss: 1.321\n",
      "[26] Training loss: 1.315\t Validation loss: 1.306\n",
      "[27] Training loss: 1.298\t Validation loss: 1.294\n",
      "[28] Training loss: 1.285\t Validation loss: 1.283\n",
      "[29] Training loss: 1.272\t Validation loss: 1.268\n",
      "[30] Training loss: 1.256\t Validation loss: 1.247\n",
      "[31] Training loss: 1.234\t Validation loss: 1.224\n",
      "[32] Training loss: 1.210\t Validation loss: 1.202\n",
      "[33] Training loss: 1.188\t Validation loss: 1.182\n",
      "[34] Training loss: 1.168\t Validation loss: 1.166\n",
      "[35] Training loss: 1.152\t Validation loss: 1.153\n",
      "[36] Training loss: 1.138\t Validation loss: 1.139\n",
      "[37] Training loss: 1.124\t Validation loss: 1.122\n",
      "[38] Training loss: 1.107\t Validation loss: 1.102\n",
      "[39] Training loss: 1.086\t Validation loss: 1.080\n",
      "[40] Training loss: 1.064\t Validation loss: 1.059\n",
      "[41] Training loss: 1.043\t Validation loss: 1.040\n",
      "[42] Training loss: 1.025\t Validation loss: 1.023\n",
      "[43] Training loss: 1.007\t Validation loss: 1.005\n",
      "[44] Training loss: 0.989\t Validation loss: 0.988\n",
      "[45] Training loss: 0.971\t Validation loss: 0.970\n",
      "[46] Training loss: 0.953\t Validation loss: 0.954\n",
      "[47] Training loss: 0.936\t Validation loss: 0.939\n",
      "[48] Training loss: 0.921\t Validation loss: 0.924\n",
      "[49] Training loss: 0.906\t Validation loss: 0.909\n",
      "[50] Training loss: 0.891\t Validation loss: 0.893\n",
      "[1] Training loss: 5.337\t Validation loss: 4.484\n",
      "[2] Training loss: 4.543\t Validation loss: 3.516\n",
      "[3] Training loss: 3.564\t Validation loss: 2.587\n",
      "[4] Training loss: 2.624\t Validation loss: 2.030\n",
      "[5] Training loss: 2.060\t Validation loss: 2.028\n",
      "[6] Training loss: 2.055\t Validation loss: 2.206\n",
      "[7] Training loss: 2.232\t Validation loss: 2.142\n",
      "[8] Training loss: 2.164\t Validation loss: 1.881\n",
      "[9] Training loss: 1.898\t Validation loss: 1.625\n",
      "[10] Training loss: 1.640\t Validation loss: 1.505\n",
      "[11] Training loss: 1.518\t Validation loss: 1.524\n",
      "[12] Training loss: 1.536\t Validation loss: 1.607\n",
      "[13] Training loss: 1.618\t Validation loss: 1.677\n",
      "[14] Training loss: 1.688\t Validation loss: 1.697\n",
      "[15] Training loss: 1.705\t Validation loss: 1.661\n",
      "[16] Training loss: 1.668\t Validation loss: 1.588\n",
      "[17] Training loss: 1.593\t Validation loss: 1.505\n",
      "[18] Training loss: 1.509\t Validation loss: 1.441\n",
      "[19] Training loss: 1.443\t Validation loss: 1.411\n",
      "[20] Training loss: 1.413\t Validation loss: 1.406\n",
      "[21] Training loss: 1.407\t Validation loss: 1.401\n",
      "[22] Training loss: 1.401\t Validation loss: 1.378\n",
      "[23] Training loss: 1.377\t Validation loss: 1.337\n",
      "[24] Training loss: 1.335\t Validation loss: 1.293\n",
      "[25] Training loss: 1.289\t Validation loss: 1.258\n",
      "[26] Training loss: 1.253\t Validation loss: 1.238\n",
      "[27] Training loss: 1.232\t Validation loss: 1.228\n",
      "[28] Training loss: 1.221\t Validation loss: 1.216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29] Training loss: 1.208\t Validation loss: 1.196\n",
      "[30] Training loss: 1.188\t Validation loss: 1.168\n",
      "[31] Training loss: 1.159\t Validation loss: 1.138\n",
      "[32] Training loss: 1.128\t Validation loss: 1.114\n",
      "[33] Training loss: 1.103\t Validation loss: 1.097\n",
      "[34] Training loss: 1.085\t Validation loss: 1.079\n",
      "[35] Training loss: 1.066\t Validation loss: 1.058\n",
      "[36] Training loss: 1.043\t Validation loss: 1.035\n",
      "[37] Training loss: 1.019\t Validation loss: 1.013\n",
      "[38] Training loss: 0.997\t Validation loss: 0.994\n",
      "[39] Training loss: 0.977\t Validation loss: 0.976\n",
      "[40] Training loss: 0.959\t Validation loss: 0.960\n",
      "[41] Training loss: 0.942\t Validation loss: 0.945\n",
      "[42] Training loss: 0.927\t Validation loss: 0.929\n",
      "[43] Training loss: 0.911\t Validation loss: 0.912\n",
      "[44] Training loss: 0.893\t Validation loss: 0.891\n",
      "[45] Training loss: 0.873\t Validation loss: 0.871\n",
      "[46] Training loss: 0.852\t Validation loss: 0.852\n",
      "[47] Training loss: 0.833\t Validation loss: 0.836\n",
      "[48] Training loss: 0.816\t Validation loss: 0.820\n",
      "[49] Training loss: 0.801\t Validation loss: 0.805\n",
      "[50] Training loss: 0.785\t Validation loss: 0.789\n",
      "[1] Training loss: 5.269\t Validation loss: 4.533\n",
      "[2] Training loss: 4.610\t Validation loss: 3.666\n",
      "[3] Training loss: 3.726\t Validation loss: 2.725\n",
      "[4] Training loss: 2.765\t Validation loss: 2.046\n",
      "[5] Training loss: 2.071\t Validation loss: 1.938\n",
      "[6] Training loss: 1.956\t Validation loss: 2.141\n",
      "[7] Training loss: 2.156\t Validation loss: 2.152\n",
      "[8] Training loss: 2.160\t Validation loss: 1.908\n",
      "[9] Training loss: 1.907\t Validation loss: 1.637\n",
      "[10] Training loss: 1.628\t Validation loss: 1.512\n",
      "[11] Training loss: 1.500\t Validation loss: 1.535\n",
      "[12] Training loss: 1.524\t Validation loss: 1.623\n",
      "[13] Training loss: 1.614\t Validation loss: 1.699\n",
      "[14] Training loss: 1.690\t Validation loss: 1.722\n",
      "[15] Training loss: 1.714\t Validation loss: 1.685\n",
      "[16] Training loss: 1.676\t Validation loss: 1.604\n",
      "[17] Training loss: 1.593\t Validation loss: 1.505\n",
      "[18] Training loss: 1.492\t Validation loss: 1.422\n",
      "[19] Training loss: 1.407\t Validation loss: 1.380\n",
      "[20] Training loss: 1.363\t Validation loss: 1.373\n",
      "[21] Training loss: 1.355\t Validation loss: 1.369\n",
      "[22] Training loss: 1.350\t Validation loss: 1.343\n",
      "[23] Training loss: 1.324\t Validation loss: 1.296\n",
      "[24] Training loss: 1.277\t Validation loss: 1.246\n",
      "[25] Training loss: 1.226\t Validation loss: 1.211\n",
      "[26] Training loss: 1.189\t Validation loss: 1.194\n",
      "[27] Training loss: 1.172\t Validation loss: 1.189\n",
      "[28] Training loss: 1.166\t Validation loss: 1.183\n",
      "[29] Training loss: 1.159\t Validation loss: 1.166\n",
      "[30] Training loss: 1.141\t Validation loss: 1.138\n",
      "[31] Training loss: 1.111\t Validation loss: 1.104\n",
      "[32] Training loss: 1.075\t Validation loss: 1.072\n",
      "[33] Training loss: 1.041\t Validation loss: 1.047\n",
      "[34] Training loss: 1.015\t Validation loss: 1.030\n",
      "[35] Training loss: 0.997\t Validation loss: 1.017\n",
      "[36] Training loss: 0.983\t Validation loss: 1.001\n",
      "[37] Training loss: 0.967\t Validation loss: 0.982\n",
      "[38] Training loss: 0.947\t Validation loss: 0.958\n",
      "[39] Training loss: 0.924\t Validation loss: 0.936\n",
      "[40] Training loss: 0.902\t Validation loss: 0.916\n",
      "[41] Training loss: 0.882\t Validation loss: 0.899\n",
      "[42] Training loss: 0.865\t Validation loss: 0.882\n",
      "[43] Training loss: 0.848\t Validation loss: 0.863\n",
      "[44] Training loss: 0.829\t Validation loss: 0.843\n",
      "[45] Training loss: 0.808\t Validation loss: 0.823\n",
      "[46] Training loss: 0.788\t Validation loss: 0.806\n",
      "[47] Training loss: 0.771\t Validation loss: 0.791\n",
      "[48] Training loss: 0.756\t Validation loss: 0.777\n",
      "[49] Training loss: 0.741\t Validation loss: 0.760\n",
      "[50] Training loss: 0.725\t Validation loss: 0.742\n",
      "[1] Training loss: 5.407\t Validation loss: 4.711\n",
      "[2] Training loss: 4.702\t Validation loss: 3.844\n",
      "[3] Training loss: 3.830\t Validation loss: 2.863\n",
      "[4] Training loss: 2.846\t Validation loss: 2.059\n",
      "[5] Training loss: 2.038\t Validation loss: 1.839\n",
      "[6] Training loss: 1.816\t Validation loss: 2.134\n",
      "[7] Training loss: 2.112\t Validation loss: 2.238\n",
      "[8] Training loss: 2.218\t Validation loss: 2.026\n",
      "[9] Training loss: 2.008\t Validation loss: 1.739\n",
      "[10] Training loss: 1.722\t Validation loss: 1.558\n",
      "[11] Training loss: 1.542\t Validation loss: 1.532\n",
      "[12] Training loss: 1.515\t Validation loss: 1.607\n",
      "[13] Training loss: 1.591\t Validation loss: 1.702\n",
      "[14] Training loss: 1.685\t Validation loss: 1.757\n",
      "[15] Training loss: 1.740\t Validation loss: 1.752\n",
      "[16] Training loss: 1.733\t Validation loss: 1.689\n",
      "[17] Training loss: 1.670\t Validation loss: 1.592\n",
      "[18] Training loss: 1.571\t Validation loss: 1.490\n",
      "[19] Training loss: 1.467\t Validation loss: 1.413\n",
      "[20] Training loss: 1.389\t Validation loss: 1.378\n",
      "[21] Training loss: 1.353\t Validation loss: 1.382\n",
      "[22] Training loss: 1.355\t Validation loss: 1.400\n",
      "[23] Training loss: 1.371\t Validation loss: 1.405\n",
      "[24] Training loss: 1.375\t Validation loss: 1.387\n",
      "[25] Training loss: 1.356\t Validation loss: 1.354\n",
      "[26] Training loss: 1.322\t Validation loss: 1.319\n",
      "[27] Training loss: 1.286\t Validation loss: 1.292\n",
      "[28] Training loss: 1.258\t Validation loss: 1.276\n",
      "[29] Training loss: 1.240\t Validation loss: 1.264\n",
      "[30] Training loss: 1.228\t Validation loss: 1.249\n",
      "[31] Training loss: 1.213\t Validation loss: 1.228\n",
      "[32] Training loss: 1.191\t Validation loss: 1.199\n",
      "[33] Training loss: 1.163\t Validation loss: 1.167\n",
      "[34] Training loss: 1.132\t Validation loss: 1.139\n",
      "[35] Training loss: 1.105\t Validation loss: 1.120\n",
      "[36] Training loss: 1.086\t Validation loss: 1.103\n",
      "[37] Training loss: 1.069\t Validation loss: 1.085\n",
      "[38] Training loss: 1.051\t Validation loss: 1.066\n",
      "[39] Training loss: 1.032\t Validation loss: 1.047\n",
      "[40] Training loss: 1.012\t Validation loss: 1.028\n",
      "[41] Training loss: 0.992\t Validation loss: 1.008\n",
      "[42] Training loss: 0.971\t Validation loss: 0.988\n",
      "[43] Training loss: 0.951\t Validation loss: 0.969\n",
      "[44] Training loss: 0.931\t Validation loss: 0.952\n",
      "[45] Training loss: 0.913\t Validation loss: 0.934\n",
      "[46] Training loss: 0.895\t Validation loss: 0.914\n",
      "[47] Training loss: 0.876\t Validation loss: 0.894\n",
      "[48] Training loss: 0.855\t Validation loss: 0.875\n",
      "[49] Training loss: 0.836\t Validation loss: 0.859\n",
      "[50] Training loss: 0.821\t Validation loss: 0.844\n",
      "3684 Samples\n",
      "\n",
      "[1] Training loss: 5.291\t Validation loss: 5.121\n",
      "[2] Training loss: 5.057\t Validation loss: 4.947\n",
      "[3] Training loss: 4.882\t Validation loss: 4.761\n",
      "[4] Training loss: 4.693\t Validation loss: 4.567\n",
      "[5] Training loss: 4.497\t Validation loss: 4.371\n",
      "[6] Training loss: 4.299\t Validation loss: 4.179\n",
      "[7] Training loss: 4.105\t Validation loss: 3.996\n",
      "[8] Training loss: 3.920\t Validation loss: 3.826\n",
      "[9] Training loss: 3.748\t Validation loss: 3.671\n",
      "[10] Training loss: 3.592\t Validation loss: 3.528\n",
      "[11] Training loss: 3.449\t Validation loss: 3.395\n",
      "[12] Training loss: 3.317\t Validation loss: 3.266\n",
      "[13] Training loss: 3.189\t Validation loss: 3.137\n",
      "[14] Training loss: 3.062\t Validation loss: 3.005\n",
      "[15] Training loss: 2.933\t Validation loss: 2.870\n",
      "[16] Training loss: 2.802\t Validation loss: 2.735\n",
      "[17] Training loss: 2.671\t Validation loss: 2.603\n",
      "[18] Training loss: 2.544\t Validation loss: 2.478\n",
      "[19] Training loss: 2.423\t Validation loss: 2.363\n",
      "[20] Training loss: 2.312\t Validation loss: 2.259\n",
      "[21] Training loss: 2.212\t Validation loss: 2.166\n",
      "[22] Training loss: 2.123\t Validation loss: 2.084\n",
      "[23] Training loss: 2.044\t Validation loss: 2.011\n",
      "[24] Training loss: 1.974\t Validation loss: 1.946\n",
      "[25] Training loss: 1.912\t Validation loss: 1.886\n",
      "[26] Training loss: 1.855\t Validation loss: 1.832\n",
      "[27] Training loss: 1.802\t Validation loss: 1.782\n",
      "[28] Training loss: 1.755\t Validation loss: 1.737\n",
      "[29] Training loss: 1.712\t Validation loss: 1.697\n",
      "[30] Training loss: 1.674\t Validation loss: 1.664\n",
      "[31] Training loss: 1.642\t Validation loss: 1.635\n",
      "[32] Training loss: 1.615\t Validation loss: 1.611\n",
      "[33] Training loss: 1.593\t Validation loss: 1.591\n",
      "[34] Training loss: 1.575\t Validation loss: 1.574\n",
      "[35] Training loss: 1.559\t Validation loss: 1.559\n",
      "[36] Training loss: 1.545\t Validation loss: 1.546\n",
      "[37] Training loss: 1.533\t Validation loss: 1.533\n",
      "[38] Training loss: 1.522\t Validation loss: 1.522\n",
      "[39] Training loss: 1.512\t Validation loss: 1.512\n",
      "[40] Training loss: 1.503\t Validation loss: 1.504\n",
      "[41] Training loss: 1.496\t Validation loss: 1.498\n",
      "[42] Training loss: 1.491\t Validation loss: 1.493\n",
      "[43] Training loss: 1.487\t Validation loss: 1.489\n",
      "[44] Training loss: 1.484\t Validation loss: 1.486\n",
      "[45] Training loss: 1.481\t Validation loss: 1.483\n",
      "[46] Training loss: 1.479\t Validation loss: 1.480\n",
      "[47] Training loss: 1.476\t Validation loss: 1.478\n",
      "[48] Training loss: 1.474\t Validation loss: 1.476\n",
      "[49] Training loss: 1.472\t Validation loss: 1.474\n",
      "[50] Training loss: 1.471\t Validation loss: 1.472\n",
      "[1] Training loss: 5.604\t Validation loss: 5.468\n",
      "[2] Training loss: 5.482\t Validation loss: 5.400\n",
      "[3] Training loss: 5.413\t Validation loss: 5.320\n",
      "[4] Training loss: 5.331\t Validation loss: 5.227\n",
      "[5] Training loss: 5.236\t Validation loss: 5.121\n",
      "[6] Training loss: 5.127\t Validation loss: 4.994\n",
      "[7] Training loss: 4.997\t Validation loss: 4.842\n",
      "[8] Training loss: 4.842\t Validation loss: 4.669\n",
      "[9] Training loss: 4.666\t Validation loss: 4.482\n",
      "[10] Training loss: 4.476\t Validation loss: 4.287\n",
      "[11] Training loss: 4.277\t Validation loss: 4.086\n",
      "[12] Training loss: 4.073\t Validation loss: 3.885\n",
      "[13] Training loss: 3.870\t Validation loss: 3.688\n",
      "[14] Training loss: 3.670\t Validation loss: 3.497\n",
      "[15] Training loss: 3.476\t Validation loss: 3.316\n",
      "[16] Training loss: 3.292\t Validation loss: 3.145\n",
      "[17] Training loss: 3.120\t Validation loss: 2.987\n",
      "[18] Training loss: 2.960\t Validation loss: 2.841\n",
      "[19] Training loss: 2.813\t Validation loss: 2.706\n",
      "[20] Training loss: 2.678\t Validation loss: 2.581\n",
      "[21] Training loss: 2.552\t Validation loss: 2.463\n",
      "[22] Training loss: 2.434\t Validation loss: 2.352\n",
      "[23] Training loss: 2.323\t Validation loss: 2.246\n",
      "[24] Training loss: 2.218\t Validation loss: 2.148\n",
      "[25] Training loss: 2.121\t Validation loss: 2.058\n",
      "[26] Training loss: 2.031\t Validation loss: 1.977\n",
      "[27] Training loss: 1.951\t Validation loss: 1.906\n",
      "[28] Training loss: 1.880\t Validation loss: 1.844\n",
      "[29] Training loss: 1.818\t Validation loss: 1.790\n",
      "[30] Training loss: 1.765\t Validation loss: 1.744\n",
      "[31] Training loss: 1.719\t Validation loss: 1.705\n",
      "[32] Training loss: 1.680\t Validation loss: 1.672\n",
      "[33] Training loss: 1.647\t Validation loss: 1.643\n",
      "[34] Training loss: 1.619\t Validation loss: 1.618\n",
      "[35] Training loss: 1.595\t Validation loss: 1.597\n",
      "[36] Training loss: 1.573\t Validation loss: 1.578\n",
      "[37] Training loss: 1.555\t Validation loss: 1.562\n",
      "[38] Training loss: 1.539\t Validation loss: 1.549\n",
      "[39] Training loss: 1.526\t Validation loss: 1.538\n",
      "[40] Training loss: 1.516\t Validation loss: 1.529\n",
      "[41] Training loss: 1.507\t Validation loss: 1.521\n",
      "[42] Training loss: 1.500\t Validation loss: 1.516\n",
      "[43] Training loss: 1.495\t Validation loss: 1.511\n",
      "[44] Training loss: 1.490\t Validation loss: 1.506\n",
      "[45] Training loss: 1.486\t Validation loss: 1.502\n",
      "[46] Training loss: 1.483\t Validation loss: 1.499\n",
      "[47] Training loss: 1.480\t Validation loss: 1.496\n",
      "[48] Training loss: 1.477\t Validation loss: 1.493\n",
      "[49] Training loss: 1.475\t Validation loss: 1.491\n",
      "[50] Training loss: 1.473\t Validation loss: 1.490\n",
      "[1] Training loss: 5.212\t Validation loss: 4.630\n",
      "[2] Training loss: 4.702\t Validation loss: 4.106\n",
      "[3] Training loss: 4.166\t Validation loss: 3.562\n",
      "[4] Training loss: 3.609\t Validation loss: 3.068\n",
      "[5] Training loss: 3.104\t Validation loss: 2.700\n",
      "[6] Training loss: 2.727\t Validation loss: 2.484\n",
      "[7] Training loss: 2.503\t Validation loss: 2.365\n",
      "[8] Training loss: 2.378\t Validation loss: 2.265\n",
      "[9] Training loss: 2.274\t Validation loss: 2.141\n",
      "[10] Training loss: 2.145\t Validation loss: 1.994\n",
      "[11] Training loss: 1.995\t Validation loss: 1.851\n",
      "[12] Training loss: 1.848\t Validation loss: 1.731\n",
      "[13] Training loss: 1.725\t Validation loss: 1.645\n",
      "[14] Training loss: 1.636\t Validation loss: 1.588\n",
      "[15] Training loss: 1.577\t Validation loss: 1.554\n",
      "[16] Training loss: 1.542\t Validation loss: 1.534\n",
      "[17] Training loss: 1.521\t Validation loss: 1.521\n",
      "[18] Training loss: 1.508\t Validation loss: 1.511\n",
      "[19] Training loss: 1.498\t Validation loss: 1.503\n",
      "[20] Training loss: 1.490\t Validation loss: 1.497\n",
      "[21] Training loss: 1.484\t Validation loss: 1.495\n",
      "[22] Training loss: 1.482\t Validation loss: 1.494\n",
      "[23] Training loss: 1.479\t Validation loss: 1.490\n",
      "[24] Training loss: 1.474\t Validation loss: 1.480\n",
      "[25] Training loss: 1.463\t Validation loss: 1.465\n",
      "[26] Training loss: 1.446\t Validation loss: 1.448\n",
      "[27] Training loss: 1.425\t Validation loss: 1.431\n",
      "[28] Training loss: 1.405\t Validation loss: 1.416\n",
      "[29] Training loss: 1.387\t Validation loss: 1.403\n",
      "[30] Training loss: 1.371\t Validation loss: 1.391\n",
      "[31] Training loss: 1.356\t Validation loss: 1.379\n",
      "[32] Training loss: 1.342\t Validation loss: 1.367\n",
      "[33] Training loss: 1.327\t Validation loss: 1.354\n",
      "[34] Training loss: 1.312\t Validation loss: 1.343\n",
      "[35] Training loss: 1.300\t Validation loss: 1.333\n",
      "[36] Training loss: 1.289\t Validation loss: 1.325\n",
      "[37] Training loss: 1.281\t Validation loss: 1.319\n",
      "[38] Training loss: 1.274\t Validation loss: 1.314\n",
      "[39] Training loss: 1.268\t Validation loss: 1.307\n",
      "[40] Training loss: 1.262\t Validation loss: 1.300\n",
      "[41] Training loss: 1.254\t Validation loss: 1.291\n",
      "[42] Training loss: 1.246\t Validation loss: 1.283\n",
      "[43] Training loss: 1.237\t Validation loss: 1.275\n",
      "[44] Training loss: 1.229\t Validation loss: 1.268\n",
      "[45] Training loss: 1.223\t Validation loss: 1.262\n",
      "[46] Training loss: 1.217\t Validation loss: 1.256\n",
      "[47] Training loss: 1.211\t Validation loss: 1.250\n",
      "[48] Training loss: 1.206\t Validation loss: 1.244\n",
      "[49] Training loss: 1.200\t Validation loss: 1.238\n",
      "[50] Training loss: 1.194\t Validation loss: 1.231\n",
      "[1] Training loss: 5.300\t Validation loss: 4.817\n",
      "[2] Training loss: 4.820\t Validation loss: 4.279\n",
      "[3] Training loss: 4.277\t Validation loss: 3.701\n",
      "[4] Training loss: 3.694\t Validation loss: 3.172\n",
      "[5] Training loss: 3.161\t Validation loss: 2.774\n",
      "[6] Training loss: 2.758\t Validation loss: 2.514\n",
      "[7] Training loss: 2.496\t Validation loss: 2.321\n",
      "[8] Training loss: 2.302\t Validation loss: 2.141\n",
      "[9] Training loss: 2.121\t Validation loss: 1.969\n",
      "[10] Training loss: 1.949\t Validation loss: 1.829\n",
      "[11] Training loss: 1.808\t Validation loss: 1.742\n",
      "[12] Training loss: 1.721\t Validation loss: 1.714\n",
      "[13] Training loss: 1.691\t Validation loss: 1.713\n",
      "[14] Training loss: 1.689\t Validation loss: 1.710\n",
      "[15] Training loss: 1.684\t Validation loss: 1.693\n",
      "[16] Training loss: 1.666\t Validation loss: 1.661\n",
      "[17] Training loss: 1.631\t Validation loss: 1.619\n",
      "[18] Training loss: 1.587\t Validation loss: 1.575\n",
      "[19] Training loss: 1.541\t Validation loss: 1.535\n",
      "[20] Training loss: 1.499\t Validation loss: 1.505\n",
      "[21] Training loss: 1.466\t Validation loss: 1.484\n",
      "[22] Training loss: 1.444\t Validation loss: 1.471\n",
      "[23] Training loss: 1.428\t Validation loss: 1.462\n",
      "[24] Training loss: 1.416\t Validation loss: 1.453\n",
      "[25] Training loss: 1.404\t Validation loss: 1.444\n",
      "[26] Training loss: 1.393\t Validation loss: 1.436\n",
      "[27] Training loss: 1.382\t Validation loss: 1.429\n",
      "[28] Training loss: 1.373\t Validation loss: 1.425\n",
      "[29] Training loss: 1.366\t Validation loss: 1.420\n",
      "[30] Training loss: 1.359\t Validation loss: 1.412\n",
      "[31] Training loss: 1.349\t Validation loss: 1.401\n",
      "[32] Training loss: 1.336\t Validation loss: 1.387\n",
      "[33] Training loss: 1.321\t Validation loss: 1.373\n",
      "[34] Training loss: 1.306\t Validation loss: 1.359\n",
      "[35] Training loss: 1.291\t Validation loss: 1.348\n",
      "[36] Training loss: 1.279\t Validation loss: 1.337\n",
      "[37] Training loss: 1.268\t Validation loss: 1.327\n",
      "[38] Training loss: 1.258\t Validation loss: 1.316\n",
      "[39] Training loss: 1.247\t Validation loss: 1.305\n",
      "[40] Training loss: 1.236\t Validation loss: 1.295\n",
      "[41] Training loss: 1.225\t Validation loss: 1.285\n",
      "[42] Training loss: 1.216\t Validation loss: 1.276\n",
      "[43] Training loss: 1.206\t Validation loss: 1.267\n",
      "[44] Training loss: 1.197\t Validation loss: 1.258\n",
      "[45] Training loss: 1.188\t Validation loss: 1.248\n",
      "[46] Training loss: 1.178\t Validation loss: 1.239\n",
      "[47] Training loss: 1.169\t Validation loss: 1.231\n",
      "[48] Training loss: 1.161\t Validation loss: 1.224\n",
      "[49] Training loss: 1.153\t Validation loss: 1.216\n",
      "[50] Training loss: 1.145\t Validation loss: 1.209\n",
      "[1] Training loss: 5.224\t Validation loss: 4.766\n",
      "[2] Training loss: 4.715\t Validation loss: 4.139\n",
      "[3] Training loss: 4.097\t Validation loss: 3.442\n",
      "[4] Training loss: 3.411\t Validation loss: 2.803\n",
      "[5] Training loss: 2.783\t Validation loss: 2.389\n",
      "[6] Training loss: 2.376\t Validation loss: 2.278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] Training loss: 2.266\t Validation loss: 2.309\n",
      "[8] Training loss: 2.294\t Validation loss: 2.239\n",
      "[9] Training loss: 2.219\t Validation loss: 2.035\n",
      "[10] Training loss: 2.011\t Validation loss: 1.791\n",
      "[11] Training loss: 1.764\t Validation loss: 1.597\n",
      "[12] Training loss: 1.566\t Validation loss: 1.494\n",
      "[13] Training loss: 1.459\t Validation loss: 1.473\n",
      "[14] Training loss: 1.433\t Validation loss: 1.499\n",
      "[15] Training loss: 1.454\t Validation loss: 1.537\n",
      "[16] Training loss: 1.488\t Validation loss: 1.565\n",
      "[17] Training loss: 1.512\t Validation loss: 1.571\n",
      "[18] Training loss: 1.515\t Validation loss: 1.557\n",
      "[19] Training loss: 1.498\t Validation loss: 1.528\n",
      "[20] Training loss: 1.467\t Validation loss: 1.492\n",
      "[21] Training loss: 1.431\t Validation loss: 1.456\n",
      "[22] Training loss: 1.393\t Validation loss: 1.423\n",
      "[23] Training loss: 1.359\t Validation loss: 1.396\n",
      "[24] Training loss: 1.330\t Validation loss: 1.369\n",
      "[25] Training loss: 1.303\t Validation loss: 1.338\n",
      "[26] Training loss: 1.272\t Validation loss: 1.305\n",
      "[27] Training loss: 1.240\t Validation loss: 1.276\n",
      "[28] Training loss: 1.212\t Validation loss: 1.252\n",
      "[29] Training loss: 1.189\t Validation loss: 1.234\n",
      "[30] Training loss: 1.170\t Validation loss: 1.218\n",
      "[31] Training loss: 1.153\t Validation loss: 1.203\n",
      "[32] Training loss: 1.138\t Validation loss: 1.189\n",
      "[33] Training loss: 1.123\t Validation loss: 1.175\n",
      "[34] Training loss: 1.107\t Validation loss: 1.162\n",
      "[35] Training loss: 1.092\t Validation loss: 1.149\n",
      "[36] Training loss: 1.078\t Validation loss: 1.136\n",
      "[37] Training loss: 1.065\t Validation loss: 1.123\n",
      "[38] Training loss: 1.051\t Validation loss: 1.109\n",
      "[39] Training loss: 1.037\t Validation loss: 1.094\n",
      "[40] Training loss: 1.022\t Validation loss: 1.078\n",
      "[41] Training loss: 1.007\t Validation loss: 1.064\n",
      "[42] Training loss: 0.994\t Validation loss: 1.052\n",
      "[43] Training loss: 0.982\t Validation loss: 1.041\n",
      "[44] Training loss: 0.972\t Validation loss: 1.031\n",
      "[45] Training loss: 0.962\t Validation loss: 1.020\n",
      "[46] Training loss: 0.951\t Validation loss: 1.009\n",
      "[47] Training loss: 0.939\t Validation loss: 0.999\n",
      "[48] Training loss: 0.928\t Validation loss: 0.989\n",
      "[49] Training loss: 0.918\t Validation loss: 0.980\n",
      "[50] Training loss: 0.908\t Validation loss: 0.971\n",
      "[1] Training loss: 5.055\t Validation loss: 4.570\n",
      "[2] Training loss: 4.596\t Validation loss: 4.012\n",
      "[3] Training loss: 4.026\t Validation loss: 3.368\n",
      "[4] Training loss: 3.371\t Validation loss: 2.776\n",
      "[5] Training loss: 2.767\t Validation loss: 2.366\n",
      "[6] Training loss: 2.350\t Validation loss: 2.153\n",
      "[7] Training loss: 2.134\t Validation loss: 2.032\n",
      "[8] Training loss: 2.013\t Validation loss: 1.914\n",
      "[9] Training loss: 1.898\t Validation loss: 1.789\n",
      "[10] Training loss: 1.775\t Validation loss: 1.681\n",
      "[11] Training loss: 1.668\t Validation loss: 1.611\n",
      "[12] Training loss: 1.596\t Validation loss: 1.579\n",
      "[13] Training loss: 1.563\t Validation loss: 1.576\n",
      "[14] Training loss: 1.557\t Validation loss: 1.587\n",
      "[15] Training loss: 1.564\t Validation loss: 1.597\n",
      "[16] Training loss: 1.570\t Validation loss: 1.599\n",
      "[17] Training loss: 1.567\t Validation loss: 1.591\n",
      "[18] Training loss: 1.555\t Validation loss: 1.576\n",
      "[19] Training loss: 1.537\t Validation loss: 1.559\n",
      "[20] Training loss: 1.517\t Validation loss: 1.543\n",
      "[21] Training loss: 1.498\t Validation loss: 1.528\n",
      "[22] Training loss: 1.479\t Validation loss: 1.508\n",
      "[23] Training loss: 1.457\t Validation loss: 1.479\n",
      "[24] Training loss: 1.426\t Validation loss: 1.444\n",
      "[25] Training loss: 1.388\t Validation loss: 1.408\n",
      "[26] Training loss: 1.350\t Validation loss: 1.381\n",
      "[27] Training loss: 1.320\t Validation loss: 1.368\n",
      "[28] Training loss: 1.305\t Validation loss: 1.364\n",
      "[29] Training loss: 1.299\t Validation loss: 1.356\n",
      "[30] Training loss: 1.291\t Validation loss: 1.342\n",
      "[31] Training loss: 1.276\t Validation loss: 1.322\n",
      "[32] Training loss: 1.257\t Validation loss: 1.302\n",
      "[33] Training loss: 1.237\t Validation loss: 1.285\n",
      "[34] Training loss: 1.220\t Validation loss: 1.273\n",
      "[35] Training loss: 1.208\t Validation loss: 1.264\n",
      "[36] Training loss: 1.199\t Validation loss: 1.254\n",
      "[37] Training loss: 1.189\t Validation loss: 1.242\n",
      "[38] Training loss: 1.176\t Validation loss: 1.225\n",
      "[39] Training loss: 1.158\t Validation loss: 1.208\n",
      "[40] Training loss: 1.140\t Validation loss: 1.193\n",
      "[41] Training loss: 1.123\t Validation loss: 1.181\n",
      "[42] Training loss: 1.111\t Validation loss: 1.172\n",
      "[43] Training loss: 1.100\t Validation loss: 1.162\n",
      "[44] Training loss: 1.088\t Validation loss: 1.150\n",
      "[45] Training loss: 1.074\t Validation loss: 1.136\n",
      "[46] Training loss: 1.058\t Validation loss: 1.122\n",
      "[47] Training loss: 1.043\t Validation loss: 1.111\n",
      "[48] Training loss: 1.031\t Validation loss: 1.101\n",
      "[49] Training loss: 1.020\t Validation loss: 1.092\n",
      "[50] Training loss: 1.009\t Validation loss: 1.081\n",
      "[1] Training loss: 5.309\t Validation loss: 4.500\n",
      "[2] Training loss: 4.639\t Validation loss: 3.742\n",
      "[3] Training loss: 3.850\t Validation loss: 2.904\n",
      "[4] Training loss: 2.975\t Validation loss: 2.208\n",
      "[5] Training loss: 2.248\t Validation loss: 1.926\n",
      "[6] Training loss: 1.948\t Validation loss: 2.030\n",
      "[7] Training loss: 2.048\t Validation loss: 2.123\n",
      "[8] Training loss: 2.138\t Validation loss: 2.009\n",
      "[9] Training loss: 2.017\t Validation loss: 1.785\n",
      "[10] Training loss: 1.783\t Validation loss: 1.602\n",
      "[11] Training loss: 1.594\t Validation loss: 1.535\n",
      "[12] Training loss: 1.525\t Validation loss: 1.564\n",
      "[13] Training loss: 1.556\t Validation loss: 1.629\n",
      "[14] Training loss: 1.625\t Validation loss: 1.679\n",
      "[15] Training loss: 1.677\t Validation loss: 1.688\n",
      "[16] Training loss: 1.688\t Validation loss: 1.655\n",
      "[17] Training loss: 1.655\t Validation loss: 1.593\n",
      "[18] Training loss: 1.590\t Validation loss: 1.520\n",
      "[19] Training loss: 1.514\t Validation loss: 1.457\n",
      "[20] Training loss: 1.447\t Validation loss: 1.416\n",
      "[21] Training loss: 1.402\t Validation loss: 1.398\n",
      "[22] Training loss: 1.380\t Validation loss: 1.393\n",
      "[23] Training loss: 1.371\t Validation loss: 1.387\n",
      "[24] Training loss: 1.360\t Validation loss: 1.370\n",
      "[25] Training loss: 1.337\t Validation loss: 1.343\n",
      "[26] Training loss: 1.304\t Validation loss: 1.315\n",
      "[27] Training loss: 1.270\t Validation loss: 1.293\n",
      "[28] Training loss: 1.244\t Validation loss: 1.282\n",
      "[29] Training loss: 1.228\t Validation loss: 1.277\n",
      "[30] Training loss: 1.220\t Validation loss: 1.271\n",
      "[31] Training loss: 1.212\t Validation loss: 1.260\n",
      "[32] Training loss: 1.199\t Validation loss: 1.242\n",
      "[33] Training loss: 1.179\t Validation loss: 1.219\n",
      "[34] Training loss: 1.154\t Validation loss: 1.195\n",
      "[35] Training loss: 1.128\t Validation loss: 1.175\n",
      "[36] Training loss: 1.106\t Validation loss: 1.159\n",
      "[37] Training loss: 1.090\t Validation loss: 1.146\n",
      "[38] Training loss: 1.076\t Validation loss: 1.132\n",
      "[39] Training loss: 1.062\t Validation loss: 1.116\n",
      "[40] Training loss: 1.046\t Validation loss: 1.098\n",
      "[41] Training loss: 1.027\t Validation loss: 1.080\n",
      "[42] Training loss: 1.008\t Validation loss: 1.065\n",
      "[43] Training loss: 0.992\t Validation loss: 1.052\n",
      "[44] Training loss: 0.978\t Validation loss: 1.040\n",
      "[45] Training loss: 0.966\t Validation loss: 1.028\n",
      "[46] Training loss: 0.952\t Validation loss: 1.014\n",
      "[47] Training loss: 0.937\t Validation loss: 0.999\n",
      "[48] Training loss: 0.920\t Validation loss: 0.984\n",
      "[49] Training loss: 0.903\t Validation loss: 0.971\n",
      "[50] Training loss: 0.888\t Validation loss: 0.959\n",
      "[1] Training loss: 5.450\t Validation loss: 4.596\n",
      "[2] Training loss: 4.851\t Validation loss: 3.860\n",
      "[3] Training loss: 4.063\t Validation loss: 2.974\n",
      "[4] Training loss: 3.119\t Validation loss: 2.175\n",
      "[5] Training loss: 2.271\t Validation loss: 1.788\n",
      "[6] Training loss: 1.862\t Validation loss: 1.907\n",
      "[7] Training loss: 1.990\t Validation loss: 2.108\n",
      "[8] Training loss: 2.198\t Validation loss: 2.058\n",
      "[9] Training loss: 2.138\t Validation loss: 1.831\n",
      "[10] Training loss: 1.888\t Validation loss: 1.617\n",
      "[11] Training loss: 1.655\t Validation loss: 1.524\n",
      "[12] Training loss: 1.552\t Validation loss: 1.546\n",
      "[13] Training loss: 1.571\t Validation loss: 1.617\n",
      "[14] Training loss: 1.645\t Validation loss: 1.682\n",
      "[15] Training loss: 1.712\t Validation loss: 1.709\n",
      "[16] Training loss: 1.740\t Validation loss: 1.690\n",
      "[17] Training loss: 1.718\t Validation loss: 1.631\n",
      "[18] Training loss: 1.655\t Validation loss: 1.550\n",
      "[19] Training loss: 1.568\t Validation loss: 1.468\n",
      "[20] Training loss: 1.482\t Validation loss: 1.408\n",
      "[21] Training loss: 1.417\t Validation loss: 1.379\n",
      "[22] Training loss: 1.387\t Validation loss: 1.380\n",
      "[23] Training loss: 1.388\t Validation loss: 1.392\n",
      "[24] Training loss: 1.401\t Validation loss: 1.395\n",
      "[25] Training loss: 1.404\t Validation loss: 1.377\n",
      "[26] Training loss: 1.385\t Validation loss: 1.343\n",
      "[27] Training loss: 1.348\t Validation loss: 1.306\n",
      "[28] Training loss: 1.308\t Validation loss: 1.279\n",
      "[29] Training loss: 1.278\t Validation loss: 1.264\n",
      "[30] Training loss: 1.260\t Validation loss: 1.256\n",
      "[31] Training loss: 1.250\t Validation loss: 1.249\n",
      "[32] Training loss: 1.239\t Validation loss: 1.237\n",
      "[33] Training loss: 1.223\t Validation loss: 1.220\n",
      "[34] Training loss: 1.202\t Validation loss: 1.201\n",
      "[35] Training loss: 1.178\t Validation loss: 1.179\n",
      "[36] Training loss: 1.151\t Validation loss: 1.156\n",
      "[37] Training loss: 1.125\t Validation loss: 1.138\n",
      "[38] Training loss: 1.103\t Validation loss: 1.125\n",
      "[39] Training loss: 1.088\t Validation loss: 1.115\n",
      "[40] Training loss: 1.076\t Validation loss: 1.104\n",
      "[41] Training loss: 1.064\t Validation loss: 1.088\n",
      "[42] Training loss: 1.046\t Validation loss: 1.067\n",
      "[43] Training loss: 1.023\t Validation loss: 1.044\n",
      "[44] Training loss: 0.999\t Validation loss: 1.023\n",
      "[45] Training loss: 0.977\t Validation loss: 1.008\n",
      "[46] Training loss: 0.960\t Validation loss: 0.995\n",
      "[47] Training loss: 0.946\t Validation loss: 0.981\n",
      "[48] Training loss: 0.931\t Validation loss: 0.965\n",
      "[49] Training loss: 0.914\t Validation loss: 0.948\n",
      "[50] Training loss: 0.894\t Validation loss: 0.931\n",
      "[1] Training loss: 5.369\t Validation loss: 4.659\n",
      "[2] Training loss: 4.666\t Validation loss: 3.810\n",
      "[3] Training loss: 3.809\t Validation loss: 2.910\n",
      "[4] Training loss: 2.901\t Validation loss: 2.260\n",
      "[5] Training loss: 2.240\t Validation loss: 2.089\n",
      "[6] Training loss: 2.060\t Validation loss: 2.111\n",
      "[7] Training loss: 2.080\t Validation loss: 2.035\n",
      "[8] Training loss: 2.005\t Validation loss: 1.844\n",
      "[9] Training loss: 1.817\t Validation loss: 1.659\n",
      "[10] Training loss: 1.637\t Validation loss: 1.584\n",
      "[11] Training loss: 1.566\t Validation loss: 1.623\n",
      "[12] Training loss: 1.609\t Validation loss: 1.705\n",
      "[13] Training loss: 1.693\t Validation loss: 1.761\n",
      "[14] Training loss: 1.747\t Validation loss: 1.762\n",
      "[15] Training loss: 1.747\t Validation loss: 1.713\n",
      "[16] Training loss: 1.695\t Validation loss: 1.633\n",
      "[17] Training loss: 1.612\t Validation loss: 1.548\n",
      "[18] Training loss: 1.523\t Validation loss: 1.481\n",
      "[19] Training loss: 1.452\t Validation loss: 1.446\n",
      "[20] Training loss: 1.411\t Validation loss: 1.437\n",
      "[21] Training loss: 1.397\t Validation loss: 1.437\n",
      "[22] Training loss: 1.392\t Validation loss: 1.426\n",
      "[23] Training loss: 1.378\t Validation loss: 1.400\n",
      "[24] Training loss: 1.348\t Validation loss: 1.368\n",
      "[25] Training loss: 1.313\t Validation loss: 1.344\n",
      "[26] Training loss: 1.286\t Validation loss: 1.334\n",
      "[27] Training loss: 1.273\t Validation loss: 1.334\n",
      "[28] Training loss: 1.270\t Validation loss: 1.333\n",
      "[29] Training loss: 1.266\t Validation loss: 1.320\n",
      "[30] Training loss: 1.252\t Validation loss: 1.296\n",
      "[31] Training loss: 1.225\t Validation loss: 1.263\n",
      "[32] Training loss: 1.191\t Validation loss: 1.232\n",
      "[33] Training loss: 1.158\t Validation loss: 1.208\n",
      "[34] Training loss: 1.133\t Validation loss: 1.192\n",
      "[35] Training loss: 1.116\t Validation loss: 1.179\n",
      "[36] Training loss: 1.101\t Validation loss: 1.163\n",
      "[37] Training loss: 1.084\t Validation loss: 1.143\n",
      "[38] Training loss: 1.062\t Validation loss: 1.122\n",
      "[39] Training loss: 1.040\t Validation loss: 1.104\n",
      "[40] Training loss: 1.020\t Validation loss: 1.090\n",
      "[41] Training loss: 1.004\t Validation loss: 1.076\n",
      "[42] Training loss: 0.988\t Validation loss: 1.059\n",
      "[43] Training loss: 0.970\t Validation loss: 1.040\n",
      "[44] Training loss: 0.949\t Validation loss: 1.021\n",
      "[45] Training loss: 0.928\t Validation loss: 1.004\n",
      "[46] Training loss: 0.909\t Validation loss: 0.989\n",
      "[47] Training loss: 0.893\t Validation loss: 0.975\n",
      "[48] Training loss: 0.878\t Validation loss: 0.960\n",
      "[49] Training loss: 0.861\t Validation loss: 0.943\n",
      "[50] Training loss: 0.844\t Validation loss: 0.927\n",
      "1357 Samples\n",
      "\n",
      "[1] Training loss: 5.047\t Validation loss: 4.808\n",
      "[2] Training loss: 4.730\t Validation loss: 4.451\n",
      "[3] Training loss: 4.374\t Validation loss: 4.077\n",
      "[4] Training loss: 4.000\t Validation loss: 3.703\n",
      "[5] Training loss: 3.626\t Validation loss: 3.351\n",
      "[6] Training loss: 3.274\t Validation loss: 3.042\n",
      "[7] Training loss: 2.964\t Validation loss: 2.790\n",
      "[8] Training loss: 2.712\t Validation loss: 2.590\n",
      "[9] Training loss: 2.515\t Validation loss: 2.423\n",
      "[10] Training loss: 2.351\t Validation loss: 2.277\n",
      "[11] Training loss: 2.208\t Validation loss: 2.152\n",
      "[12] Training loss: 2.089\t Validation loss: 2.048\n",
      "[13] Training loss: 1.993\t Validation loss: 1.962\n",
      "[14] Training loss: 1.913\t Validation loss: 1.885\n",
      "[15] Training loss: 1.841\t Validation loss: 1.810\n",
      "[16] Training loss: 1.769\t Validation loss: 1.737\n",
      "[17] Training loss: 1.697\t Validation loss: 1.672\n",
      "[18] Training loss: 1.631\t Validation loss: 1.620\n",
      "[19] Training loss: 1.578\t Validation loss: 1.585\n",
      "[20] Training loss: 1.540\t Validation loss: 1.562\n",
      "[21] Training loss: 1.514\t Validation loss: 1.549\n",
      "[22] Training loss: 1.497\t Validation loss: 1.540\n",
      "[23] Training loss: 1.485\t Validation loss: 1.532\n",
      "[24] Training loss: 1.476\t Validation loss: 1.525\n",
      "[25] Training loss: 1.467\t Validation loss: 1.517\n",
      "[26] Training loss: 1.458\t Validation loss: 1.511\n",
      "[27] Training loss: 1.451\t Validation loss: 1.506\n",
      "[28] Training loss: 1.446\t Validation loss: 1.503\n",
      "[29] Training loss: 1.443\t Validation loss: 1.501\n",
      "[30] Training loss: 1.441\t Validation loss: 1.500\n",
      "[31] Training loss: 1.440\t Validation loss: 1.497\n",
      "[32] Training loss: 1.436\t Validation loss: 1.490\n",
      "[33] Training loss: 1.430\t Validation loss: 1.480\n",
      "[34] Training loss: 1.419\t Validation loss: 1.467\n",
      "[35] Training loss: 1.406\t Validation loss: 1.454\n",
      "[36] Training loss: 1.391\t Validation loss: 1.441\n",
      "[37] Training loss: 1.378\t Validation loss: 1.431\n",
      "[38] Training loss: 1.367\t Validation loss: 1.424\n",
      "[39] Training loss: 1.360\t Validation loss: 1.420\n",
      "[40] Training loss: 1.355\t Validation loss: 1.418\n",
      "[41] Training loss: 1.353\t Validation loss: 1.416\n",
      "[42] Training loss: 1.352\t Validation loss: 1.414\n",
      "[43] Training loss: 1.350\t Validation loss: 1.412\n",
      "[44] Training loss: 1.347\t Validation loss: 1.408\n",
      "[45] Training loss: 1.343\t Validation loss: 1.403\n",
      "[46] Training loss: 1.339\t Validation loss: 1.399\n",
      "[47] Training loss: 1.335\t Validation loss: 1.395\n",
      "[48] Training loss: 1.332\t Validation loss: 1.392\n",
      "[49] Training loss: 1.329\t Validation loss: 1.390\n",
      "[50] Training loss: 1.326\t Validation loss: 1.388\n",
      "[1] Training loss: 5.505\t Validation loss: 5.077\n",
      "[2] Training loss: 5.100\t Validation loss: 4.595\n",
      "[3] Training loss: 4.617\t Validation loss: 4.091\n",
      "[4] Training loss: 4.114\t Validation loss: 3.624\n",
      "[5] Training loss: 3.649\t Validation loss: 3.251\n",
      "[6] Training loss: 3.278\t Validation loss: 2.993\n",
      "[7] Training loss: 3.021\t Validation loss: 2.797\n",
      "[8] Training loss: 2.822\t Validation loss: 2.606\n",
      "[9] Training loss: 2.623\t Validation loss: 2.401\n",
      "[10] Training loss: 2.406\t Validation loss: 2.190\n",
      "[11] Training loss: 2.181\t Validation loss: 1.993\n",
      "[12] Training loss: 1.969\t Validation loss: 1.827\n",
      "[13] Training loss: 1.787\t Validation loss: 1.700\n",
      "[14] Training loss: 1.645\t Validation loss: 1.614\n",
      "[15] Training loss: 1.545\t Validation loss: 1.565\n",
      "[16] Training loss: 1.485\t Validation loss: 1.546\n",
      "[17] Training loss: 1.456\t Validation loss: 1.548\n",
      "[18] Training loss: 1.450\t Validation loss: 1.560\n",
      "[19] Training loss: 1.457\t Validation loss: 1.574\n",
      "[20] Training loss: 1.467\t Validation loss: 1.583\n",
      "[21] Training loss: 1.474\t Validation loss: 1.585\n",
      "[22] Training loss: 1.476\t Validation loss: 1.582\n",
      "[23] Training loss: 1.472\t Validation loss: 1.574\n",
      "[24] Training loss: 1.465\t Validation loss: 1.563\n",
      "[25] Training loss: 1.455\t Validation loss: 1.550\n",
      "[26] Training loss: 1.442\t Validation loss: 1.535\n",
      "[27] Training loss: 1.426\t Validation loss: 1.517\n",
      "[28] Training loss: 1.407\t Validation loss: 1.497\n",
      "[29] Training loss: 1.386\t Validation loss: 1.475\n",
      "[30] Training loss: 1.364\t Validation loss: 1.455\n",
      "[31] Training loss: 1.343\t Validation loss: 1.438\n",
      "[32] Training loss: 1.325\t Validation loss: 1.424\n",
      "[33] Training loss: 1.310\t Validation loss: 1.413\n",
      "[34] Training loss: 1.297\t Validation loss: 1.403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35] Training loss: 1.286\t Validation loss: 1.393\n",
      "[36] Training loss: 1.275\t Validation loss: 1.382\n",
      "[37] Training loss: 1.263\t Validation loss: 1.373\n",
      "[38] Training loss: 1.251\t Validation loss: 1.366\n",
      "[39] Training loss: 1.243\t Validation loss: 1.361\n",
      "[40] Training loss: 1.236\t Validation loss: 1.357\n",
      "[41] Training loss: 1.230\t Validation loss: 1.351\n",
      "[42] Training loss: 1.221\t Validation loss: 1.343\n",
      "[43] Training loss: 1.211\t Validation loss: 1.336\n",
      "[44] Training loss: 1.201\t Validation loss: 1.330\n",
      "[45] Training loss: 1.193\t Validation loss: 1.325\n",
      "[46] Training loss: 1.186\t Validation loss: 1.321\n",
      "[47] Training loss: 1.180\t Validation loss: 1.316\n",
      "[48] Training loss: 1.173\t Validation loss: 1.310\n",
      "[49] Training loss: 1.165\t Validation loss: 1.305\n",
      "[50] Training loss: 1.158\t Validation loss: 1.300\n",
      "[1] Training loss: 5.193\t Validation loss: 4.591\n",
      "[2] Training loss: 4.636\t Validation loss: 3.904\n",
      "[3] Training loss: 3.956\t Validation loss: 3.220\n",
      "[4] Training loss: 3.278\t Validation loss: 2.668\n",
      "[5] Training loss: 2.726\t Validation loss: 2.304\n",
      "[6] Training loss: 2.353\t Validation loss: 2.088\n",
      "[7] Training loss: 2.117\t Validation loss: 1.940\n",
      "[8] Training loss: 1.947\t Validation loss: 1.820\n",
      "[9] Training loss: 1.807\t Validation loss: 1.727\n",
      "[10] Training loss: 1.696\t Validation loss: 1.678\n",
      "[11] Training loss: 1.633\t Validation loss: 1.674\n",
      "[12] Training loss: 1.620\t Validation loss: 1.692\n",
      "[13] Training loss: 1.632\t Validation loss: 1.703\n",
      "[14] Training loss: 1.639\t Validation loss: 1.692\n",
      "[15] Training loss: 1.626\t Validation loss: 1.662\n",
      "[16] Training loss: 1.594\t Validation loss: 1.619\n",
      "[17] Training loss: 1.550\t Validation loss: 1.570\n",
      "[18] Training loss: 1.501\t Validation loss: 1.522\n",
      "[19] Training loss: 1.452\t Validation loss: 1.479\n",
      "[20] Training loss: 1.406\t Validation loss: 1.442\n",
      "[21] Training loss: 1.367\t Validation loss: 1.413\n",
      "[22] Training loss: 1.335\t Validation loss: 1.389\n",
      "[23] Training loss: 1.307\t Validation loss: 1.369\n",
      "[24] Training loss: 1.284\t Validation loss: 1.352\n",
      "[25] Training loss: 1.263\t Validation loss: 1.338\n",
      "[26] Training loss: 1.244\t Validation loss: 1.323\n",
      "[27] Training loss: 1.225\t Validation loss: 1.308\n",
      "[28] Training loss: 1.204\t Validation loss: 1.292\n",
      "[29] Training loss: 1.182\t Validation loss: 1.277\n",
      "[30] Training loss: 1.161\t Validation loss: 1.262\n",
      "[31] Training loss: 1.141\t Validation loss: 1.249\n",
      "[32] Training loss: 1.123\t Validation loss: 1.238\n",
      "[33] Training loss: 1.108\t Validation loss: 1.229\n",
      "[34] Training loss: 1.096\t Validation loss: 1.221\n",
      "[35] Training loss: 1.084\t Validation loss: 1.213\n",
      "[36] Training loss: 1.072\t Validation loss: 1.202\n",
      "[37] Training loss: 1.059\t Validation loss: 1.190\n",
      "[38] Training loss: 1.044\t Validation loss: 1.177\n",
      "[39] Training loss: 1.029\t Validation loss: 1.165\n",
      "[40] Training loss: 1.015\t Validation loss: 1.153\n",
      "[41] Training loss: 1.002\t Validation loss: 1.141\n",
      "[42] Training loss: 0.989\t Validation loss: 1.129\n",
      "[43] Training loss: 0.977\t Validation loss: 1.118\n",
      "[44] Training loss: 0.965\t Validation loss: 1.107\n",
      "[45] Training loss: 0.954\t Validation loss: 1.097\n",
      "[46] Training loss: 0.944\t Validation loss: 1.087\n",
      "[47] Training loss: 0.933\t Validation loss: 1.078\n",
      "[48] Training loss: 0.923\t Validation loss: 1.069\n",
      "[49] Training loss: 0.913\t Validation loss: 1.060\n",
      "[50] Training loss: 0.903\t Validation loss: 1.051\n",
      "[1] Training loss: 5.471\t Validation loss: 5.037\n",
      "[2] Training loss: 5.167\t Validation loss: 4.666\n",
      "[3] Training loss: 4.786\t Validation loss: 4.184\n",
      "[4] Training loss: 4.293\t Validation loss: 3.638\n",
      "[5] Training loss: 3.736\t Validation loss: 3.104\n",
      "[6] Training loss: 3.189\t Validation loss: 2.673\n",
      "[7] Training loss: 2.746\t Validation loss: 2.423\n",
      "[8] Training loss: 2.483\t Validation loss: 2.308\n",
      "[9] Training loss: 2.352\t Validation loss: 2.205\n",
      "[10] Training loss: 2.231\t Validation loss: 2.061\n",
      "[11] Training loss: 2.068\t Validation loss: 1.886\n",
      "[12] Training loss: 1.878\t Validation loss: 1.722\n",
      "[13] Training loss: 1.701\t Validation loss: 1.605\n",
      "[14] Training loss: 1.575\t Validation loss: 1.548\n",
      "[15] Training loss: 1.509\t Validation loss: 1.536\n",
      "[16] Training loss: 1.489\t Validation loss: 1.543\n",
      "[17] Training loss: 1.488\t Validation loss: 1.551\n",
      "[18] Training loss: 1.487\t Validation loss: 1.548\n",
      "[19] Training loss: 1.476\t Validation loss: 1.536\n",
      "[20] Training loss: 1.457\t Validation loss: 1.520\n",
      "[21] Training loss: 1.434\t Validation loss: 1.506\n",
      "[22] Training loss: 1.413\t Validation loss: 1.497\n",
      "[23] Training loss: 1.399\t Validation loss: 1.490\n",
      "[24] Training loss: 1.388\t Validation loss: 1.479\n",
      "[25] Training loss: 1.374\t Validation loss: 1.461\n",
      "[26] Training loss: 1.354\t Validation loss: 1.435\n",
      "[27] Training loss: 1.328\t Validation loss: 1.406\n",
      "[28] Training loss: 1.298\t Validation loss: 1.378\n",
      "[29] Training loss: 1.269\t Validation loss: 1.354\n",
      "[30] Training loss: 1.243\t Validation loss: 1.333\n",
      "[31] Training loss: 1.221\t Validation loss: 1.315\n",
      "[32] Training loss: 1.201\t Validation loss: 1.297\n",
      "[33] Training loss: 1.182\t Validation loss: 1.281\n",
      "[34] Training loss: 1.164\t Validation loss: 1.266\n",
      "[35] Training loss: 1.148\t Validation loss: 1.255\n",
      "[36] Training loss: 1.136\t Validation loss: 1.246\n",
      "[37] Training loss: 1.126\t Validation loss: 1.239\n",
      "[38] Training loss: 1.117\t Validation loss: 1.230\n",
      "[39] Training loss: 1.107\t Validation loss: 1.221\n",
      "[40] Training loss: 1.095\t Validation loss: 1.213\n",
      "[41] Training loss: 1.084\t Validation loss: 1.205\n",
      "[42] Training loss: 1.073\t Validation loss: 1.199\n",
      "[43] Training loss: 1.064\t Validation loss: 1.194\n",
      "[44] Training loss: 1.055\t Validation loss: 1.189\n",
      "[45] Training loss: 1.046\t Validation loss: 1.184\n",
      "[46] Training loss: 1.037\t Validation loss: 1.178\n",
      "[47] Training loss: 1.028\t Validation loss: 1.171\n",
      "[48] Training loss: 1.019\t Validation loss: 1.165\n",
      "[49] Training loss: 1.009\t Validation loss: 1.157\n",
      "[50] Training loss: 1.000\t Validation loss: 1.149\n",
      "[1] Training loss: 5.693\t Validation loss: 4.772\n",
      "[2] Training loss: 4.935\t Validation loss: 3.917\n",
      "[3] Training loss: 4.044\t Validation loss: 3.053\n",
      "[4] Training loss: 3.144\t Validation loss: 2.407\n",
      "[5] Training loss: 2.472\t Validation loss: 2.145\n",
      "[6] Training loss: 2.198\t Validation loss: 2.122\n",
      "[7] Training loss: 2.165\t Validation loss: 2.094\n",
      "[8] Training loss: 2.122\t Validation loss: 1.967\n",
      "[9] Training loss: 1.973\t Validation loss: 1.786\n",
      "[10] Training loss: 1.770\t Validation loss: 1.638\n",
      "[11] Training loss: 1.606\t Validation loss: 1.579\n",
      "[12] Training loss: 1.538\t Validation loss: 1.601\n",
      "[13] Training loss: 1.558\t Validation loss: 1.657\n",
      "[14] Training loss: 1.614\t Validation loss: 1.706\n",
      "[15] Training loss: 1.662\t Validation loss: 1.727\n",
      "[16] Training loss: 1.681\t Validation loss: 1.714\n",
      "[17] Training loss: 1.666\t Validation loss: 1.674\n",
      "[18] Training loss: 1.621\t Validation loss: 1.615\n",
      "[19] Training loss: 1.558\t Validation loss: 1.552\n",
      "[20] Training loss: 1.489\t Validation loss: 1.498\n",
      "[21] Training loss: 1.430\t Validation loss: 1.461\n",
      "[22] Training loss: 1.388\t Validation loss: 1.440\n",
      "[23] Training loss: 1.364\t Validation loss: 1.430\n",
      "[24] Training loss: 1.350\t Validation loss: 1.419\n",
      "[25] Training loss: 1.337\t Validation loss: 1.404\n",
      "[26] Training loss: 1.318\t Validation loss: 1.384\n",
      "[27] Training loss: 1.295\t Validation loss: 1.364\n",
      "[28] Training loss: 1.273\t Validation loss: 1.351\n",
      "[29] Training loss: 1.255\t Validation loss: 1.346\n",
      "[30] Training loss: 1.245\t Validation loss: 1.344\n",
      "[31] Training loss: 1.239\t Validation loss: 1.343\n",
      "[32] Training loss: 1.232\t Validation loss: 1.337\n",
      "[33] Training loss: 1.221\t Validation loss: 1.324\n",
      "[34] Training loss: 1.204\t Validation loss: 1.307\n",
      "[35] Training loss: 1.182\t Validation loss: 1.289\n",
      "[36] Training loss: 1.159\t Validation loss: 1.273\n",
      "[37] Training loss: 1.139\t Validation loss: 1.261\n",
      "[38] Training loss: 1.122\t Validation loss: 1.252\n",
      "[39] Training loss: 1.109\t Validation loss: 1.244\n",
      "[40] Training loss: 1.097\t Validation loss: 1.233\n",
      "[41] Training loss: 1.084\t Validation loss: 1.220\n",
      "[42] Training loss: 1.068\t Validation loss: 1.207\n",
      "[43] Training loss: 1.052\t Validation loss: 1.195\n",
      "[44] Training loss: 1.038\t Validation loss: 1.184\n",
      "[45] Training loss: 1.025\t Validation loss: 1.176\n",
      "[46] Training loss: 1.015\t Validation loss: 1.167\n",
      "[47] Training loss: 1.004\t Validation loss: 1.158\n",
      "[48] Training loss: 0.993\t Validation loss: 1.147\n",
      "[49] Training loss: 0.980\t Validation loss: 1.135\n",
      "[50] Training loss: 0.966\t Validation loss: 1.124\n",
      "[1] Training loss: 5.367\t Validation loss: 4.888\n",
      "[2] Training loss: 4.880\t Validation loss: 4.280\n",
      "[3] Training loss: 4.273\t Validation loss: 3.545\n",
      "[4] Training loss: 3.541\t Validation loss: 2.828\n",
      "[5] Training loss: 2.831\t Validation loss: 2.311\n",
      "[6] Training loss: 2.317\t Validation loss: 2.075\n",
      "[7] Training loss: 2.081\t Validation loss: 2.006\n",
      "[8] Training loss: 2.012\t Validation loss: 1.957\n",
      "[9] Training loss: 1.966\t Validation loss: 1.865\n",
      "[10] Training loss: 1.878\t Validation loss: 1.739\n",
      "[11] Training loss: 1.755\t Validation loss: 1.632\n",
      "[12] Training loss: 1.648\t Validation loss: 1.586\n",
      "[13] Training loss: 1.597\t Validation loss: 1.599\n",
      "[14] Training loss: 1.603\t Validation loss: 1.640\n",
      "[15] Training loss: 1.635\t Validation loss: 1.674\n",
      "[16] Training loss: 1.659\t Validation loss: 1.680\n",
      "[17] Training loss: 1.656\t Validation loss: 1.656\n",
      "[18] Training loss: 1.623\t Validation loss: 1.610\n",
      "[19] Training loss: 1.569\t Validation loss: 1.555\n",
      "[20] Training loss: 1.507\t Validation loss: 1.504\n",
      "[21] Training loss: 1.450\t Validation loss: 1.469\n",
      "[22] Training loss: 1.408\t Validation loss: 1.449\n",
      "[23] Training loss: 1.383\t Validation loss: 1.437\n",
      "[24] Training loss: 1.366\t Validation loss: 1.424\n",
      "[25] Training loss: 1.348\t Validation loss: 1.401\n",
      "[26] Training loss: 1.321\t Validation loss: 1.370\n",
      "[27] Training loss: 1.285\t Validation loss: 1.338\n",
      "[28] Training loss: 1.248\t Validation loss: 1.313\n",
      "[29] Training loss: 1.218\t Validation loss: 1.299\n",
      "[30] Training loss: 1.198\t Validation loss: 1.296\n",
      "[31] Training loss: 1.187\t Validation loss: 1.295\n",
      "[32] Training loss: 1.180\t Validation loss: 1.290\n",
      "[33] Training loss: 1.169\t Validation loss: 1.277\n",
      "[34] Training loss: 1.151\t Validation loss: 1.256\n",
      "[35] Training loss: 1.126\t Validation loss: 1.231\n",
      "[36] Training loss: 1.097\t Validation loss: 1.205\n",
      "[37] Training loss: 1.069\t Validation loss: 1.185\n",
      "[38] Training loss: 1.046\t Validation loss: 1.171\n",
      "[39] Training loss: 1.029\t Validation loss: 1.162\n",
      "[40] Training loss: 1.016\t Validation loss: 1.153\n",
      "[41] Training loss: 1.003\t Validation loss: 1.143\n",
      "[42] Training loss: 0.989\t Validation loss: 1.130\n",
      "[43] Training loss: 0.973\t Validation loss: 1.118\n",
      "[44] Training loss: 0.957\t Validation loss: 1.105\n",
      "[45] Training loss: 0.941\t Validation loss: 1.094\n",
      "[46] Training loss: 0.927\t Validation loss: 1.084\n",
      "[47] Training loss: 0.913\t Validation loss: 1.074\n",
      "[48] Training loss: 0.900\t Validation loss: 1.063\n",
      "[49] Training loss: 0.886\t Validation loss: 1.052\n",
      "[50] Training loss: 0.872\t Validation loss: 1.041\n",
      "[1] Training loss: 4.934\t Validation loss: 4.631\n",
      "[2] Training loss: 4.279\t Validation loss: 3.676\n",
      "[3] Training loss: 3.409\t Validation loss: 2.728\n",
      "[4] Training loss: 2.547\t Validation loss: 2.177\n",
      "[5] Training loss: 2.047\t Validation loss: 2.138\n",
      "[6] Training loss: 1.999\t Validation loss: 2.159\n",
      "[7] Training loss: 1.995\t Validation loss: 1.985\n",
      "[8] Training loss: 1.812\t Validation loss: 1.731\n",
      "[9] Training loss: 1.560\t Validation loss: 1.565\n",
      "[10] Training loss: 1.392\t Validation loss: 1.546\n",
      "[11] Training loss: 1.362\t Validation loss: 1.618\n",
      "[12] Training loss: 1.418\t Validation loss: 1.695\n",
      "[13] Training loss: 1.479\t Validation loss: 1.724\n",
      "[14] Training loss: 1.497\t Validation loss: 1.694\n",
      "[15] Training loss: 1.461\t Validation loss: 1.618\n",
      "[16] Training loss: 1.385\t Validation loss: 1.525\n",
      "[17] Training loss: 1.293\t Validation loss: 1.441\n",
      "[18] Training loss: 1.211\t Validation loss: 1.383\n",
      "[19] Training loss: 1.153\t Validation loss: 1.348\n",
      "[20] Training loss: 1.116\t Validation loss: 1.316\n",
      "[21] Training loss: 1.082\t Validation loss: 1.274\n",
      "[22] Training loss: 1.038\t Validation loss: 1.224\n",
      "[23] Training loss: 0.986\t Validation loss: 1.181\n",
      "[24] Training loss: 0.940\t Validation loss: 1.158\n",
      "[25] Training loss: 0.911\t Validation loss: 1.154\n",
      "[26] Training loss: 0.899\t Validation loss: 1.157\n",
      "[27] Training loss: 0.894\t Validation loss: 1.154\n",
      "[28] Training loss: 0.883\t Validation loss: 1.136\n",
      "[29] Training loss: 0.860\t Validation loss: 1.105\n",
      "[30] Training loss: 0.825\t Validation loss: 1.068\n",
      "[31] Training loss: 0.786\t Validation loss: 1.034\n",
      "[32] Training loss: 0.750\t Validation loss: 1.008\n",
      "[33] Training loss: 0.722\t Validation loss: 0.989\n",
      "[34] Training loss: 0.699\t Validation loss: 0.973\n",
      "[35] Training loss: 0.681\t Validation loss: 0.959\n",
      "[36] Training loss: 0.662\t Validation loss: 0.944\n",
      "[37] Training loss: 0.644\t Validation loss: 0.930\n",
      "[38] Training loss: 0.626\t Validation loss: 0.917\n",
      "[39] Training loss: 0.610\t Validation loss: 0.904\n",
      "[40] Training loss: 0.595\t Validation loss: 0.888\n",
      "[41] Training loss: 0.578\t Validation loss: 0.869\n",
      "[42] Training loss: 0.559\t Validation loss: 0.848\n",
      "[43] Training loss: 0.539\t Validation loss: 0.827\n",
      "[44] Training loss: 0.520\t Validation loss: 0.810\n",
      "[45] Training loss: 0.505\t Validation loss: 0.796\n",
      "[46] Training loss: 0.491\t Validation loss: 0.785\n",
      "[47] Training loss: 0.479\t Validation loss: 0.774\n",
      "[48] Training loss: 0.466\t Validation loss: 0.763\n",
      "[49] Training loss: 0.452\t Validation loss: 0.752\n",
      "[50] Training loss: 0.439\t Validation loss: 0.740\n",
      "[1] Training loss: 5.191\t Validation loss: 4.563\n",
      "[2] Training loss: 4.501\t Validation loss: 3.629\n",
      "[3] Training loss: 3.585\t Validation loss: 2.647\n",
      "[4] Training loss: 2.624\t Validation loss: 2.021\n",
      "[5] Training loss: 2.016\t Validation loss: 2.012\n",
      "[6] Training loss: 2.007\t Validation loss: 2.145\n",
      "[7] Training loss: 2.121\t Validation loss: 2.034\n",
      "[8] Training loss: 1.985\t Validation loss: 1.777\n",
      "[9] Training loss: 1.705\t Validation loss: 1.589\n",
      "[10] Training loss: 1.497\t Validation loss: 1.557\n",
      "[11] Training loss: 1.448\t Validation loss: 1.632\n",
      "[12] Training loss: 1.507\t Validation loss: 1.720\n",
      "[13] Training loss: 1.583\t Validation loss: 1.762\n",
      "[14] Training loss: 1.616\t Validation loss: 1.740\n",
      "[15] Training loss: 1.587\t Validation loss: 1.665\n",
      "[16] Training loss: 1.507\t Validation loss: 1.565\n",
      "[17] Training loss: 1.402\t Validation loss: 1.471\n",
      "[18] Training loss: 1.305\t Validation loss: 1.409\n",
      "[19] Training loss: 1.241\t Validation loss: 1.387\n",
      "[20] Training loss: 1.216\t Validation loss: 1.387\n",
      "[21] Training loss: 1.215\t Validation loss: 1.382\n",
      "[22] Training loss: 1.207\t Validation loss: 1.354\n",
      "[23] Training loss: 1.177\t Validation loss: 1.309\n",
      "[24] Training loss: 1.127\t Validation loss: 1.264\n",
      "[25] Training loss: 1.078\t Validation loss: 1.235\n",
      "[26] Training loss: 1.042\t Validation loss: 1.223\n",
      "[27] Training loss: 1.023\t Validation loss: 1.219\n",
      "[28] Training loss: 1.012\t Validation loss: 1.211\n",
      "[29] Training loss: 0.996\t Validation loss: 1.193\n",
      "[30] Training loss: 0.970\t Validation loss: 1.166\n",
      "[31] Training loss: 0.937\t Validation loss: 1.137\n",
      "[32] Training loss: 0.902\t Validation loss: 1.114\n",
      "[33] Training loss: 0.874\t Validation loss: 1.099\n",
      "[34] Training loss: 0.854\t Validation loss: 1.089\n",
      "[35] Training loss: 0.841\t Validation loss: 1.077\n",
      "[36] Training loss: 0.825\t Validation loss: 1.059\n",
      "[37] Training loss: 0.804\t Validation loss: 1.037\n",
      "[38] Training loss: 0.779\t Validation loss: 1.016\n",
      "[39] Training loss: 0.756\t Validation loss: 1.001\n",
      "[40] Training loss: 0.737\t Validation loss: 0.988\n",
      "[41] Training loss: 0.723\t Validation loss: 0.976\n",
      "[42] Training loss: 0.708\t Validation loss: 0.960\n",
      "[43] Training loss: 0.691\t Validation loss: 0.942\n",
      "[44] Training loss: 0.672\t Validation loss: 0.924\n",
      "[45] Training loss: 0.652\t Validation loss: 0.908\n",
      "[46] Training loss: 0.635\t Validation loss: 0.894\n",
      "[47] Training loss: 0.619\t Validation loss: 0.881\n",
      "[48] Training loss: 0.604\t Validation loss: 0.868\n",
      "[49] Training loss: 0.589\t Validation loss: 0.854\n",
      "[50] Training loss: 0.572\t Validation loss: 0.841\n",
      "[1] Training loss: 5.428\t Validation loss: 4.682\n",
      "[2] Training loss: 4.716\t Validation loss: 3.818\n",
      "[3] Training loss: 3.845\t Validation loss: 2.874\n",
      "[4] Training loss: 2.896\t Validation loss: 2.143\n",
      "[5] Training loss: 2.165\t Validation loss: 1.917\n",
      "[6] Training loss: 1.940\t Validation loss: 2.095\n",
      "[7] Training loss: 2.119\t Validation loss: 2.195\n",
      "[8] Training loss: 2.215\t Validation loss: 2.033\n",
      "[9] Training loss: 2.042\t Validation loss: 1.765\n",
      "[10] Training loss: 1.761\t Validation loss: 1.578\n",
      "[11] Training loss: 1.562\t Validation loss: 1.537\n",
      "[12] Training loss: 1.510\t Validation loss: 1.602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13] Training loss: 1.565\t Validation loss: 1.697\n",
      "[14] Training loss: 1.650\t Validation loss: 1.761\n",
      "[15] Training loss: 1.705\t Validation loss: 1.766\n",
      "[16] Training loss: 1.702\t Validation loss: 1.715\n",
      "[17] Training loss: 1.643\t Validation loss: 1.627\n",
      "[18] Training loss: 1.549\t Validation loss: 1.536\n",
      "[19] Training loss: 1.452\t Validation loss: 1.469\n",
      "[20] Training loss: 1.380\t Validation loss: 1.437\n",
      "[21] Training loss: 1.345\t Validation loss: 1.428\n",
      "[22] Training loss: 1.331\t Validation loss: 1.418\n",
      "[23] Training loss: 1.316\t Validation loss: 1.396\n",
      "[24] Training loss: 1.287\t Validation loss: 1.365\n",
      "[25] Training loss: 1.250\t Validation loss: 1.339\n",
      "[26] Training loss: 1.217\t Validation loss: 1.325\n",
      "[27] Training loss: 1.196\t Validation loss: 1.321\n",
      "[28] Training loss: 1.185\t Validation loss: 1.318\n",
      "[29] Training loss: 1.175\t Validation loss: 1.308\n",
      "[30] Training loss: 1.158\t Validation loss: 1.285\n",
      "[31] Training loss: 1.129\t Validation loss: 1.254\n",
      "[32] Training loss: 1.092\t Validation loss: 1.221\n",
      "[33] Training loss: 1.053\t Validation loss: 1.194\n",
      "[34] Training loss: 1.021\t Validation loss: 1.178\n",
      "[35] Training loss: 1.001\t Validation loss: 1.169\n",
      "[36] Training loss: 0.988\t Validation loss: 1.160\n",
      "[37] Training loss: 0.975\t Validation loss: 1.144\n",
      "[38] Training loss: 0.954\t Validation loss: 1.123\n",
      "[39] Training loss: 0.929\t Validation loss: 1.103\n",
      "[40] Training loss: 0.903\t Validation loss: 1.086\n",
      "[41] Training loss: 0.882\t Validation loss: 1.073\n",
      "[42] Training loss: 0.863\t Validation loss: 1.059\n",
      "[43] Training loss: 0.845\t Validation loss: 1.042\n",
      "[44] Training loss: 0.825\t Validation loss: 1.022\n",
      "[45] Training loss: 0.802\t Validation loss: 1.001\n",
      "[46] Training loss: 0.779\t Validation loss: 0.983\n",
      "[47] Training loss: 0.758\t Validation loss: 0.967\n",
      "[48] Training loss: 0.741\t Validation loss: 0.953\n",
      "[49] Training loss: 0.725\t Validation loss: 0.938\n",
      "[50] Training loss: 0.707\t Validation loss: 0.922\n",
      "499 Samples\n",
      "\n",
      "[1] Training loss: 5.866\t Validation loss: 5.101\n",
      "[2] Training loss: 5.503\t Validation loss: 4.760\n",
      "[3] Training loss: 5.101\t Validation loss: 4.424\n",
      "[4] Training loss: 4.703\t Validation loss: 4.116\n",
      "[5] Training loss: 4.336\t Validation loss: 3.850\n",
      "[6] Training loss: 4.016\t Validation loss: 3.633\n",
      "[7] Training loss: 3.755\t Validation loss: 3.466\n",
      "[8] Training loss: 3.556\t Validation loss: 3.337\n",
      "[9] Training loss: 3.405\t Validation loss: 3.225\n",
      "[10] Training loss: 3.281\t Validation loss: 3.115\n",
      "[11] Training loss: 3.165\t Validation loss: 2.998\n",
      "[12] Training loss: 3.044\t Validation loss: 2.871\n",
      "[13] Training loss: 2.915\t Validation loss: 2.741\n",
      "[14] Training loss: 2.782\t Validation loss: 2.617\n",
      "[15] Training loss: 2.655\t Validation loss: 2.504\n",
      "[16] Training loss: 2.537\t Validation loss: 2.405\n",
      "[17] Training loss: 2.430\t Validation loss: 2.318\n",
      "[18] Training loss: 2.335\t Validation loss: 2.241\n",
      "[19] Training loss: 2.250\t Validation loss: 2.171\n",
      "[20] Training loss: 2.172\t Validation loss: 2.107\n",
      "[21] Training loss: 2.101\t Validation loss: 2.050\n",
      "[22] Training loss: 2.038\t Validation loss: 1.998\n",
      "[23] Training loss: 1.983\t Validation loss: 1.955\n",
      "[24] Training loss: 1.937\t Validation loss: 1.919\n",
      "[25] Training loss: 1.900\t Validation loss: 1.888\n",
      "[26] Training loss: 1.868\t Validation loss: 1.859\n",
      "[27] Training loss: 1.838\t Validation loss: 1.830\n",
      "[28] Training loss: 1.807\t Validation loss: 1.799\n",
      "[29] Training loss: 1.774\t Validation loss: 1.767\n",
      "[30] Training loss: 1.739\t Validation loss: 1.736\n",
      "[31] Training loss: 1.705\t Validation loss: 1.708\n",
      "[32] Training loss: 1.674\t Validation loss: 1.684\n",
      "[33] Training loss: 1.648\t Validation loss: 1.665\n",
      "[34] Training loss: 1.625\t Validation loss: 1.648\n",
      "[35] Training loss: 1.607\t Validation loss: 1.633\n",
      "[36] Training loss: 1.590\t Validation loss: 1.620\n",
      "[37] Training loss: 1.575\t Validation loss: 1.608\n",
      "[38] Training loss: 1.561\t Validation loss: 1.596\n",
      "[39] Training loss: 1.548\t Validation loss: 1.585\n",
      "[40] Training loss: 1.535\t Validation loss: 1.576\n",
      "[41] Training loss: 1.523\t Validation loss: 1.567\n",
      "[42] Training loss: 1.512\t Validation loss: 1.559\n",
      "[43] Training loss: 1.502\t Validation loss: 1.553\n",
      "[44] Training loss: 1.492\t Validation loss: 1.547\n",
      "[45] Training loss: 1.483\t Validation loss: 1.543\n",
      "[46] Training loss: 1.475\t Validation loss: 1.539\n",
      "[47] Training loss: 1.468\t Validation loss: 1.537\n",
      "[48] Training loss: 1.463\t Validation loss: 1.535\n",
      "[49] Training loss: 1.458\t Validation loss: 1.533\n",
      "[50] Training loss: 1.454\t Validation loss: 1.531\n",
      "[1] Training loss: 5.557\t Validation loss: 5.479\n",
      "[2] Training loss: 5.335\t Validation loss: 5.249\n",
      "[3] Training loss: 5.104\t Validation loss: 4.981\n",
      "[4] Training loss: 4.835\t Validation loss: 4.686\n",
      "[5] Training loss: 4.540\t Validation loss: 4.376\n",
      "[6] Training loss: 4.230\t Validation loss: 4.068\n",
      "[7] Training loss: 3.923\t Validation loss: 3.778\n",
      "[8] Training loss: 3.634\t Validation loss: 3.518\n",
      "[9] Training loss: 3.373\t Validation loss: 3.291\n",
      "[10] Training loss: 3.145\t Validation loss: 3.090\n",
      "[11] Training loss: 2.941\t Validation loss: 2.905\n",
      "[12] Training loss: 2.754\t Validation loss: 2.734\n",
      "[13] Training loss: 2.583\t Validation loss: 2.577\n",
      "[14] Training loss: 2.425\t Validation loss: 2.435\n",
      "[15] Training loss: 2.283\t Validation loss: 2.312\n",
      "[16] Training loss: 2.158\t Validation loss: 2.209\n",
      "[17] Training loss: 2.051\t Validation loss: 2.123\n",
      "[18] Training loss: 1.960\t Validation loss: 2.049\n",
      "[19] Training loss: 1.882\t Validation loss: 1.984\n",
      "[20] Training loss: 1.812\t Validation loss: 1.923\n",
      "[21] Training loss: 1.747\t Validation loss: 1.865\n",
      "[22] Training loss: 1.687\t Validation loss: 1.811\n",
      "[23] Training loss: 1.631\t Validation loss: 1.764\n",
      "[24] Training loss: 1.582\t Validation loss: 1.724\n",
      "[25] Training loss: 1.540\t Validation loss: 1.692\n",
      "[26] Training loss: 1.505\t Validation loss: 1.666\n",
      "[27] Training loss: 1.475\t Validation loss: 1.646\n",
      "[28] Training loss: 1.451\t Validation loss: 1.629\n",
      "[29] Training loss: 1.430\t Validation loss: 1.616\n",
      "[30] Training loss: 1.412\t Validation loss: 1.605\n",
      "[31] Training loss: 1.396\t Validation loss: 1.596\n",
      "[32] Training loss: 1.383\t Validation loss: 1.588\n",
      "[33] Training loss: 1.371\t Validation loss: 1.580\n",
      "[34] Training loss: 1.361\t Validation loss: 1.572\n",
      "[35] Training loss: 1.351\t Validation loss: 1.563\n",
      "[36] Training loss: 1.342\t Validation loss: 1.554\n",
      "[37] Training loss: 1.333\t Validation loss: 1.545\n",
      "[38] Training loss: 1.324\t Validation loss: 1.536\n",
      "[39] Training loss: 1.316\t Validation loss: 1.529\n",
      "[40] Training loss: 1.309\t Validation loss: 1.524\n",
      "[41] Training loss: 1.303\t Validation loss: 1.519\n",
      "[42] Training loss: 1.297\t Validation loss: 1.516\n",
      "[43] Training loss: 1.293\t Validation loss: 1.515\n",
      "[44] Training loss: 1.290\t Validation loss: 1.514\n",
      "[45] Training loss: 1.287\t Validation loss: 1.513\n",
      "[46] Training loss: 1.285\t Validation loss: 1.513\n",
      "[47] Training loss: 1.283\t Validation loss: 1.512\n",
      "[48] Training loss: 1.280\t Validation loss: 1.511\n",
      "[49] Training loss: 1.278\t Validation loss: 1.509\n",
      "[50] Training loss: 1.275\t Validation loss: 1.508\n",
      "[1] Training loss: 5.516\t Validation loss: 5.028\n",
      "[2] Training loss: 5.148\t Validation loss: 4.537\n",
      "[3] Training loss: 4.645\t Validation loss: 3.966\n",
      "[4] Training loss: 4.064\t Validation loss: 3.385\n",
      "[5] Training loss: 3.473\t Validation loss: 2.872\n",
      "[6] Training loss: 2.950\t Validation loss: 2.495\n",
      "[7] Training loss: 2.568\t Validation loss: 2.259\n",
      "[8] Training loss: 2.328\t Validation loss: 2.117\n",
      "[9] Training loss: 2.175\t Validation loss: 2.017\n",
      "[10] Training loss: 2.056\t Validation loss: 1.928\n",
      "[11] Training loss: 1.939\t Validation loss: 1.838\n",
      "[12] Training loss: 1.819\t Validation loss: 1.754\n",
      "[13] Training loss: 1.708\t Validation loss: 1.691\n",
      "[14] Training loss: 1.623\t Validation loss: 1.656\n",
      "[15] Training loss: 1.572\t Validation loss: 1.643\n",
      "[16] Training loss: 1.547\t Validation loss: 1.639\n",
      "[17] Training loss: 1.535\t Validation loss: 1.636\n",
      "[18] Training loss: 1.528\t Validation loss: 1.628\n",
      "[19] Training loss: 1.518\t Validation loss: 1.615\n",
      "[20] Training loss: 1.501\t Validation loss: 1.596\n",
      "[21] Training loss: 1.477\t Validation loss: 1.574\n",
      "[22] Training loss: 1.449\t Validation loss: 1.551\n",
      "[23] Training loss: 1.420\t Validation loss: 1.531\n",
      "[24] Training loss: 1.393\t Validation loss: 1.513\n",
      "[25] Training loss: 1.369\t Validation loss: 1.497\n",
      "[26] Training loss: 1.347\t Validation loss: 1.482\n",
      "[27] Training loss: 1.325\t Validation loss: 1.466\n",
      "[28] Training loss: 1.302\t Validation loss: 1.448\n",
      "[29] Training loss: 1.278\t Validation loss: 1.430\n",
      "[30] Training loss: 1.252\t Validation loss: 1.412\n",
      "[31] Training loss: 1.226\t Validation loss: 1.397\n",
      "[32] Training loss: 1.202\t Validation loss: 1.385\n",
      "[33] Training loss: 1.182\t Validation loss: 1.377\n",
      "[34] Training loss: 1.165\t Validation loss: 1.373\n",
      "[35] Training loss: 1.150\t Validation loss: 1.373\n",
      "[36] Training loss: 1.138\t Validation loss: 1.373\n",
      "[37] Training loss: 1.128\t Validation loss: 1.374\n",
      "[38] Training loss: 1.118\t Validation loss: 1.373\n",
      "[39] Training loss: 1.108\t Validation loss: 1.371\n",
      "[40] Training loss: 1.097\t Validation loss: 1.368\n",
      "[41] Training loss: 1.085\t Validation loss: 1.362\n",
      "[42] Training loss: 1.072\t Validation loss: 1.355\n",
      "[43] Training loss: 1.058\t Validation loss: 1.347\n",
      "[44] Training loss: 1.044\t Validation loss: 1.340\n",
      "[45] Training loss: 1.031\t Validation loss: 1.334\n",
      "[46] Training loss: 1.020\t Validation loss: 1.329\n",
      "[47] Training loss: 1.009\t Validation loss: 1.324\n",
      "[48] Training loss: 0.998\t Validation loss: 1.319\n",
      "[49] Training loss: 0.988\t Validation loss: 1.314\n",
      "[50] Training loss: 0.977\t Validation loss: 1.309\n",
      "[1] Training loss: 5.559\t Validation loss: 5.043\n",
      "[2] Training loss: 5.266\t Validation loss: 4.706\n",
      "[3] Training loss: 4.898\t Validation loss: 4.259\n",
      "[4] Training loss: 4.417\t Validation loss: 3.734\n",
      "[5] Training loss: 3.859\t Validation loss: 3.199\n",
      "[6] Training loss: 3.291\t Validation loss: 2.736\n",
      "[7] Training loss: 2.801\t Validation loss: 2.420\n",
      "[8] Training loss: 2.465\t Validation loss: 2.268\n",
      "[9] Training loss: 2.299\t Validation loss: 2.199\n",
      "[10] Training loss: 2.215\t Validation loss: 2.114\n",
      "[11] Training loss: 2.108\t Validation loss: 1.975\n",
      "[12] Training loss: 1.941\t Validation loss: 1.810\n",
      "[13] Training loss: 1.745\t Validation loss: 1.668\n",
      "[14] Training loss: 1.570\t Validation loss: 1.579\n",
      "[15] Training loss: 1.453\t Validation loss: 1.549\n",
      "[16] Training loss: 1.398\t Validation loss: 1.559\n",
      "[17] Training loss: 1.387\t Validation loss: 1.586\n",
      "[18] Training loss: 1.395\t Validation loss: 1.608\n",
      "[19] Training loss: 1.401\t Validation loss: 1.616\n",
      "[20] Training loss: 1.394\t Validation loss: 1.609\n",
      "[21] Training loss: 1.372\t Validation loss: 1.593\n",
      "[22] Training loss: 1.343\t Validation loss: 1.575\n",
      "[23] Training loss: 1.315\t Validation loss: 1.560\n",
      "[24] Training loss: 1.291\t Validation loss: 1.550\n",
      "[25] Training loss: 1.272\t Validation loss: 1.540\n",
      "[26] Training loss: 1.253\t Validation loss: 1.525\n",
      "[27] Training loss: 1.229\t Validation loss: 1.505\n",
      "[28] Training loss: 1.199\t Validation loss: 1.481\n",
      "[29] Training loss: 1.165\t Validation loss: 1.458\n",
      "[30] Training loss: 1.132\t Validation loss: 1.440\n",
      "[31] Training loss: 1.104\t Validation loss: 1.428\n",
      "[32] Training loss: 1.082\t Validation loss: 1.421\n",
      "[33] Training loss: 1.065\t Validation loss: 1.414\n",
      "[34] Training loss: 1.050\t Validation loss: 1.405\n",
      "[35] Training loss: 1.035\t Validation loss: 1.394\n",
      "[36] Training loss: 1.017\t Validation loss: 1.382\n",
      "[37] Training loss: 1.000\t Validation loss: 1.370\n",
      "[38] Training loss: 0.985\t Validation loss: 1.359\n",
      "[39] Training loss: 0.972\t Validation loss: 1.352\n",
      "[40] Training loss: 0.961\t Validation loss: 1.345\n",
      "[41] Training loss: 0.952\t Validation loss: 1.339\n",
      "[42] Training loss: 0.943\t Validation loss: 1.332\n",
      "[43] Training loss: 0.933\t Validation loss: 1.326\n",
      "[44] Training loss: 0.923\t Validation loss: 1.321\n",
      "[45] Training loss: 0.913\t Validation loss: 1.317\n",
      "[46] Training loss: 0.903\t Validation loss: 1.314\n",
      "[47] Training loss: 0.894\t Validation loss: 1.311\n",
      "[48] Training loss: 0.885\t Validation loss: 1.307\n",
      "[49] Training loss: 0.875\t Validation loss: 1.303\n",
      "[50] Training loss: 0.865\t Validation loss: 1.298\n",
      "[1] Training loss: 5.178\t Validation loss: 5.055\n",
      "[2] Training loss: 4.804\t Validation loss: 4.619\n",
      "[3] Training loss: 4.365\t Validation loss: 4.046\n",
      "[4] Training loss: 3.807\t Validation loss: 3.399\n",
      "[5] Training loss: 3.192\t Validation loss: 2.785\n",
      "[6] Training loss: 2.615\t Validation loss: 2.352\n",
      "[7] Training loss: 2.213\t Validation loss: 2.163\n",
      "[8] Training loss: 2.038\t Validation loss: 2.105\n",
      "[9] Training loss: 1.974\t Validation loss: 2.037\n",
      "[10] Training loss: 1.892\t Validation loss: 1.915\n",
      "[11] Training loss: 1.756\t Validation loss: 1.773\n",
      "[12] Training loss: 1.600\t Validation loss: 1.661\n",
      "[13] Training loss: 1.474\t Validation loss: 1.612\n",
      "[14] Training loss: 1.410\t Validation loss: 1.622\n",
      "[15] Training loss: 1.404\t Validation loss: 1.665\n",
      "[16] Training loss: 1.432\t Validation loss: 1.709\n",
      "[17] Training loss: 1.463\t Validation loss: 1.731\n",
      "[18] Training loss: 1.477\t Validation loss: 1.723\n",
      "[19] Training loss: 1.464\t Validation loss: 1.685\n",
      "[20] Training loss: 1.425\t Validation loss: 1.628\n",
      "[21] Training loss: 1.371\t Validation loss: 1.564\n",
      "[22] Training loss: 1.312\t Validation loss: 1.507\n",
      "[23] Training loss: 1.259\t Validation loss: 1.463\n",
      "[24] Training loss: 1.219\t Validation loss: 1.436\n",
      "[25] Training loss: 1.191\t Validation loss: 1.420\n",
      "[26] Training loss: 1.171\t Validation loss: 1.410\n",
      "[27] Training loss: 1.152\t Validation loss: 1.400\n",
      "[28] Training loss: 1.130\t Validation loss: 1.390\n",
      "[29] Training loss: 1.104\t Validation loss: 1.383\n",
      "[30] Training loss: 1.079\t Validation loss: 1.381\n",
      "[31] Training loss: 1.058\t Validation loss: 1.386\n",
      "[32] Training loss: 1.044\t Validation loss: 1.395\n",
      "[33] Training loss: 1.034\t Validation loss: 1.405\n",
      "[34] Training loss: 1.026\t Validation loss: 1.411\n",
      "[35] Training loss: 1.018\t Validation loss: 1.411\n",
      "[36] Training loss: 1.007\t Validation loss: 1.404\n",
      "[37] Training loss: 0.991\t Validation loss: 1.390\n",
      "[38] Training loss: 0.972\t Validation loss: 1.374\n",
      "[39] Training loss: 0.952\t Validation loss: 1.358\n",
      "[40] Training loss: 0.933\t Validation loss: 1.344\n",
      "[41] Training loss: 0.917\t Validation loss: 1.332\n",
      "[42] Training loss: 0.902\t Validation loss: 1.323\n",
      "[43] Training loss: 0.890\t Validation loss: 1.314\n",
      "[44] Training loss: 0.877\t Validation loss: 1.306\n",
      "[45] Training loss: 0.863\t Validation loss: 1.299\n",
      "[46] Training loss: 0.848\t Validation loss: 1.293\n",
      "[47] Training loss: 0.834\t Validation loss: 1.288\n",
      "[48] Training loss: 0.822\t Validation loss: 1.284\n",
      "[49] Training loss: 0.810\t Validation loss: 1.281\n",
      "[50] Training loss: 0.800\t Validation loss: 1.277\n",
      "[1] Training loss: 5.892\t Validation loss: 5.100\n",
      "[2] Training loss: 5.563\t Validation loss: 4.752\n",
      "[3] Training loss: 5.148\t Validation loss: 4.214\n",
      "[4] Training loss: 4.530\t Validation loss: 3.552\n",
      "[5] Training loss: 3.778\t Validation loss: 2.890\n",
      "[6] Training loss: 3.031\t Validation loss: 2.394\n",
      "[7] Training loss: 2.473\t Validation loss: 2.145\n",
      "[8] Training loss: 2.183\t Validation loss: 2.059\n",
      "[9] Training loss: 2.069\t Validation loss: 2.023\n",
      "[10] Training loss: 2.010\t Validation loss: 1.954\n",
      "[11] Training loss: 1.913\t Validation loss: 1.833\n",
      "[12] Training loss: 1.756\t Validation loss: 1.705\n",
      "[13] Training loss: 1.594\t Validation loss: 1.627\n",
      "[14] Training loss: 1.489\t Validation loss: 1.614\n",
      "[15] Training loss: 1.460\t Validation loss: 1.646\n",
      "[16] Training loss: 1.481\t Validation loss: 1.686\n",
      "[17] Training loss: 1.514\t Validation loss: 1.711\n",
      "[18] Training loss: 1.530\t Validation loss: 1.706\n",
      "[19] Training loss: 1.516\t Validation loss: 1.673\n",
      "[20] Training loss: 1.473\t Validation loss: 1.621\n",
      "[21] Training loss: 1.410\t Validation loss: 1.565\n",
      "[22] Training loss: 1.344\t Validation loss: 1.519\n",
      "[23] Training loss: 1.289\t Validation loss: 1.489\n",
      "[24] Training loss: 1.249\t Validation loss: 1.468\n",
      "[25] Training loss: 1.217\t Validation loss: 1.448\n",
      "[26] Training loss: 1.183\t Validation loss: 1.425\n",
      "[27] Training loss: 1.142\t Validation loss: 1.401\n",
      "[28] Training loss: 1.100\t Validation loss: 1.382\n",
      "[29] Training loss: 1.063\t Validation loss: 1.371\n",
      "[30] Training loss: 1.036\t Validation loss: 1.369\n",
      "[31] Training loss: 1.017\t Validation loss: 1.372\n",
      "[32] Training loss: 1.005\t Validation loss: 1.374\n",
      "[33] Training loss: 0.994\t Validation loss: 1.374\n",
      "[34] Training loss: 0.982\t Validation loss: 1.368\n",
      "[35] Training loss: 0.966\t Validation loss: 1.359\n",
      "[36] Training loss: 0.948\t Validation loss: 1.348\n",
      "[37] Training loss: 0.928\t Validation loss: 1.336\n",
      "[38] Training loss: 0.909\t Validation loss: 1.327\n",
      "[39] Training loss: 0.890\t Validation loss: 1.318\n",
      "[40] Training loss: 0.872\t Validation loss: 1.311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41] Training loss: 0.854\t Validation loss: 1.305\n",
      "[42] Training loss: 0.836\t Validation loss: 1.299\n",
      "[43] Training loss: 0.818\t Validation loss: 1.294\n",
      "[44] Training loss: 0.801\t Validation loss: 1.291\n",
      "[45] Training loss: 0.785\t Validation loss: 1.288\n",
      "[46] Training loss: 0.771\t Validation loss: 1.285\n",
      "[47] Training loss: 0.758\t Validation loss: 1.281\n",
      "[48] Training loss: 0.746\t Validation loss: 1.275\n",
      "[49] Training loss: 0.732\t Validation loss: 1.268\n",
      "[50] Training loss: 0.719\t Validation loss: 1.260\n",
      "[1] Training loss: 5.825\t Validation loss: 4.888\n",
      "[2] Training loss: 5.206\t Validation loss: 4.201\n",
      "[3] Training loss: 4.436\t Validation loss: 3.385\n",
      "[4] Training loss: 3.529\t Validation loss: 2.592\n",
      "[5] Training loss: 2.651\t Validation loss: 2.056\n",
      "[6] Training loss: 2.063\t Validation loss: 1.949\n",
      "[7] Training loss: 1.951\t Validation loss: 2.079\n",
      "[8] Training loss: 2.103\t Validation loss: 2.125\n",
      "[9] Training loss: 2.162\t Validation loss: 1.981\n",
      "[10] Training loss: 2.011\t Validation loss: 1.752\n",
      "[11] Training loss: 1.759\t Validation loss: 1.571\n",
      "[12] Training loss: 1.552\t Validation loss: 1.502\n",
      "[13] Training loss: 1.459\t Validation loss: 1.526\n",
      "[14] Training loss: 1.463\t Validation loss: 1.592\n",
      "[15] Training loss: 1.509\t Validation loss: 1.653\n",
      "[16] Training loss: 1.551\t Validation loss: 1.683\n",
      "[17] Training loss: 1.559\t Validation loss: 1.676\n",
      "[18] Training loss: 1.526\t Validation loss: 1.639\n",
      "[19] Training loss: 1.463\t Validation loss: 1.588\n",
      "[20] Training loss: 1.388\t Validation loss: 1.537\n",
      "[21] Training loss: 1.315\t Validation loss: 1.494\n",
      "[22] Training loss: 1.255\t Validation loss: 1.462\n",
      "[23] Training loss: 1.211\t Validation loss: 1.438\n",
      "[24] Training loss: 1.178\t Validation loss: 1.418\n",
      "[25] Training loss: 1.150\t Validation loss: 1.400\n",
      "[26] Training loss: 1.124\t Validation loss: 1.382\n",
      "[27] Training loss: 1.098\t Validation loss: 1.368\n",
      "[28] Training loss: 1.071\t Validation loss: 1.356\n",
      "[29] Training loss: 1.047\t Validation loss: 1.349\n",
      "[30] Training loss: 1.025\t Validation loss: 1.344\n",
      "[31] Training loss: 1.004\t Validation loss: 1.338\n",
      "[32] Training loss: 0.983\t Validation loss: 1.331\n",
      "[33] Training loss: 0.960\t Validation loss: 1.322\n",
      "[34] Training loss: 0.934\t Validation loss: 1.310\n",
      "[35] Training loss: 0.906\t Validation loss: 1.299\n",
      "[36] Training loss: 0.879\t Validation loss: 1.288\n",
      "[37] Training loss: 0.852\t Validation loss: 1.280\n",
      "[38] Training loss: 0.829\t Validation loss: 1.273\n",
      "[39] Training loss: 0.810\t Validation loss: 1.269\n",
      "[40] Training loss: 0.793\t Validation loss: 1.264\n",
      "[41] Training loss: 0.776\t Validation loss: 1.257\n",
      "[42] Training loss: 0.759\t Validation loss: 1.248\n",
      "[43] Training loss: 0.740\t Validation loss: 1.237\n",
      "[44] Training loss: 0.719\t Validation loss: 1.225\n",
      "[45] Training loss: 0.697\t Validation loss: 1.213\n",
      "[46] Training loss: 0.677\t Validation loss: 1.203\n",
      "[47] Training loss: 0.658\t Validation loss: 1.196\n",
      "[48] Training loss: 0.641\t Validation loss: 1.190\n",
      "[49] Training loss: 0.626\t Validation loss: 1.185\n",
      "[50] Training loss: 0.610\t Validation loss: 1.180\n",
      "[1] Training loss: 5.389\t Validation loss: 4.559\n",
      "[2] Training loss: 4.638\t Validation loss: 3.665\n",
      "[3] Training loss: 3.726\t Validation loss: 2.701\n",
      "[4] Training loss: 2.750\t Validation loss: 1.933\n",
      "[5] Training loss: 1.985\t Validation loss: 1.704\n",
      "[6] Training loss: 1.770\t Validation loss: 1.956\n",
      "[7] Training loss: 2.016\t Validation loss: 2.163\n",
      "[8] Training loss: 2.191\t Validation loss: 2.075\n",
      "[9] Training loss: 2.060\t Validation loss: 1.836\n",
      "[10] Training loss: 1.774\t Validation loss: 1.642\n",
      "[11] Training loss: 1.534\t Validation loss: 1.578\n",
      "[12] Training loss: 1.433\t Validation loss: 1.622\n",
      "[13] Training loss: 1.451\t Validation loss: 1.709\n",
      "[14] Training loss: 1.519\t Validation loss: 1.777\n",
      "[15] Training loss: 1.572\t Validation loss: 1.796\n",
      "[16] Training loss: 1.579\t Validation loss: 1.760\n",
      "[17] Training loss: 1.531\t Validation loss: 1.683\n",
      "[18] Training loss: 1.443\t Validation loss: 1.588\n",
      "[19] Training loss: 1.338\t Validation loss: 1.502\n",
      "[20] Training loss: 1.243\t Validation loss: 1.445\n",
      "[21] Training loss: 1.178\t Validation loss: 1.425\n",
      "[22] Training loss: 1.149\t Validation loss: 1.430\n",
      "[23] Training loss: 1.144\t Validation loss: 1.441\n",
      "[24] Training loss: 1.142\t Validation loss: 1.441\n",
      "[25] Training loss: 1.127\t Validation loss: 1.425\n",
      "[26] Training loss: 1.093\t Validation loss: 1.401\n",
      "[27] Training loss: 1.048\t Validation loss: 1.379\n",
      "[28] Training loss: 1.003\t Validation loss: 1.366\n",
      "[29] Training loss: 0.967\t Validation loss: 1.363\n",
      "[30] Training loss: 0.940\t Validation loss: 1.366\n",
      "[31] Training loss: 0.921\t Validation loss: 1.368\n",
      "[32] Training loss: 0.902\t Validation loss: 1.365\n",
      "[33] Training loss: 0.880\t Validation loss: 1.355\n",
      "[34] Training loss: 0.851\t Validation loss: 1.337\n",
      "[35] Training loss: 0.819\t Validation loss: 1.315\n",
      "[36] Training loss: 0.786\t Validation loss: 1.295\n",
      "[37] Training loss: 0.759\t Validation loss: 1.281\n",
      "[38] Training loss: 0.738\t Validation loss: 1.271\n",
      "[39] Training loss: 0.723\t Validation loss: 1.263\n",
      "[40] Training loss: 0.707\t Validation loss: 1.252\n",
      "[41] Training loss: 0.687\t Validation loss: 1.240\n",
      "[42] Training loss: 0.663\t Validation loss: 1.228\n",
      "[43] Training loss: 0.638\t Validation loss: 1.220\n",
      "[44] Training loss: 0.617\t Validation loss: 1.216\n",
      "[45] Training loss: 0.600\t Validation loss: 1.214\n",
      "[46] Training loss: 0.586\t Validation loss: 1.211\n",
      "[47] Training loss: 0.571\t Validation loss: 1.205\n",
      "[48] Training loss: 0.555\t Validation loss: 1.197\n",
      "[49] Training loss: 0.538\t Validation loss: 1.187\n",
      "[50] Training loss: 0.520\t Validation loss: 1.178\n",
      "[1] Training loss: 5.586\t Validation loss: 4.687\n",
      "[2] Training loss: 4.831\t Validation loss: 3.787\n",
      "[3] Training loss: 3.886\t Validation loss: 2.790\n",
      "[4] Training loss: 2.840\t Validation loss: 2.008\n",
      "[5] Training loss: 2.021\t Validation loss: 1.844\n",
      "[6] Training loss: 1.836\t Validation loss: 2.166\n",
      "[7] Training loss: 2.146\t Validation loss: 2.293\n",
      "[8] Training loss: 2.250\t Validation loss: 2.076\n",
      "[9] Training loss: 2.002\t Validation loss: 1.769\n",
      "[10] Training loss: 1.665\t Validation loss: 1.582\n",
      "[11] Training loss: 1.453\t Validation loss: 1.561\n",
      "[12] Training loss: 1.412\t Validation loss: 1.638\n",
      "[13] Training loss: 1.472\t Validation loss: 1.728\n",
      "[14] Training loss: 1.544\t Validation loss: 1.774\n",
      "[15] Training loss: 1.570\t Validation loss: 1.756\n",
      "[16] Training loss: 1.531\t Validation loss: 1.682\n",
      "[17] Training loss: 1.435\t Validation loss: 1.581\n",
      "[18] Training loss: 1.312\t Validation loss: 1.490\n",
      "[19] Training loss: 1.200\t Validation loss: 1.442\n",
      "[20] Training loss: 1.133\t Validation loss: 1.436\n",
      "[21] Training loss: 1.112\t Validation loss: 1.445\n",
      "[22] Training loss: 1.102\t Validation loss: 1.440\n",
      "[23] Training loss: 1.078\t Validation loss: 1.418\n",
      "[24] Training loss: 1.035\t Validation loss: 1.392\n",
      "[25] Training loss: 0.987\t Validation loss: 1.371\n",
      "[26] Training loss: 0.942\t Validation loss: 1.357\n",
      "[27] Training loss: 0.906\t Validation loss: 1.347\n",
      "[28] Training loss: 0.875\t Validation loss: 1.337\n",
      "[29] Training loss: 0.848\t Validation loss: 1.324\n",
      "[30] Training loss: 0.819\t Validation loss: 1.307\n",
      "[31] Training loss: 0.788\t Validation loss: 1.289\n",
      "[32] Training loss: 0.755\t Validation loss: 1.271\n",
      "[33] Training loss: 0.723\t Validation loss: 1.255\n",
      "[34] Training loss: 0.693\t Validation loss: 1.243\n",
      "[35] Training loss: 0.664\t Validation loss: 1.234\n",
      "[36] Training loss: 0.639\t Validation loss: 1.227\n",
      "[37] Training loss: 0.615\t Validation loss: 1.221\n",
      "[38] Training loss: 0.593\t Validation loss: 1.215\n",
      "[39] Training loss: 0.571\t Validation loss: 1.206\n",
      "[40] Training loss: 0.549\t Validation loss: 1.195\n",
      "[41] Training loss: 0.526\t Validation loss: 1.182\n",
      "[42] Training loss: 0.505\t Validation loss: 1.170\n",
      "[43] Training loss: 0.487\t Validation loss: 1.159\n",
      "[44] Training loss: 0.470\t Validation loss: 1.149\n",
      "[45] Training loss: 0.454\t Validation loss: 1.139\n",
      "[46] Training loss: 0.437\t Validation loss: 1.129\n",
      "[47] Training loss: 0.419\t Validation loss: 1.120\n",
      "[48] Training loss: 0.400\t Validation loss: 1.113\n",
      "[49] Training loss: 0.384\t Validation loss: 1.110\n",
      "[50] Training loss: 0.370\t Validation loss: 1.106\n"
     ]
    }
   ],
   "source": [
    "n_nodes = 20\n",
    "histories = {}\n",
    "p = 2./n_nodes\n",
    "\n",
    "for n_samples in [5e02, 1e03, 4e03, 1e04]:\n",
    "    print('Number of Samples :', n_samples)\n",
    "    histories[n_samples] = {}\n",
    "    X = make_ER_dataset(n_samples, n_nodes, p = p)\n",
    "    Y = np.sum(X, axis = -1)\n",
    "    \n",
    "    for units in np.int0(np.linspace((.25*n_nodes), (1.75*n_nodes), 9)):\n",
    "        \n",
    "        net = NeuralNet(X[0].shape[0]**2, units, n_nodes).to(device)\n",
    "        loss_fn = nn.MSELoss(reduction='mean')\n",
    "        optimizer = optim.Adam(net.parameters(), lr=.01)\n",
    "        train_step = make_train_step(net, loss_fn, optimizer)\n",
    "        train_loader, val_loader = make_loader(X, Y, int(n_samples), .2)\n",
    "        training_losses, validation_losses = train_model(net, device, train_step, 50, train_loader, val_loader)\n",
    "        histories[n_samples][units] = {\"loss\": training_losses, \"val_loss\" :validation_losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 268,
       "width": 368
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for num in sorted(histories)[:]:\n",
    "    us, loss, val_loss = [], [],[]\n",
    "    for u in sorted(histories[num]):\n",
    "        us += [u]\n",
    "        # find best fit\n",
    "        i = argmin(histories[num][u]['val_loss'])\n",
    "        loss += [histories[num][u]['loss'][i]]\n",
    "        val_loss += [histories[num][u]['val_loss'][i]]\n",
    "        \n",
    "    #plot(us,loss)\n",
    "    plot(us, val_loss,'.-', label = '%.1g samples' %num)\n",
    "\n",
    "legend()\n",
    "ylabel('MSE', size = 14)\n",
    "xlabel('# of FC units', size = 14)\n",
    "yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Convolution Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, h, y):\n",
    "        model.train()\n",
    "        yhat = model(h, x)      \n",
    "        loss = loss_fn(y, yhat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(x_h, y, batch_size, ratio_train):\n",
    "\n",
    "    x_tensor = torch.from_numpy(x_h[0]).float()\n",
    "    h_tensor = torch.from_numpy(x_h[1]).float()\n",
    "    y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "    dataset = TensorDataset(x_tensor, h_tensor, y_tensor)\n",
    "    trainlength = int(ratio_train*x_h[0].shape[0])\n",
    "    vallength = x_h[0].shape[0] - trainlength\n",
    "    \n",
    "    train_dataset, val_dataset = random_split(dataset, [trainlength, vallength])\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size = batch_size)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size = batch_size)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train_step, n_epochs, train_loader, val_loader):\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        batch_losses = []\n",
    "        for x_batch, h_batch, y_batch in train_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            h_batch = h_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            loss = train_step(x_batch, h_batch, y_batch)\n",
    "            batch_losses.append(loss)\n",
    "        training_loss = np.mean(batch_losses)\n",
    "        training_losses.append(training_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "            for x_val, h_val, y_val in val_loader:\n",
    "                x_val = x_val.to(device)\n",
    "                h_val = h_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                model.eval()\n",
    "                \n",
    "                yhat = model(h_val, x_val)\n",
    "\n",
    "                val_loss = loss_fn(y_val, yhat).item()\n",
    "                val_losses.append(val_loss)\n",
    "            validation_loss = np.mean(val_losses)\n",
    "            validation_losses.append(validation_loss)\n",
    "\n",
    "        print(f\"[{epoch+1}] Training loss: {training_loss:.3f}\\t Validation loss: {validation_loss:.3f}\")\n",
    "    return training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 Samples\n",
      "\n",
      "GraphConvolution()\n",
      "[1] Training loss: 1.033\t Validation loss: 1.036\n",
      "[2] Training loss: 1.027\t Validation loss: 1.030\n",
      "[3] Training loss: 1.021\t Validation loss: 1.023\n",
      "[4] Training loss: 1.014\t Validation loss: 1.017\n",
      "[5] Training loss: 1.008\t Validation loss: 1.011\n",
      "[6] Training loss: 1.001\t Validation loss: 1.004\n",
      "[7] Training loss: 0.995\t Validation loss: 0.998\n",
      "[8] Training loss: 0.989\t Validation loss: 0.992\n",
      "[9] Training loss: 0.983\t Validation loss: 0.985\n",
      "[10] Training loss: 0.976\t Validation loss: 0.979\n",
      "[11] Training loss: 0.970\t Validation loss: 0.973\n",
      "[12] Training loss: 0.964\t Validation loss: 0.966\n",
      "[13] Training loss: 0.958\t Validation loss: 0.960\n",
      "[14] Training loss: 0.952\t Validation loss: 0.954\n",
      "[15] Training loss: 0.945\t Validation loss: 0.948\n",
      "[16] Training loss: 0.939\t Validation loss: 0.942\n",
      "[17] Training loss: 0.933\t Validation loss: 0.936\n",
      "[18] Training loss: 0.927\t Validation loss: 0.930\n",
      "[19] Training loss: 0.921\t Validation loss: 0.924\n",
      "[20] Training loss: 0.915\t Validation loss: 0.918\n",
      "[21] Training loss: 0.909\t Validation loss: 0.911\n",
      "[22] Training loss: 0.903\t Validation loss: 0.906\n",
      "[23] Training loss: 0.897\t Validation loss: 0.900\n",
      "[24] Training loss: 0.891\t Validation loss: 0.894\n",
      "[25] Training loss: 0.885\t Validation loss: 0.888\n",
      "[26] Training loss: 0.880\t Validation loss: 0.882\n",
      "[27] Training loss: 0.874\t Validation loss: 0.876\n",
      "[28] Training loss: 0.868\t Validation loss: 0.870\n",
      "[29] Training loss: 0.862\t Validation loss: 0.864\n",
      "[30] Training loss: 0.856\t Validation loss: 0.859\n",
      "[31] Training loss: 0.851\t Validation loss: 0.853\n",
      "[32] Training loss: 0.845\t Validation loss: 0.847\n",
      "[33] Training loss: 0.839\t Validation loss: 0.841\n",
      "[34] Training loss: 0.834\t Validation loss: 0.836\n",
      "[35] Training loss: 0.828\t Validation loss: 0.830\n",
      "[36] Training loss: 0.823\t Validation loss: 0.825\n",
      "[37] Training loss: 0.817\t Validation loss: 0.819\n",
      "[38] Training loss: 0.812\t Validation loss: 0.813\n",
      "[39] Training loss: 0.806\t Validation loss: 0.808\n",
      "[40] Training loss: 0.801\t Validation loss: 0.802\n",
      "[41] Training loss: 0.795\t Validation loss: 0.797\n",
      "[42] Training loss: 0.790\t Validation loss: 0.792\n",
      "[43] Training loss: 0.784\t Validation loss: 0.786\n",
      "[44] Training loss: 0.779\t Validation loss: 0.781\n",
      "[45] Training loss: 0.774\t Validation loss: 0.775\n",
      "[46] Training loss: 0.768\t Validation loss: 0.770\n",
      "[47] Training loss: 0.763\t Validation loss: 0.765\n",
      "[48] Training loss: 0.758\t Validation loss: 0.760\n",
      "[49] Training loss: 0.753\t Validation loss: 0.754\n",
      "[50] Training loss: 0.747\t Validation loss: 0.749\n",
      "[51] Training loss: 0.742\t Validation loss: 0.744\n",
      "[52] Training loss: 0.737\t Validation loss: 0.739\n",
      "[53] Training loss: 0.732\t Validation loss: 0.734\n",
      "[54] Training loss: 0.727\t Validation loss: 0.728\n",
      "[55] Training loss: 0.722\t Validation loss: 0.723\n",
      "[56] Training loss: 0.717\t Validation loss: 0.718\n",
      "[57] Training loss: 0.712\t Validation loss: 0.713\n",
      "[58] Training loss: 0.707\t Validation loss: 0.708\n",
      "[59] Training loss: 0.702\t Validation loss: 0.703\n",
      "[60] Training loss: 0.697\t Validation loss: 0.698\n",
      "[61] Training loss: 0.692\t Validation loss: 0.693\n",
      "[62] Training loss: 0.687\t Validation loss: 0.689\n",
      "[63] Training loss: 0.682\t Validation loss: 0.684\n",
      "[64] Training loss: 0.677\t Validation loss: 0.679\n",
      "[65] Training loss: 0.673\t Validation loss: 0.674\n",
      "[66] Training loss: 0.668\t Validation loss: 0.669\n",
      "[67] Training loss: 0.663\t Validation loss: 0.664\n",
      "[68] Training loss: 0.658\t Validation loss: 0.660\n",
      "[69] Training loss: 0.654\t Validation loss: 0.655\n",
      "[70] Training loss: 0.649\t Validation loss: 0.650\n",
      "[71] Training loss: 0.644\t Validation loss: 0.646\n",
      "[72] Training loss: 0.640\t Validation loss: 0.641\n",
      "[73] Training loss: 0.635\t Validation loss: 0.636\n",
      "[74] Training loss: 0.630\t Validation loss: 0.632\n",
      "[75] Training loss: 0.626\t Validation loss: 0.627\n",
      "[76] Training loss: 0.621\t Validation loss: 0.623\n",
      "[77] Training loss: 0.617\t Validation loss: 0.618\n",
      "[78] Training loss: 0.612\t Validation loss: 0.614\n",
      "[79] Training loss: 0.608\t Validation loss: 0.609\n",
      "[80] Training loss: 0.604\t Validation loss: 0.605\n",
      "[81] Training loss: 0.599\t Validation loss: 0.600\n",
      "[82] Training loss: 0.595\t Validation loss: 0.596\n",
      "[83] Training loss: 0.590\t Validation loss: 0.592\n",
      "[84] Training loss: 0.586\t Validation loss: 0.587\n",
      "[85] Training loss: 0.582\t Validation loss: 0.583\n",
      "[86] Training loss: 0.578\t Validation loss: 0.579\n",
      "[87] Training loss: 0.573\t Validation loss: 0.575\n",
      "[88] Training loss: 0.569\t Validation loss: 0.570\n",
      "[89] Training loss: 0.565\t Validation loss: 0.566\n",
      "[90] Training loss: 0.561\t Validation loss: 0.562\n",
      "[91] Training loss: 0.557\t Validation loss: 0.558\n",
      "[92] Training loss: 0.553\t Validation loss: 0.554\n",
      "[93] Training loss: 0.548\t Validation loss: 0.550\n",
      "[94] Training loss: 0.544\t Validation loss: 0.545\n",
      "[95] Training loss: 0.540\t Validation loss: 0.541\n",
      "[96] Training loss: 0.536\t Validation loss: 0.537\n",
      "[97] Training loss: 0.532\t Validation loss: 0.533\n",
      "[98] Training loss: 0.528\t Validation loss: 0.529\n",
      "[99] Training loss: 0.524\t Validation loss: 0.525\n",
      "[100] Training loss: 0.520\t Validation loss: 0.521\n",
      "[101] Training loss: 0.516\t Validation loss: 0.517\n",
      "[102] Training loss: 0.513\t Validation loss: 0.514\n",
      "[103] Training loss: 0.509\t Validation loss: 0.510\n",
      "[104] Training loss: 0.505\t Validation loss: 0.506\n",
      "[105] Training loss: 0.501\t Validation loss: 0.502\n",
      "[106] Training loss: 0.497\t Validation loss: 0.498\n",
      "[107] Training loss: 0.493\t Validation loss: 0.494\n",
      "[108] Training loss: 0.490\t Validation loss: 0.491\n",
      "[109] Training loss: 0.486\t Validation loss: 0.487\n",
      "[110] Training loss: 0.482\t Validation loss: 0.483\n",
      "[111] Training loss: 0.479\t Validation loss: 0.479\n",
      "[112] Training loss: 0.475\t Validation loss: 0.476\n",
      "[113] Training loss: 0.471\t Validation loss: 0.472\n",
      "[114] Training loss: 0.468\t Validation loss: 0.469\n",
      "[115] Training loss: 0.464\t Validation loss: 0.465\n",
      "[116] Training loss: 0.460\t Validation loss: 0.461\n",
      "[117] Training loss: 0.457\t Validation loss: 0.458\n",
      "[118] Training loss: 0.453\t Validation loss: 0.454\n",
      "[119] Training loss: 0.450\t Validation loss: 0.451\n",
      "[120] Training loss: 0.446\t Validation loss: 0.447\n",
      "[121] Training loss: 0.443\t Validation loss: 0.444\n",
      "[122] Training loss: 0.439\t Validation loss: 0.440\n",
      "[123] Training loss: 0.436\t Validation loss: 0.437\n",
      "[124] Training loss: 0.433\t Validation loss: 0.433\n",
      "[125] Training loss: 0.429\t Validation loss: 0.430\n",
      "[126] Training loss: 0.426\t Validation loss: 0.427\n",
      "[127] Training loss: 0.423\t Validation loss: 0.423\n",
      "[128] Training loss: 0.419\t Validation loss: 0.420\n",
      "[129] Training loss: 0.416\t Validation loss: 0.417\n",
      "[130] Training loss: 0.413\t Validation loss: 0.413\n",
      "[131] Training loss: 0.409\t Validation loss: 0.410\n",
      "[132] Training loss: 0.406\t Validation loss: 0.407\n",
      "[133] Training loss: 0.403\t Validation loss: 0.404\n",
      "[134] Training loss: 0.400\t Validation loss: 0.400\n",
      "[135] Training loss: 0.397\t Validation loss: 0.397\n",
      "[136] Training loss: 0.393\t Validation loss: 0.394\n",
      "[137] Training loss: 0.390\t Validation loss: 0.391\n",
      "[138] Training loss: 0.387\t Validation loss: 0.388\n",
      "[139] Training loss: 0.384\t Validation loss: 0.385\n",
      "[140] Training loss: 0.381\t Validation loss: 0.382\n",
      "[141] Training loss: 0.378\t Validation loss: 0.379\n",
      "[142] Training loss: 0.375\t Validation loss: 0.376\n",
      "[143] Training loss: 0.372\t Validation loss: 0.373\n",
      "[144] Training loss: 0.369\t Validation loss: 0.370\n",
      "[145] Training loss: 0.366\t Validation loss: 0.367\n",
      "[146] Training loss: 0.363\t Validation loss: 0.364\n",
      "[147] Training loss: 0.360\t Validation loss: 0.361\n",
      "[148] Training loss: 0.357\t Validation loss: 0.358\n",
      "[149] Training loss: 0.354\t Validation loss: 0.355\n",
      "[150] Training loss: 0.351\t Validation loss: 0.352\n",
      "[151] Training loss: 0.348\t Validation loss: 0.349\n",
      "[152] Training loss: 0.346\t Validation loss: 0.346\n",
      "[153] Training loss: 0.343\t Validation loss: 0.343\n",
      "[154] Training loss: 0.340\t Validation loss: 0.341\n",
      "[155] Training loss: 0.337\t Validation loss: 0.338\n",
      "[156] Training loss: 0.334\t Validation loss: 0.335\n",
      "[157] Training loss: 0.332\t Validation loss: 0.332\n",
      "[158] Training loss: 0.329\t Validation loss: 0.329\n",
      "[159] Training loss: 0.326\t Validation loss: 0.327\n",
      "[160] Training loss: 0.324\t Validation loss: 0.324\n",
      "[161] Training loss: 0.321\t Validation loss: 0.321\n",
      "[162] Training loss: 0.318\t Validation loss: 0.319\n",
      "[163] Training loss: 0.316\t Validation loss: 0.316\n",
      "[164] Training loss: 0.313\t Validation loss: 0.313\n",
      "[165] Training loss: 0.310\t Validation loss: 0.311\n",
      "[166] Training loss: 0.308\t Validation loss: 0.308\n",
      "[167] Training loss: 0.305\t Validation loss: 0.306\n",
      "[168] Training loss: 0.303\t Validation loss: 0.303\n",
      "[169] Training loss: 0.300\t Validation loss: 0.301\n",
      "[170] Training loss: 0.298\t Validation loss: 0.298\n",
      "[171] Training loss: 0.295\t Validation loss: 0.295\n",
      "[172] Training loss: 0.293\t Validation loss: 0.293\n",
      "[173] Training loss: 0.290\t Validation loss: 0.291\n",
      "[174] Training loss: 0.288\t Validation loss: 0.288\n",
      "[175] Training loss: 0.285\t Validation loss: 0.286\n",
      "[176] Training loss: 0.283\t Validation loss: 0.283\n",
      "[177] Training loss: 0.280\t Validation loss: 0.281\n",
      "[178] Training loss: 0.278\t Validation loss: 0.278\n",
      "[179] Training loss: 0.276\t Validation loss: 0.276\n",
      "[180] Training loss: 0.273\t Validation loss: 0.274\n",
      "[181] Training loss: 0.271\t Validation loss: 0.271\n",
      "[182] Training loss: 0.269\t Validation loss: 0.269\n",
      "[183] Training loss: 0.266\t Validation loss: 0.267\n",
      "[184] Training loss: 0.264\t Validation loss: 0.264\n",
      "[185] Training loss: 0.262\t Validation loss: 0.262\n",
      "[186] Training loss: 0.260\t Validation loss: 0.260\n",
      "[187] Training loss: 0.257\t Validation loss: 0.258\n",
      "[188] Training loss: 0.255\t Validation loss: 0.255\n",
      "[189] Training loss: 0.253\t Validation loss: 0.253\n",
      "[190] Training loss: 0.251\t Validation loss: 0.251\n",
      "[191] Training loss: 0.248\t Validation loss: 0.249\n",
      "[192] Training loss: 0.246\t Validation loss: 0.247\n",
      "[193] Training loss: 0.244\t Validation loss: 0.245\n",
      "[194] Training loss: 0.242\t Validation loss: 0.242\n",
      "[195] Training loss: 0.240\t Validation loss: 0.240\n",
      "[196] Training loss: 0.238\t Validation loss: 0.238\n",
      "[197] Training loss: 0.236\t Validation loss: 0.236\n",
      "[198] Training loss: 0.234\t Validation loss: 0.234\n",
      "[199] Training loss: 0.232\t Validation loss: 0.232\n",
      "[200] Training loss: 0.230\t Validation loss: 0.230\n",
      "[201] Training loss: 0.228\t Validation loss: 0.228\n",
      "[202] Training loss: 0.226\t Validation loss: 0.226\n",
      "[203] Training loss: 0.224\t Validation loss: 0.224\n",
      "[204] Training loss: 0.222\t Validation loss: 0.222\n",
      "[205] Training loss: 0.220\t Validation loss: 0.220\n",
      "[206] Training loss: 0.218\t Validation loss: 0.218\n",
      "[207] Training loss: 0.216\t Validation loss: 0.216\n",
      "[208] Training loss: 0.214\t Validation loss: 0.214\n",
      "[209] Training loss: 0.212\t Validation loss: 0.212\n",
      "[210] Training loss: 0.210\t Validation loss: 0.210\n",
      "[211] Training loss: 0.208\t Validation loss: 0.208\n",
      "[212] Training loss: 0.206\t Validation loss: 0.207\n",
      "[213] Training loss: 0.204\t Validation loss: 0.205\n",
      "[214] Training loss: 0.203\t Validation loss: 0.203\n",
      "[215] Training loss: 0.201\t Validation loss: 0.201\n",
      "[216] Training loss: 0.199\t Validation loss: 0.199\n",
      "[217] Training loss: 0.197\t Validation loss: 0.197\n",
      "[218] Training loss: 0.195\t Validation loss: 0.196\n",
      "[219] Training loss: 0.194\t Validation loss: 0.194\n",
      "[220] Training loss: 0.192\t Validation loss: 0.192\n",
      "[221] Training loss: 0.190\t Validation loss: 0.190\n",
      "[222] Training loss: 0.188\t Validation loss: 0.189\n",
      "[223] Training loss: 0.187\t Validation loss: 0.187\n",
      "[224] Training loss: 0.185\t Validation loss: 0.185\n",
      "[225] Training loss: 0.183\t Validation loss: 0.184\n",
      "[226] Training loss: 0.182\t Validation loss: 0.182\n",
      "[227] Training loss: 0.180\t Validation loss: 0.180\n",
      "[228] Training loss: 0.178\t Validation loss: 0.179\n",
      "[229] Training loss: 0.177\t Validation loss: 0.177\n",
      "[230] Training loss: 0.175\t Validation loss: 0.175\n",
      "[231] Training loss: 0.173\t Validation loss: 0.174\n",
      "[232] Training loss: 0.172\t Validation loss: 0.172\n",
      "[233] Training loss: 0.170\t Validation loss: 0.170\n",
      "[234] Training loss: 0.169\t Validation loss: 0.169\n",
      "[235] Training loss: 0.167\t Validation loss: 0.167\n",
      "[236] Training loss: 0.166\t Validation loss: 0.166\n",
      "[237] Training loss: 0.164\t Validation loss: 0.164\n",
      "[238] Training loss: 0.163\t Validation loss: 0.163\n",
      "[239] Training loss: 0.161\t Validation loss: 0.161\n",
      "[240] Training loss: 0.159\t Validation loss: 0.160\n",
      "[241] Training loss: 0.158\t Validation loss: 0.158\n",
      "[242] Training loss: 0.157\t Validation loss: 0.157\n",
      "[243] Training loss: 0.155\t Validation loss: 0.155\n",
      "[244] Training loss: 0.154\t Validation loss: 0.154\n",
      "[245] Training loss: 0.152\t Validation loss: 0.152\n",
      "[246] Training loss: 0.151\t Validation loss: 0.151\n",
      "[247] Training loss: 0.149\t Validation loss: 0.149\n",
      "[248] Training loss: 0.148\t Validation loss: 0.148\n",
      "[249] Training loss: 0.147\t Validation loss: 0.147\n",
      "[250] Training loss: 0.145\t Validation loss: 0.145\n",
      "[251] Training loss: 0.144\t Validation loss: 0.144\n",
      "[252] Training loss: 0.142\t Validation loss: 0.143\n",
      "[253] Training loss: 0.141\t Validation loss: 0.141\n",
      "[254] Training loss: 0.140\t Validation loss: 0.140\n",
      "[255] Training loss: 0.138\t Validation loss: 0.139\n",
      "[256] Training loss: 0.137\t Validation loss: 0.137\n",
      "[257] Training loss: 0.136\t Validation loss: 0.136\n",
      "[258] Training loss: 0.134\t Validation loss: 0.135\n",
      "[259] Training loss: 0.133\t Validation loss: 0.133\n",
      "[260] Training loss: 0.132\t Validation loss: 0.132\n",
      "[261] Training loss: 0.131\t Validation loss: 0.131\n",
      "[262] Training loss: 0.129\t Validation loss: 0.129\n",
      "[263] Training loss: 0.128\t Validation loss: 0.128\n",
      "[264] Training loss: 0.127\t Validation loss: 0.127\n",
      "[265] Training loss: 0.126\t Validation loss: 0.126\n",
      "[266] Training loss: 0.124\t Validation loss: 0.125\n",
      "[267] Training loss: 0.123\t Validation loss: 0.123\n",
      "[268] Training loss: 0.122\t Validation loss: 0.122\n",
      "[269] Training loss: 0.121\t Validation loss: 0.121\n",
      "[270] Training loss: 0.120\t Validation loss: 0.120\n",
      "[271] Training loss: 0.119\t Validation loss: 0.119\n",
      "[272] Training loss: 0.117\t Validation loss: 0.117\n",
      "[273] Training loss: 0.116\t Validation loss: 0.116\n",
      "[274] Training loss: 0.115\t Validation loss: 0.115\n",
      "[275] Training loss: 0.114\t Validation loss: 0.114\n",
      "[276] Training loss: 0.113\t Validation loss: 0.113\n",
      "[277] Training loss: 0.112\t Validation loss: 0.112\n",
      "[278] Training loss: 0.111\t Validation loss: 0.111\n",
      "[279] Training loss: 0.110\t Validation loss: 0.110\n",
      "[280] Training loss: 0.108\t Validation loss: 0.109\n",
      "[281] Training loss: 0.107\t Validation loss: 0.108\n",
      "[282] Training loss: 0.106\t Validation loss: 0.106\n",
      "[283] Training loss: 0.105\t Validation loss: 0.105\n",
      "[284] Training loss: 0.104\t Validation loss: 0.104\n",
      "[285] Training loss: 0.103\t Validation loss: 0.103\n",
      "[286] Training loss: 0.102\t Validation loss: 0.102\n",
      "[287] Training loss: 0.101\t Validation loss: 0.101\n",
      "[288] Training loss: 0.100\t Validation loss: 0.100\n",
      "[289] Training loss: 0.099\t Validation loss: 0.099\n",
      "[290] Training loss: 0.098\t Validation loss: 0.098\n",
      "[291] Training loss: 0.097\t Validation loss: 0.097\n",
      "[292] Training loss: 0.096\t Validation loss: 0.096\n",
      "[293] Training loss: 0.095\t Validation loss: 0.095\n",
      "[294] Training loss: 0.094\t Validation loss: 0.094\n",
      "[295] Training loss: 0.093\t Validation loss: 0.094\n",
      "[296] Training loss: 0.092\t Validation loss: 0.093\n",
      "[297] Training loss: 0.092\t Validation loss: 0.092\n",
      "[298] Training loss: 0.091\t Validation loss: 0.091\n",
      "[299] Training loss: 0.090\t Validation loss: 0.090\n",
      "[300] Training loss: 0.089\t Validation loss: 0.089\n",
      "[301] Training loss: 0.088\t Validation loss: 0.088\n",
      "[302] Training loss: 0.087\t Validation loss: 0.087\n",
      "[303] Training loss: 0.086\t Validation loss: 0.086\n",
      "[304] Training loss: 0.085\t Validation loss: 0.085\n",
      "[305] Training loss: 0.084\t Validation loss: 0.085\n",
      "[306] Training loss: 0.084\t Validation loss: 0.084\n",
      "[307] Training loss: 0.083\t Validation loss: 0.083\n",
      "[308] Training loss: 0.082\t Validation loss: 0.082\n",
      "[309] Training loss: 0.081\t Validation loss: 0.081\n",
      "[310] Training loss: 0.080\t Validation loss: 0.080\n",
      "[311] Training loss: 0.079\t Validation loss: 0.079\n",
      "[312] Training loss: 0.079\t Validation loss: 0.079\n",
      "[313] Training loss: 0.078\t Validation loss: 0.078\n",
      "[314] Training loss: 0.077\t Validation loss: 0.077\n",
      "[315] Training loss: 0.076\t Validation loss: 0.076\n",
      "[316] Training loss: 0.075\t Validation loss: 0.076\n",
      "[317] Training loss: 0.075\t Validation loss: 0.075\n",
      "[318] Training loss: 0.074\t Validation loss: 0.074\n",
      "[319] Training loss: 0.073\t Validation loss: 0.073\n",
      "[320] Training loss: 0.072\t Validation loss: 0.072\n",
      "[321] Training loss: 0.072\t Validation loss: 0.072\n",
      "[322] Training loss: 0.071\t Validation loss: 0.071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[323] Training loss: 0.070\t Validation loss: 0.070\n",
      "[324] Training loss: 0.069\t Validation loss: 0.070\n",
      "[325] Training loss: 0.069\t Validation loss: 0.069\n",
      "[326] Training loss: 0.068\t Validation loss: 0.068\n",
      "[327] Training loss: 0.067\t Validation loss: 0.067\n",
      "[328] Training loss: 0.067\t Validation loss: 0.067\n",
      "[329] Training loss: 0.066\t Validation loss: 0.066\n",
      "[330] Training loss: 0.065\t Validation loss: 0.065\n",
      "[331] Training loss: 0.065\t Validation loss: 0.065\n",
      "[332] Training loss: 0.064\t Validation loss: 0.064\n",
      "[333] Training loss: 0.063\t Validation loss: 0.063\n",
      "[334] Training loss: 0.063\t Validation loss: 0.063\n",
      "[335] Training loss: 0.062\t Validation loss: 0.062\n",
      "[336] Training loss: 0.061\t Validation loss: 0.061\n",
      "[337] Training loss: 0.061\t Validation loss: 0.061\n",
      "[338] Training loss: 0.060\t Validation loss: 0.060\n",
      "[339] Training loss: 0.059\t Validation loss: 0.059\n",
      "[340] Training loss: 0.059\t Validation loss: 0.059\n",
      "[341] Training loss: 0.058\t Validation loss: 0.058\n",
      "[342] Training loss: 0.058\t Validation loss: 0.058\n",
      "[343] Training loss: 0.057\t Validation loss: 0.057\n",
      "[344] Training loss: 0.056\t Validation loss: 0.056\n",
      "[345] Training loss: 0.056\t Validation loss: 0.056\n",
      "[346] Training loss: 0.055\t Validation loss: 0.055\n",
      "[347] Training loss: 0.055\t Validation loss: 0.055\n",
      "[348] Training loss: 0.054\t Validation loss: 0.054\n",
      "[349] Training loss: 0.053\t Validation loss: 0.053\n",
      "[350] Training loss: 0.053\t Validation loss: 0.053\n",
      "[351] Training loss: 0.052\t Validation loss: 0.052\n",
      "[352] Training loss: 0.052\t Validation loss: 0.052\n",
      "[353] Training loss: 0.051\t Validation loss: 0.051\n",
      "[354] Training loss: 0.051\t Validation loss: 0.051\n",
      "[355] Training loss: 0.050\t Validation loss: 0.050\n",
      "[356] Training loss: 0.050\t Validation loss: 0.050\n",
      "[357] Training loss: 0.049\t Validation loss: 0.049\n",
      "[358] Training loss: 0.049\t Validation loss: 0.049\n",
      "[359] Training loss: 0.048\t Validation loss: 0.048\n",
      "[360] Training loss: 0.048\t Validation loss: 0.048\n",
      "[361] Training loss: 0.047\t Validation loss: 0.047\n",
      "[362] Training loss: 0.047\t Validation loss: 0.047\n",
      "[363] Training loss: 0.046\t Validation loss: 0.046\n",
      "[364] Training loss: 0.046\t Validation loss: 0.046\n",
      "[365] Training loss: 0.045\t Validation loss: 0.045\n",
      "[366] Training loss: 0.045\t Validation loss: 0.045\n",
      "[367] Training loss: 0.044\t Validation loss: 0.044\n",
      "[368] Training loss: 0.044\t Validation loss: 0.044\n",
      "[369] Training loss: 0.043\t Validation loss: 0.043\n",
      "[370] Training loss: 0.043\t Validation loss: 0.043\n",
      "[371] Training loss: 0.042\t Validation loss: 0.042\n",
      "[372] Training loss: 0.042\t Validation loss: 0.042\n",
      "[373] Training loss: 0.041\t Validation loss: 0.041\n",
      "[374] Training loss: 0.041\t Validation loss: 0.041\n",
      "[375] Training loss: 0.040\t Validation loss: 0.041\n",
      "[376] Training loss: 0.040\t Validation loss: 0.040\n",
      "[377] Training loss: 0.040\t Validation loss: 0.040\n",
      "[378] Training loss: 0.039\t Validation loss: 0.039\n",
      "[379] Training loss: 0.039\t Validation loss: 0.039\n",
      "[380] Training loss: 0.038\t Validation loss: 0.038\n",
      "[381] Training loss: 0.038\t Validation loss: 0.038\n",
      "[382] Training loss: 0.038\t Validation loss: 0.038\n",
      "[383] Training loss: 0.037\t Validation loss: 0.037\n",
      "[384] Training loss: 0.037\t Validation loss: 0.037\n",
      "[385] Training loss: 0.036\t Validation loss: 0.036\n",
      "[386] Training loss: 0.036\t Validation loss: 0.036\n",
      "[387] Training loss: 0.036\t Validation loss: 0.036\n",
      "[388] Training loss: 0.035\t Validation loss: 0.035\n",
      "[389] Training loss: 0.035\t Validation loss: 0.035\n",
      "[390] Training loss: 0.034\t Validation loss: 0.034\n",
      "[391] Training loss: 0.034\t Validation loss: 0.034\n",
      "[392] Training loss: 0.034\t Validation loss: 0.034\n",
      "[393] Training loss: 0.033\t Validation loss: 0.033\n",
      "[394] Training loss: 0.033\t Validation loss: 0.033\n",
      "[395] Training loss: 0.033\t Validation loss: 0.033\n",
      "[396] Training loss: 0.032\t Validation loss: 0.032\n",
      "[397] Training loss: 0.032\t Validation loss: 0.032\n",
      "[398] Training loss: 0.032\t Validation loss: 0.032\n",
      "[399] Training loss: 0.031\t Validation loss: 0.031\n",
      "[400] Training loss: 0.031\t Validation loss: 0.031\n",
      "[401] Training loss: 0.031\t Validation loss: 0.031\n",
      "[402] Training loss: 0.030\t Validation loss: 0.030\n",
      "[403] Training loss: 0.030\t Validation loss: 0.030\n",
      "[404] Training loss: 0.030\t Validation loss: 0.030\n",
      "[405] Training loss: 0.029\t Validation loss: 0.029\n",
      "[406] Training loss: 0.029\t Validation loss: 0.029\n",
      "[407] Training loss: 0.029\t Validation loss: 0.029\n",
      "[408] Training loss: 0.028\t Validation loss: 0.028\n",
      "[409] Training loss: 0.028\t Validation loss: 0.028\n",
      "[410] Training loss: 0.028\t Validation loss: 0.028\n",
      "[411] Training loss: 0.027\t Validation loss: 0.028\n",
      "[412] Training loss: 0.027\t Validation loss: 0.027\n",
      "[413] Training loss: 0.027\t Validation loss: 0.027\n",
      "[414] Training loss: 0.027\t Validation loss: 0.027\n",
      "[415] Training loss: 0.026\t Validation loss: 0.026\n",
      "[416] Training loss: 0.026\t Validation loss: 0.026\n",
      "[417] Training loss: 0.026\t Validation loss: 0.026\n",
      "[418] Training loss: 0.025\t Validation loss: 0.026\n",
      "[419] Training loss: 0.025\t Validation loss: 0.025\n",
      "[420] Training loss: 0.025\t Validation loss: 0.025\n",
      "[421] Training loss: 0.025\t Validation loss: 0.025\n",
      "[422] Training loss: 0.024\t Validation loss: 0.024\n",
      "[423] Training loss: 0.024\t Validation loss: 0.024\n",
      "[424] Training loss: 0.024\t Validation loss: 0.024\n",
      "[425] Training loss: 0.024\t Validation loss: 0.024\n",
      "[426] Training loss: 0.023\t Validation loss: 0.023\n",
      "[427] Training loss: 0.023\t Validation loss: 0.023\n",
      "[428] Training loss: 0.023\t Validation loss: 0.023\n",
      "[429] Training loss: 0.023\t Validation loss: 0.023\n",
      "[430] Training loss: 0.022\t Validation loss: 0.022\n",
      "[431] Training loss: 0.022\t Validation loss: 0.022\n",
      "[432] Training loss: 0.022\t Validation loss: 0.022\n",
      "[433] Training loss: 0.022\t Validation loss: 0.022\n",
      "[434] Training loss: 0.021\t Validation loss: 0.021\n",
      "[435] Training loss: 0.021\t Validation loss: 0.021\n",
      "[436] Training loss: 0.021\t Validation loss: 0.021\n",
      "[437] Training loss: 0.021\t Validation loss: 0.021\n",
      "[438] Training loss: 0.021\t Validation loss: 0.021\n",
      "[439] Training loss: 0.020\t Validation loss: 0.020\n",
      "[440] Training loss: 0.020\t Validation loss: 0.020\n",
      "[441] Training loss: 0.020\t Validation loss: 0.020\n",
      "[442] Training loss: 0.020\t Validation loss: 0.020\n",
      "[443] Training loss: 0.019\t Validation loss: 0.020\n",
      "[444] Training loss: 0.019\t Validation loss: 0.019\n",
      "[445] Training loss: 0.019\t Validation loss: 0.019\n",
      "[446] Training loss: 0.019\t Validation loss: 0.019\n",
      "[447] Training loss: 0.019\t Validation loss: 0.019\n",
      "[448] Training loss: 0.018\t Validation loss: 0.019\n",
      "[449] Training loss: 0.018\t Validation loss: 0.018\n",
      "[450] Training loss: 0.018\t Validation loss: 0.018\n",
      "[451] Training loss: 0.018\t Validation loss: 0.018\n",
      "[452] Training loss: 0.018\t Validation loss: 0.018\n",
      "[453] Training loss: 0.018\t Validation loss: 0.018\n",
      "[454] Training loss: 0.017\t Validation loss: 0.017\n",
      "[455] Training loss: 0.017\t Validation loss: 0.017\n",
      "[456] Training loss: 0.017\t Validation loss: 0.017\n",
      "[457] Training loss: 0.017\t Validation loss: 0.017\n",
      "[458] Training loss: 0.017\t Validation loss: 0.017\n",
      "[459] Training loss: 0.016\t Validation loss: 0.017\n",
      "[460] Training loss: 0.016\t Validation loss: 0.016\n",
      "[461] Training loss: 0.016\t Validation loss: 0.016\n",
      "[462] Training loss: 0.016\t Validation loss: 0.016\n",
      "[463] Training loss: 0.016\t Validation loss: 0.016\n",
      "[464] Training loss: 0.016\t Validation loss: 0.016\n",
      "[465] Training loss: 0.015\t Validation loss: 0.016\n",
      "[466] Training loss: 0.015\t Validation loss: 0.015\n",
      "[467] Training loss: 0.015\t Validation loss: 0.015\n",
      "[468] Training loss: 0.015\t Validation loss: 0.015\n",
      "[469] Training loss: 0.015\t Validation loss: 0.015\n",
      "[470] Training loss: 0.015\t Validation loss: 0.015\n",
      "[471] Training loss: 0.015\t Validation loss: 0.015\n",
      "[472] Training loss: 0.014\t Validation loss: 0.014\n",
      "[473] Training loss: 0.014\t Validation loss: 0.014\n",
      "[474] Training loss: 0.014\t Validation loss: 0.014\n",
      "[475] Training loss: 0.014\t Validation loss: 0.014\n",
      "[476] Training loss: 0.014\t Validation loss: 0.014\n",
      "[477] Training loss: 0.014\t Validation loss: 0.014\n",
      "[478] Training loss: 0.014\t Validation loss: 0.014\n",
      "[479] Training loss: 0.013\t Validation loss: 0.013\n",
      "[480] Training loss: 0.013\t Validation loss: 0.013\n",
      "[481] Training loss: 0.013\t Validation loss: 0.013\n",
      "[482] Training loss: 0.013\t Validation loss: 0.013\n",
      "[483] Training loss: 0.013\t Validation loss: 0.013\n",
      "[484] Training loss: 0.013\t Validation loss: 0.013\n",
      "[485] Training loss: 0.013\t Validation loss: 0.013\n",
      "[486] Training loss: 0.013\t Validation loss: 0.013\n",
      "[487] Training loss: 0.012\t Validation loss: 0.012\n",
      "[488] Training loss: 0.012\t Validation loss: 0.012\n",
      "[489] Training loss: 0.012\t Validation loss: 0.012\n",
      "[490] Training loss: 0.012\t Validation loss: 0.012\n",
      "[491] Training loss: 0.012\t Validation loss: 0.012\n",
      "[492] Training loss: 0.012\t Validation loss: 0.012\n",
      "[493] Training loss: 0.012\t Validation loss: 0.012\n",
      "[494] Training loss: 0.012\t Validation loss: 0.012\n",
      "[495] Training loss: 0.011\t Validation loss: 0.011\n",
      "[496] Training loss: 0.011\t Validation loss: 0.011\n",
      "[497] Training loss: 0.011\t Validation loss: 0.011\n",
      "[498] Training loss: 0.011\t Validation loss: 0.011\n",
      "[499] Training loss: 0.011\t Validation loss: 0.011\n",
      "[500] Training loss: 0.011\t Validation loss: 0.011\n",
      "[501] Training loss: 0.011\t Validation loss: 0.011\n",
      "[502] Training loss: 0.011\t Validation loss: 0.011\n",
      "[503] Training loss: 0.011\t Validation loss: 0.011\n",
      "[504] Training loss: 0.011\t Validation loss: 0.011\n",
      "[505] Training loss: 0.010\t Validation loss: 0.010\n",
      "[506] Training loss: 0.010\t Validation loss: 0.010\n",
      "[507] Training loss: 0.010\t Validation loss: 0.010\n",
      "[508] Training loss: 0.010\t Validation loss: 0.010\n",
      "[509] Training loss: 0.010\t Validation loss: 0.010\n",
      "[510] Training loss: 0.010\t Validation loss: 0.010\n",
      "[511] Training loss: 0.010\t Validation loss: 0.010\n",
      "[512] Training loss: 0.010\t Validation loss: 0.010\n",
      "[513] Training loss: 0.010\t Validation loss: 0.010\n",
      "[514] Training loss: 0.010\t Validation loss: 0.010\n",
      "[515] Training loss: 0.010\t Validation loss: 0.010\n",
      "[516] Training loss: 0.009\t Validation loss: 0.009\n",
      "[517] Training loss: 0.009\t Validation loss: 0.009\n",
      "[518] Training loss: 0.009\t Validation loss: 0.009\n",
      "[519] Training loss: 0.009\t Validation loss: 0.009\n",
      "[520] Training loss: 0.009\t Validation loss: 0.009\n",
      "[521] Training loss: 0.009\t Validation loss: 0.009\n",
      "[522] Training loss: 0.009\t Validation loss: 0.009\n",
      "[523] Training loss: 0.009\t Validation loss: 0.009\n",
      "[524] Training loss: 0.009\t Validation loss: 0.009\n",
      "[525] Training loss: 0.009\t Validation loss: 0.009\n",
      "[526] Training loss: 0.009\t Validation loss: 0.009\n",
      "[527] Training loss: 0.009\t Validation loss: 0.009\n",
      "[528] Training loss: 0.008\t Validation loss: 0.008\n",
      "[529] Training loss: 0.008\t Validation loss: 0.008\n",
      "[530] Training loss: 0.008\t Validation loss: 0.008\n",
      "[531] Training loss: 0.008\t Validation loss: 0.008\n",
      "[532] Training loss: 0.008\t Validation loss: 0.008\n",
      "[533] Training loss: 0.008\t Validation loss: 0.008\n",
      "[534] Training loss: 0.008\t Validation loss: 0.008\n",
      "[535] Training loss: 0.008\t Validation loss: 0.008\n",
      "[536] Training loss: 0.008\t Validation loss: 0.008\n",
      "[537] Training loss: 0.008\t Validation loss: 0.008\n",
      "[538] Training loss: 0.008\t Validation loss: 0.008\n",
      "[539] Training loss: 0.008\t Validation loss: 0.008\n",
      "[540] Training loss: 0.008\t Validation loss: 0.008\n",
      "[541] Training loss: 0.008\t Validation loss: 0.008\n",
      "[542] Training loss: 0.008\t Validation loss: 0.008\n",
      "[543] Training loss: 0.007\t Validation loss: 0.007\n",
      "[544] Training loss: 0.007\t Validation loss: 0.007\n",
      "[545] Training loss: 0.007\t Validation loss: 0.007\n",
      "[546] Training loss: 0.007\t Validation loss: 0.007\n",
      "[547] Training loss: 0.007\t Validation loss: 0.007\n",
      "[548] Training loss: 0.007\t Validation loss: 0.007\n",
      "[549] Training loss: 0.007\t Validation loss: 0.007\n",
      "[550] Training loss: 0.007\t Validation loss: 0.007\n",
      "[551] Training loss: 0.007\t Validation loss: 0.007\n",
      "[552] Training loss: 0.007\t Validation loss: 0.007\n",
      "[553] Training loss: 0.007\t Validation loss: 0.007\n",
      "[554] Training loss: 0.007\t Validation loss: 0.007\n",
      "[555] Training loss: 0.007\t Validation loss: 0.007\n",
      "[556] Training loss: 0.007\t Validation loss: 0.007\n",
      "[557] Training loss: 0.007\t Validation loss: 0.007\n",
      "[558] Training loss: 0.007\t Validation loss: 0.007\n",
      "[559] Training loss: 0.007\t Validation loss: 0.007\n",
      "[560] Training loss: 0.007\t Validation loss: 0.007\n",
      "[561] Training loss: 0.006\t Validation loss: 0.007\n",
      "[562] Training loss: 0.006\t Validation loss: 0.006\n",
      "[563] Training loss: 0.006\t Validation loss: 0.006\n",
      "[564] Training loss: 0.006\t Validation loss: 0.006\n",
      "[565] Training loss: 0.006\t Validation loss: 0.006\n",
      "[566] Training loss: 0.006\t Validation loss: 0.006\n",
      "[567] Training loss: 0.006\t Validation loss: 0.006\n",
      "[568] Training loss: 0.006\t Validation loss: 0.006\n",
      "[569] Training loss: 0.006\t Validation loss: 0.006\n",
      "[570] Training loss: 0.006\t Validation loss: 0.006\n",
      "[571] Training loss: 0.006\t Validation loss: 0.006\n",
      "[572] Training loss: 0.006\t Validation loss: 0.006\n",
      "[573] Training loss: 0.006\t Validation loss: 0.006\n",
      "[574] Training loss: 0.006\t Validation loss: 0.006\n",
      "[575] Training loss: 0.006\t Validation loss: 0.006\n",
      "[576] Training loss: 0.006\t Validation loss: 0.006\n",
      "[577] Training loss: 0.006\t Validation loss: 0.006\n",
      "[578] Training loss: 0.006\t Validation loss: 0.006\n",
      "[579] Training loss: 0.006\t Validation loss: 0.006\n",
      "[580] Training loss: 0.006\t Validation loss: 0.006\n",
      "[581] Training loss: 0.006\t Validation loss: 0.006\n",
      "[582] Training loss: 0.006\t Validation loss: 0.006\n",
      "[583] Training loss: 0.006\t Validation loss: 0.006\n",
      "[584] Training loss: 0.006\t Validation loss: 0.006\n",
      "[585] Training loss: 0.006\t Validation loss: 0.006\n",
      "[586] Training loss: 0.005\t Validation loss: 0.005\n",
      "[587] Training loss: 0.005\t Validation loss: 0.005\n",
      "[588] Training loss: 0.005\t Validation loss: 0.005\n",
      "[589] Training loss: 0.005\t Validation loss: 0.005\n",
      "[590] Training loss: 0.005\t Validation loss: 0.005\n",
      "[591] Training loss: 0.005\t Validation loss: 0.005\n",
      "[592] Training loss: 0.005\t Validation loss: 0.005\n",
      "[593] Training loss: 0.005\t Validation loss: 0.005\n",
      "[594] Training loss: 0.005\t Validation loss: 0.005\n",
      "[595] Training loss: 0.005\t Validation loss: 0.005\n",
      "[596] Training loss: 0.005\t Validation loss: 0.005\n",
      "[597] Training loss: 0.005\t Validation loss: 0.005\n",
      "[598] Training loss: 0.005\t Validation loss: 0.005\n",
      "[599] Training loss: 0.005\t Validation loss: 0.005\n",
      "[600] Training loss: 0.005\t Validation loss: 0.005\n",
      "[601] Training loss: 0.005\t Validation loss: 0.005\n",
      "[602] Training loss: 0.005\t Validation loss: 0.005\n",
      "[603] Training loss: 0.005\t Validation loss: 0.005\n",
      "[604] Training loss: 0.005\t Validation loss: 0.005\n",
      "[605] Training loss: 0.005\t Validation loss: 0.005\n",
      "[606] Training loss: 0.005\t Validation loss: 0.005\n",
      "[607] Training loss: 0.005\t Validation loss: 0.005\n",
      "[608] Training loss: 0.005\t Validation loss: 0.005\n",
      "[609] Training loss: 0.005\t Validation loss: 0.005\n",
      "[610] Training loss: 0.005\t Validation loss: 0.005\n",
      "[611] Training loss: 0.005\t Validation loss: 0.005\n",
      "[612] Training loss: 0.005\t Validation loss: 0.005\n",
      "[613] Training loss: 0.005\t Validation loss: 0.005\n",
      "[614] Training loss: 0.005\t Validation loss: 0.005\n",
      "[615] Training loss: 0.005\t Validation loss: 0.005\n",
      "[616] Training loss: 0.005\t Validation loss: 0.005\n",
      "[617] Training loss: 0.005\t Validation loss: 0.005\n",
      "[618] Training loss: 0.005\t Validation loss: 0.005\n",
      "[619] Training loss: 0.005\t Validation loss: 0.005\n",
      "[620] Training loss: 0.005\t Validation loss: 0.005\n",
      "[621] Training loss: 0.004\t Validation loss: 0.004\n",
      "[622] Training loss: 0.004\t Validation loss: 0.004\n",
      "[623] Training loss: 0.004\t Validation loss: 0.004\n",
      "[624] Training loss: 0.004\t Validation loss: 0.004\n",
      "[625] Training loss: 0.004\t Validation loss: 0.004\n",
      "[626] Training loss: 0.004\t Validation loss: 0.004\n",
      "[627] Training loss: 0.004\t Validation loss: 0.004\n",
      "[628] Training loss: 0.004\t Validation loss: 0.004\n",
      "[629] Training loss: 0.004\t Validation loss: 0.004\n",
      "[630] Training loss: 0.004\t Validation loss: 0.004\n",
      "[631] Training loss: 0.004\t Validation loss: 0.004\n",
      "[632] Training loss: 0.004\t Validation loss: 0.004\n",
      "[633] Training loss: 0.004\t Validation loss: 0.004\n",
      "[634] Training loss: 0.004\t Validation loss: 0.004\n",
      "[635] Training loss: 0.004\t Validation loss: 0.004\n",
      "[636] Training loss: 0.004\t Validation loss: 0.004\n",
      "[637] Training loss: 0.004\t Validation loss: 0.004\n",
      "[638] Training loss: 0.004\t Validation loss: 0.004\n",
      "[639] Training loss: 0.004\t Validation loss: 0.004\n",
      "[640] Training loss: 0.004\t Validation loss: 0.004\n",
      "[641] Training loss: 0.004\t Validation loss: 0.004\n",
      "[642] Training loss: 0.004\t Validation loss: 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[643] Training loss: 0.004\t Validation loss: 0.004\n",
      "[644] Training loss: 0.004\t Validation loss: 0.004\n",
      "[645] Training loss: 0.004\t Validation loss: 0.004\n",
      "[646] Training loss: 0.004\t Validation loss: 0.004\n",
      "[647] Training loss: 0.004\t Validation loss: 0.004\n",
      "[648] Training loss: 0.004\t Validation loss: 0.004\n",
      "[649] Training loss: 0.004\t Validation loss: 0.004\n",
      "[650] Training loss: 0.004\t Validation loss: 0.004\n",
      "[651] Training loss: 0.004\t Validation loss: 0.004\n",
      "[652] Training loss: 0.004\t Validation loss: 0.004\n",
      "[653] Training loss: 0.004\t Validation loss: 0.004\n",
      "[654] Training loss: 0.004\t Validation loss: 0.004\n",
      "[655] Training loss: 0.004\t Validation loss: 0.004\n",
      "[656] Training loss: 0.004\t Validation loss: 0.004\n",
      "[657] Training loss: 0.004\t Validation loss: 0.004\n",
      "[658] Training loss: 0.004\t Validation loss: 0.004\n",
      "[659] Training loss: 0.004\t Validation loss: 0.004\n",
      "[660] Training loss: 0.004\t Validation loss: 0.004\n",
      "[661] Training loss: 0.004\t Validation loss: 0.004\n",
      "[662] Training loss: 0.004\t Validation loss: 0.004\n",
      "[663] Training loss: 0.004\t Validation loss: 0.004\n",
      "[664] Training loss: 0.004\t Validation loss: 0.004\n",
      "[665] Training loss: 0.004\t Validation loss: 0.004\n",
      "[666] Training loss: 0.004\t Validation loss: 0.004\n",
      "[667] Training loss: 0.004\t Validation loss: 0.004\n",
      "[668] Training loss: 0.004\t Validation loss: 0.004\n",
      "[669] Training loss: 0.004\t Validation loss: 0.004\n",
      "[670] Training loss: 0.004\t Validation loss: 0.004\n",
      "[671] Training loss: 0.004\t Validation loss: 0.004\n",
      "[672] Training loss: 0.004\t Validation loss: 0.004\n",
      "[673] Training loss: 0.004\t Validation loss: 0.004\n",
      "[674] Training loss: 0.004\t Validation loss: 0.004\n",
      "[675] Training loss: 0.004\t Validation loss: 0.004\n",
      "[676] Training loss: 0.004\t Validation loss: 0.004\n",
      "[677] Training loss: 0.004\t Validation loss: 0.004\n",
      "[678] Training loss: 0.004\t Validation loss: 0.004\n",
      "[679] Training loss: 0.004\t Validation loss: 0.004\n",
      "[680] Training loss: 0.004\t Validation loss: 0.004\n",
      "[681] Training loss: 0.004\t Validation loss: 0.004\n",
      "[682] Training loss: 0.004\t Validation loss: 0.004\n",
      "[683] Training loss: 0.004\t Validation loss: 0.004\n",
      "[684] Training loss: 0.003\t Validation loss: 0.003\n",
      "[685] Training loss: 0.003\t Validation loss: 0.003\n",
      "[686] Training loss: 0.003\t Validation loss: 0.003\n",
      "[687] Training loss: 0.003\t Validation loss: 0.003\n",
      "[688] Training loss: 0.003\t Validation loss: 0.003\n",
      "[689] Training loss: 0.003\t Validation loss: 0.003\n",
      "[690] Training loss: 0.003\t Validation loss: 0.003\n",
      "[691] Training loss: 0.003\t Validation loss: 0.003\n",
      "[692] Training loss: 0.003\t Validation loss: 0.003\n",
      "[693] Training loss: 0.003\t Validation loss: 0.003\n",
      "[694] Training loss: 0.003\t Validation loss: 0.003\n",
      "[695] Training loss: 0.003\t Validation loss: 0.003\n",
      "[696] Training loss: 0.003\t Validation loss: 0.003\n",
      "[697] Training loss: 0.003\t Validation loss: 0.003\n",
      "[698] Training loss: 0.003\t Validation loss: 0.003\n",
      "[699] Training loss: 0.003\t Validation loss: 0.003\n",
      "[700] Training loss: 0.003\t Validation loss: 0.003\n",
      "[701] Training loss: 0.003\t Validation loss: 0.003\n",
      "[702] Training loss: 0.003\t Validation loss: 0.003\n",
      "[703] Training loss: 0.003\t Validation loss: 0.003\n",
      "[704] Training loss: 0.003\t Validation loss: 0.003\n",
      "[705] Training loss: 0.003\t Validation loss: 0.003\n",
      "[706] Training loss: 0.003\t Validation loss: 0.003\n",
      "[707] Training loss: 0.003\t Validation loss: 0.003\n",
      "[708] Training loss: 0.003\t Validation loss: 0.003\n",
      "[709] Training loss: 0.003\t Validation loss: 0.003\n",
      "[710] Training loss: 0.003\t Validation loss: 0.003\n",
      "[711] Training loss: 0.003\t Validation loss: 0.003\n",
      "[712] Training loss: 0.003\t Validation loss: 0.003\n",
      "[713] Training loss: 0.003\t Validation loss: 0.003\n",
      "[714] Training loss: 0.003\t Validation loss: 0.003\n",
      "[715] Training loss: 0.003\t Validation loss: 0.003\n",
      "[716] Training loss: 0.003\t Validation loss: 0.003\n",
      "[717] Training loss: 0.003\t Validation loss: 0.003\n",
      "[718] Training loss: 0.003\t Validation loss: 0.003\n",
      "[719] Training loss: 0.003\t Validation loss: 0.003\n",
      "[720] Training loss: 0.003\t Validation loss: 0.003\n",
      "[721] Training loss: 0.003\t Validation loss: 0.003\n",
      "[722] Training loss: 0.003\t Validation loss: 0.003\n",
      "[723] Training loss: 0.003\t Validation loss: 0.003\n",
      "[724] Training loss: 0.003\t Validation loss: 0.003\n",
      "[725] Training loss: 0.003\t Validation loss: 0.003\n",
      "[726] Training loss: 0.003\t Validation loss: 0.003\n",
      "[727] Training loss: 0.003\t Validation loss: 0.003\n",
      "[728] Training loss: 0.003\t Validation loss: 0.003\n",
      "[729] Training loss: 0.003\t Validation loss: 0.003\n",
      "[730] Training loss: 0.003\t Validation loss: 0.003\n",
      "[731] Training loss: 0.003\t Validation loss: 0.003\n",
      "[732] Training loss: 0.003\t Validation loss: 0.003\n",
      "[733] Training loss: 0.003\t Validation loss: 0.003\n",
      "[734] Training loss: 0.003\t Validation loss: 0.003\n",
      "[735] Training loss: 0.003\t Validation loss: 0.003\n",
      "[736] Training loss: 0.003\t Validation loss: 0.003\n",
      "[737] Training loss: 0.003\t Validation loss: 0.003\n",
      "[738] Training loss: 0.003\t Validation loss: 0.003\n",
      "[739] Training loss: 0.003\t Validation loss: 0.003\n",
      "[740] Training loss: 0.003\t Validation loss: 0.003\n",
      "[741] Training loss: 0.003\t Validation loss: 0.003\n",
      "[742] Training loss: 0.003\t Validation loss: 0.003\n",
      "[743] Training loss: 0.003\t Validation loss: 0.003\n",
      "[744] Training loss: 0.003\t Validation loss: 0.003\n",
      "[745] Training loss: 0.003\t Validation loss: 0.003\n",
      "[746] Training loss: 0.003\t Validation loss: 0.003\n",
      "[747] Training loss: 0.003\t Validation loss: 0.003\n",
      "[748] Training loss: 0.003\t Validation loss: 0.003\n",
      "[749] Training loss: 0.003\t Validation loss: 0.003\n",
      "[750] Training loss: 0.003\t Validation loss: 0.003\n",
      "[751] Training loss: 0.003\t Validation loss: 0.003\n",
      "[752] Training loss: 0.003\t Validation loss: 0.003\n",
      "[753] Training loss: 0.003\t Validation loss: 0.003\n",
      "[754] Training loss: 0.003\t Validation loss: 0.003\n",
      "[755] Training loss: 0.003\t Validation loss: 0.003\n",
      "[756] Training loss: 0.003\t Validation loss: 0.003\n",
      "[757] Training loss: 0.003\t Validation loss: 0.003\n",
      "[758] Training loss: 0.003\t Validation loss: 0.003\n",
      "[759] Training loss: 0.003\t Validation loss: 0.003\n",
      "[760] Training loss: 0.003\t Validation loss: 0.003\n",
      "[761] Training loss: 0.003\t Validation loss: 0.003\n",
      "[762] Training loss: 0.003\t Validation loss: 0.003\n",
      "[763] Training loss: 0.003\t Validation loss: 0.003\n",
      "[764] Training loss: 0.003\t Validation loss: 0.003\n",
      "[765] Training loss: 0.003\t Validation loss: 0.003\n",
      "[766] Training loss: 0.003\t Validation loss: 0.003\n",
      "[767] Training loss: 0.003\t Validation loss: 0.003\n",
      "[768] Training loss: 0.003\t Validation loss: 0.003\n",
      "[769] Training loss: 0.003\t Validation loss: 0.003\n",
      "[770] Training loss: 0.003\t Validation loss: 0.003\n",
      "[771] Training loss: 0.003\t Validation loss: 0.003\n",
      "[772] Training loss: 0.003\t Validation loss: 0.003\n",
      "[773] Training loss: 0.003\t Validation loss: 0.003\n",
      "[774] Training loss: 0.003\t Validation loss: 0.003\n",
      "[775] Training loss: 0.003\t Validation loss: 0.003\n",
      "[776] Training loss: 0.003\t Validation loss: 0.003\n",
      "[777] Training loss: 0.003\t Validation loss: 0.003\n",
      "[778] Training loss: 0.003\t Validation loss: 0.003\n",
      "[779] Training loss: 0.003\t Validation loss: 0.003\n",
      "[780] Training loss: 0.003\t Validation loss: 0.003\n",
      "[781] Training loss: 0.003\t Validation loss: 0.003\n",
      "[782] Training loss: 0.003\t Validation loss: 0.003\n",
      "[783] Training loss: 0.003\t Validation loss: 0.003\n",
      "[784] Training loss: 0.003\t Validation loss: 0.003\n",
      "[785] Training loss: 0.003\t Validation loss: 0.003\n",
      "[786] Training loss: 0.003\t Validation loss: 0.003\n",
      "[787] Training loss: 0.003\t Validation loss: 0.003\n",
      "[788] Training loss: 0.003\t Validation loss: 0.003\n",
      "[789] Training loss: 0.003\t Validation loss: 0.003\n",
      "[790] Training loss: 0.003\t Validation loss: 0.003\n",
      "[791] Training loss: 0.003\t Validation loss: 0.003\n",
      "[792] Training loss: 0.003\t Validation loss: 0.003\n",
      "[793] Training loss: 0.003\t Validation loss: 0.003\n",
      "[794] Training loss: 0.003\t Validation loss: 0.003\n",
      "[795] Training loss: 0.003\t Validation loss: 0.003\n",
      "[796] Training loss: 0.003\t Validation loss: 0.003\n",
      "[797] Training loss: 0.003\t Validation loss: 0.003\n",
      "[798] Training loss: 0.003\t Validation loss: 0.003\n",
      "[799] Training loss: 0.003\t Validation loss: 0.003\n",
      "[800] Training loss: 0.003\t Validation loss: 0.003\n",
      "[801] Training loss: 0.003\t Validation loss: 0.003\n",
      "[802] Training loss: 0.003\t Validation loss: 0.003\n",
      "[803] Training loss: 0.003\t Validation loss: 0.003\n",
      "[804] Training loss: 0.003\t Validation loss: 0.003\n",
      "[805] Training loss: 0.003\t Validation loss: 0.003\n",
      "[806] Training loss: 0.003\t Validation loss: 0.003\n",
      "[807] Training loss: 0.003\t Validation loss: 0.003\n",
      "[808] Training loss: 0.003\t Validation loss: 0.003\n",
      "[809] Training loss: 0.003\t Validation loss: 0.003\n",
      "[810] Training loss: 0.003\t Validation loss: 0.003\n",
      "[811] Training loss: 0.003\t Validation loss: 0.003\n",
      "[812] Training loss: 0.003\t Validation loss: 0.003\n",
      "[813] Training loss: 0.003\t Validation loss: 0.003\n",
      "[814] Training loss: 0.003\t Validation loss: 0.003\n",
      "[815] Training loss: 0.003\t Validation loss: 0.003\n",
      "[816] Training loss: 0.003\t Validation loss: 0.003\n",
      "[817] Training loss: 0.003\t Validation loss: 0.003\n",
      "[818] Training loss: 0.003\t Validation loss: 0.003\n",
      "[819] Training loss: 0.003\t Validation loss: 0.003\n",
      "[820] Training loss: 0.003\t Validation loss: 0.003\n",
      "[821] Training loss: 0.003\t Validation loss: 0.003\n",
      "[822] Training loss: 0.003\t Validation loss: 0.003\n",
      "[823] Training loss: 0.003\t Validation loss: 0.003\n",
      "[824] Training loss: 0.003\t Validation loss: 0.003\n",
      "[825] Training loss: 0.003\t Validation loss: 0.003\n",
      "[826] Training loss: 0.003\t Validation loss: 0.003\n",
      "[827] Training loss: 0.003\t Validation loss: 0.003\n",
      "[828] Training loss: 0.003\t Validation loss: 0.003\n",
      "[829] Training loss: 0.003\t Validation loss: 0.003\n",
      "[830] Training loss: 0.003\t Validation loss: 0.003\n",
      "[831] Training loss: 0.003\t Validation loss: 0.003\n",
      "[832] Training loss: 0.003\t Validation loss: 0.003\n",
      "[833] Training loss: 0.003\t Validation loss: 0.003\n",
      "[834] Training loss: 0.003\t Validation loss: 0.003\n",
      "[835] Training loss: 0.003\t Validation loss: 0.003\n",
      "[836] Training loss: 0.003\t Validation loss: 0.003\n",
      "[837] Training loss: 0.003\t Validation loss: 0.002\n",
      "[838] Training loss: 0.002\t Validation loss: 0.002\n",
      "[839] Training loss: 0.002\t Validation loss: 0.002\n",
      "[840] Training loss: 0.002\t Validation loss: 0.002\n",
      "[841] Training loss: 0.002\t Validation loss: 0.002\n",
      "[842] Training loss: 0.002\t Validation loss: 0.002\n",
      "[843] Training loss: 0.002\t Validation loss: 0.002\n",
      "[844] Training loss: 0.002\t Validation loss: 0.002\n",
      "[845] Training loss: 0.002\t Validation loss: 0.002\n",
      "[846] Training loss: 0.002\t Validation loss: 0.002\n",
      "[847] Training loss: 0.002\t Validation loss: 0.002\n",
      "[848] Training loss: 0.002\t Validation loss: 0.002\n",
      "[849] Training loss: 0.002\t Validation loss: 0.002\n",
      "[850] Training loss: 0.002\t Validation loss: 0.002\n",
      "[851] Training loss: 0.002\t Validation loss: 0.002\n",
      "[852] Training loss: 0.002\t Validation loss: 0.002\n",
      "[853] Training loss: 0.002\t Validation loss: 0.002\n",
      "[854] Training loss: 0.002\t Validation loss: 0.002\n",
      "[855] Training loss: 0.002\t Validation loss: 0.002\n",
      "[856] Training loss: 0.002\t Validation loss: 0.002\n",
      "[857] Training loss: 0.002\t Validation loss: 0.002\n",
      "[858] Training loss: 0.002\t Validation loss: 0.002\n",
      "[859] Training loss: 0.002\t Validation loss: 0.002\n",
      "[860] Training loss: 0.002\t Validation loss: 0.002\n",
      "[861] Training loss: 0.002\t Validation loss: 0.002\n",
      "[862] Training loss: 0.002\t Validation loss: 0.002\n",
      "[863] Training loss: 0.002\t Validation loss: 0.002\n",
      "[864] Training loss: 0.002\t Validation loss: 0.002\n",
      "[865] Training loss: 0.002\t Validation loss: 0.002\n",
      "[866] Training loss: 0.002\t Validation loss: 0.002\n",
      "[867] Training loss: 0.002\t Validation loss: 0.002\n",
      "[868] Training loss: 0.002\t Validation loss: 0.002\n",
      "[869] Training loss: 0.002\t Validation loss: 0.002\n",
      "[870] Training loss: 0.002\t Validation loss: 0.002\n",
      "[871] Training loss: 0.002\t Validation loss: 0.002\n",
      "[872] Training loss: 0.002\t Validation loss: 0.002\n",
      "[873] Training loss: 0.002\t Validation loss: 0.002\n",
      "[874] Training loss: 0.002\t Validation loss: 0.002\n",
      "[875] Training loss: 0.002\t Validation loss: 0.002\n",
      "[876] Training loss: 0.002\t Validation loss: 0.002\n",
      "[877] Training loss: 0.002\t Validation loss: 0.002\n",
      "[878] Training loss: 0.002\t Validation loss: 0.002\n",
      "[879] Training loss: 0.002\t Validation loss: 0.002\n",
      "[880] Training loss: 0.002\t Validation loss: 0.002\n",
      "[881] Training loss: 0.002\t Validation loss: 0.002\n",
      "[882] Training loss: 0.002\t Validation loss: 0.002\n",
      "[883] Training loss: 0.002\t Validation loss: 0.002\n",
      "[884] Training loss: 0.002\t Validation loss: 0.002\n",
      "[885] Training loss: 0.002\t Validation loss: 0.002\n",
      "[886] Training loss: 0.002\t Validation loss: 0.002\n",
      "[887] Training loss: 0.002\t Validation loss: 0.002\n",
      "[888] Training loss: 0.002\t Validation loss: 0.002\n",
      "[889] Training loss: 0.002\t Validation loss: 0.002\n",
      "[890] Training loss: 0.002\t Validation loss: 0.002\n",
      "[891] Training loss: 0.002\t Validation loss: 0.002\n",
      "[892] Training loss: 0.002\t Validation loss: 0.002\n",
      "[893] Training loss: 0.002\t Validation loss: 0.002\n",
      "[894] Training loss: 0.002\t Validation loss: 0.002\n",
      "[895] Training loss: 0.002\t Validation loss: 0.002\n",
      "[896] Training loss: 0.002\t Validation loss: 0.002\n",
      "[897] Training loss: 0.002\t Validation loss: 0.002\n",
      "[898] Training loss: 0.002\t Validation loss: 0.002\n",
      "[899] Training loss: 0.002\t Validation loss: 0.002\n",
      "[900] Training loss: 0.002\t Validation loss: 0.002\n",
      "[901] Training loss: 0.002\t Validation loss: 0.002\n",
      "[902] Training loss: 0.002\t Validation loss: 0.002\n",
      "[903] Training loss: 0.002\t Validation loss: 0.002\n",
      "[904] Training loss: 0.002\t Validation loss: 0.002\n",
      "[905] Training loss: 0.002\t Validation loss: 0.002\n",
      "[906] Training loss: 0.002\t Validation loss: 0.002\n",
      "[907] Training loss: 0.002\t Validation loss: 0.002\n",
      "[908] Training loss: 0.002\t Validation loss: 0.002\n",
      "[909] Training loss: 0.002\t Validation loss: 0.002\n",
      "[910] Training loss: 0.002\t Validation loss: 0.002\n",
      "[911] Training loss: 0.002\t Validation loss: 0.002\n",
      "[912] Training loss: 0.002\t Validation loss: 0.002\n",
      "[913] Training loss: 0.002\t Validation loss: 0.002\n",
      "[914] Training loss: 0.002\t Validation loss: 0.002\n",
      "[915] Training loss: 0.002\t Validation loss: 0.002\n",
      "[916] Training loss: 0.002\t Validation loss: 0.002\n",
      "[917] Training loss: 0.002\t Validation loss: 0.002\n",
      "[918] Training loss: 0.002\t Validation loss: 0.002\n",
      "[919] Training loss: 0.002\t Validation loss: 0.002\n",
      "[920] Training loss: 0.002\t Validation loss: 0.002\n",
      "[921] Training loss: 0.002\t Validation loss: 0.002\n",
      "[922] Training loss: 0.002\t Validation loss: 0.002\n",
      "[923] Training loss: 0.002\t Validation loss: 0.002\n",
      "[924] Training loss: 0.002\t Validation loss: 0.002\n",
      "[925] Training loss: 0.002\t Validation loss: 0.002\n",
      "[926] Training loss: 0.002\t Validation loss: 0.002\n",
      "[927] Training loss: 0.002\t Validation loss: 0.002\n",
      "[928] Training loss: 0.002\t Validation loss: 0.002\n",
      "[929] Training loss: 0.002\t Validation loss: 0.002\n",
      "[930] Training loss: 0.002\t Validation loss: 0.002\n",
      "[931] Training loss: 0.002\t Validation loss: 0.002\n",
      "[932] Training loss: 0.002\t Validation loss: 0.002\n",
      "[933] Training loss: 0.002\t Validation loss: 0.002\n",
      "[934] Training loss: 0.002\t Validation loss: 0.002\n",
      "[935] Training loss: 0.002\t Validation loss: 0.002\n",
      "[936] Training loss: 0.002\t Validation loss: 0.002\n",
      "[937] Training loss: 0.002\t Validation loss: 0.002\n",
      "[938] Training loss: 0.002\t Validation loss: 0.002\n",
      "[939] Training loss: 0.002\t Validation loss: 0.002\n",
      "[940] Training loss: 0.002\t Validation loss: 0.002\n",
      "[941] Training loss: 0.002\t Validation loss: 0.002\n",
      "[942] Training loss: 0.002\t Validation loss: 0.002\n",
      "[943] Training loss: 0.002\t Validation loss: 0.002\n",
      "[944] Training loss: 0.002\t Validation loss: 0.002\n",
      "[945] Training loss: 0.002\t Validation loss: 0.002\n",
      "[946] Training loss: 0.002\t Validation loss: 0.002\n",
      "[947] Training loss: 0.002\t Validation loss: 0.002\n",
      "[948] Training loss: 0.002\t Validation loss: 0.002\n",
      "[949] Training loss: 0.002\t Validation loss: 0.002\n",
      "[950] Training loss: 0.002\t Validation loss: 0.002\n",
      "[951] Training loss: 0.002\t Validation loss: 0.002\n",
      "[952] Training loss: 0.002\t Validation loss: 0.002\n",
      "[953] Training loss: 0.002\t Validation loss: 0.002\n",
      "[954] Training loss: 0.002\t Validation loss: 0.002\n",
      "[955] Training loss: 0.002\t Validation loss: 0.002\n",
      "[956] Training loss: 0.002\t Validation loss: 0.002\n",
      "[957] Training loss: 0.002\t Validation loss: 0.002\n",
      "[958] Training loss: 0.002\t Validation loss: 0.002\n",
      "[959] Training loss: 0.002\t Validation loss: 0.002\n",
      "[960] Training loss: 0.002\t Validation loss: 0.002\n",
      "[961] Training loss: 0.002\t Validation loss: 0.002\n",
      "[962] Training loss: 0.002\t Validation loss: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[963] Training loss: 0.002\t Validation loss: 0.002\n",
      "[964] Training loss: 0.002\t Validation loss: 0.002\n",
      "[965] Training loss: 0.002\t Validation loss: 0.002\n",
      "[966] Training loss: 0.002\t Validation loss: 0.002\n",
      "[967] Training loss: 0.002\t Validation loss: 0.002\n",
      "[968] Training loss: 0.002\t Validation loss: 0.002\n",
      "[969] Training loss: 0.002\t Validation loss: 0.002\n",
      "[970] Training loss: 0.002\t Validation loss: 0.002\n",
      "[971] Training loss: 0.002\t Validation loss: 0.002\n",
      "[972] Training loss: 0.002\t Validation loss: 0.002\n",
      "[973] Training loss: 0.002\t Validation loss: 0.002\n",
      "[974] Training loss: 0.002\t Validation loss: 0.002\n",
      "[975] Training loss: 0.002\t Validation loss: 0.002\n",
      "[976] Training loss: 0.002\t Validation loss: 0.002\n",
      "[977] Training loss: 0.002\t Validation loss: 0.002\n",
      "[978] Training loss: 0.002\t Validation loss: 0.002\n",
      "[979] Training loss: 0.002\t Validation loss: 0.002\n",
      "[980] Training loss: 0.002\t Validation loss: 0.002\n",
      "[981] Training loss: 0.002\t Validation loss: 0.002\n",
      "[982] Training loss: 0.002\t Validation loss: 0.002\n",
      "[983] Training loss: 0.002\t Validation loss: 0.002\n",
      "[984] Training loss: 0.002\t Validation loss: 0.002\n",
      "[985] Training loss: 0.002\t Validation loss: 0.002\n",
      "[986] Training loss: 0.002\t Validation loss: 0.002\n",
      "[987] Training loss: 0.002\t Validation loss: 0.002\n",
      "[988] Training loss: 0.002\t Validation loss: 0.002\n",
      "[989] Training loss: 0.002\t Validation loss: 0.002\n",
      "[990] Training loss: 0.002\t Validation loss: 0.002\n",
      "[991] Training loss: 0.002\t Validation loss: 0.002\n",
      "[992] Training loss: 0.002\t Validation loss: 0.002\n",
      "[993] Training loss: 0.002\t Validation loss: 0.002\n",
      "[994] Training loss: 0.002\t Validation loss: 0.002\n",
      "[995] Training loss: 0.002\t Validation loss: 0.002\n",
      "[996] Training loss: 0.002\t Validation loss: 0.002\n",
      "[997] Training loss: 0.002\t Validation loss: 0.002\n",
      "[998] Training loss: 0.002\t Validation loss: 0.002\n",
      "[999] Training loss: 0.002\t Validation loss: 0.002\n",
      "[1000] Training loss: 0.002\t Validation loss: 0.002\n",
      "3684 Samples\n",
      "\n",
      "GraphConvolution()\n",
      "[1] Training loss: 0.314\t Validation loss: 0.305\n",
      "[2] Training loss: 0.310\t Validation loss: 0.302\n",
      "[3] Training loss: 0.307\t Validation loss: 0.298\n",
      "[4] Training loss: 0.303\t Validation loss: 0.295\n",
      "[5] Training loss: 0.300\t Validation loss: 0.291\n",
      "[6] Training loss: 0.296\t Validation loss: 0.288\n",
      "[7] Training loss: 0.293\t Validation loss: 0.285\n",
      "[8] Training loss: 0.289\t Validation loss: 0.281\n",
      "[9] Training loss: 0.286\t Validation loss: 0.278\n",
      "[10] Training loss: 0.283\t Validation loss: 0.275\n",
      "[11] Training loss: 0.279\t Validation loss: 0.271\n",
      "[12] Training loss: 0.276\t Validation loss: 0.268\n",
      "[13] Training loss: 0.273\t Validation loss: 0.265\n",
      "[14] Training loss: 0.269\t Validation loss: 0.262\n",
      "[15] Training loss: 0.266\t Validation loss: 0.259\n",
      "[16] Training loss: 0.263\t Validation loss: 0.255\n",
      "[17] Training loss: 0.260\t Validation loss: 0.252\n",
      "[18] Training loss: 0.256\t Validation loss: 0.249\n",
      "[19] Training loss: 0.253\t Validation loss: 0.246\n",
      "[20] Training loss: 0.250\t Validation loss: 0.243\n",
      "[21] Training loss: 0.247\t Validation loss: 0.240\n",
      "[22] Training loss: 0.244\t Validation loss: 0.237\n",
      "[23] Training loss: 0.241\t Validation loss: 0.234\n",
      "[24] Training loss: 0.238\t Validation loss: 0.231\n",
      "[25] Training loss: 0.235\t Validation loss: 0.228\n",
      "[26] Training loss: 0.232\t Validation loss: 0.225\n",
      "[27] Training loss: 0.229\t Validation loss: 0.223\n",
      "[28] Training loss: 0.226\t Validation loss: 0.220\n",
      "[29] Training loss: 0.223\t Validation loss: 0.217\n",
      "[30] Training loss: 0.220\t Validation loss: 0.214\n",
      "[31] Training loss: 0.217\t Validation loss: 0.211\n",
      "[32] Training loss: 0.215\t Validation loss: 0.209\n",
      "[33] Training loss: 0.212\t Validation loss: 0.206\n",
      "[34] Training loss: 0.209\t Validation loss: 0.203\n",
      "[35] Training loss: 0.206\t Validation loss: 0.201\n",
      "[36] Training loss: 0.204\t Validation loss: 0.198\n",
      "[37] Training loss: 0.201\t Validation loss: 0.195\n",
      "[38] Training loss: 0.198\t Validation loss: 0.193\n",
      "[39] Training loss: 0.196\t Validation loss: 0.190\n",
      "[40] Training loss: 0.193\t Validation loss: 0.188\n",
      "[41] Training loss: 0.191\t Validation loss: 0.185\n",
      "[42] Training loss: 0.188\t Validation loss: 0.183\n",
      "[43] Training loss: 0.185\t Validation loss: 0.180\n",
      "[44] Training loss: 0.183\t Validation loss: 0.178\n",
      "[45] Training loss: 0.181\t Validation loss: 0.176\n",
      "[46] Training loss: 0.178\t Validation loss: 0.173\n",
      "[47] Training loss: 0.176\t Validation loss: 0.171\n",
      "[48] Training loss: 0.173\t Validation loss: 0.169\n",
      "[49] Training loss: 0.171\t Validation loss: 0.166\n",
      "[50] Training loss: 0.169\t Validation loss: 0.164\n",
      "[51] Training loss: 0.166\t Validation loss: 0.162\n",
      "[52] Training loss: 0.164\t Validation loss: 0.160\n",
      "[53] Training loss: 0.162\t Validation loss: 0.157\n",
      "[54] Training loss: 0.159\t Validation loss: 0.155\n",
      "[55] Training loss: 0.157\t Validation loss: 0.153\n",
      "[56] Training loss: 0.155\t Validation loss: 0.151\n",
      "[57] Training loss: 0.153\t Validation loss: 0.149\n",
      "[58] Training loss: 0.151\t Validation loss: 0.147\n",
      "[59] Training loss: 0.149\t Validation loss: 0.145\n",
      "[60] Training loss: 0.147\t Validation loss: 0.143\n",
      "[61] Training loss: 0.144\t Validation loss: 0.141\n",
      "[62] Training loss: 0.142\t Validation loss: 0.139\n",
      "[63] Training loss: 0.140\t Validation loss: 0.137\n",
      "[64] Training loss: 0.138\t Validation loss: 0.135\n",
      "[65] Training loss: 0.136\t Validation loss: 0.133\n",
      "[66] Training loss: 0.134\t Validation loss: 0.131\n",
      "[67] Training loss: 0.133\t Validation loss: 0.129\n",
      "[68] Training loss: 0.131\t Validation loss: 0.127\n",
      "[69] Training loss: 0.129\t Validation loss: 0.125\n",
      "[70] Training loss: 0.127\t Validation loss: 0.124\n",
      "[71] Training loss: 0.125\t Validation loss: 0.122\n",
      "[72] Training loss: 0.123\t Validation loss: 0.120\n",
      "[73] Training loss: 0.121\t Validation loss: 0.118\n",
      "[74] Training loss: 0.120\t Validation loss: 0.117\n",
      "[75] Training loss: 0.118\t Validation loss: 0.115\n",
      "[76] Training loss: 0.116\t Validation loss: 0.113\n",
      "[77] Training loss: 0.114\t Validation loss: 0.111\n",
      "[78] Training loss: 0.113\t Validation loss: 0.110\n",
      "[79] Training loss: 0.111\t Validation loss: 0.108\n",
      "[80] Training loss: 0.109\t Validation loss: 0.107\n",
      "[81] Training loss: 0.108\t Validation loss: 0.105\n",
      "[82] Training loss: 0.106\t Validation loss: 0.103\n",
      "[83] Training loss: 0.105\t Validation loss: 0.102\n",
      "[84] Training loss: 0.103\t Validation loss: 0.100\n",
      "[85] Training loss: 0.102\t Validation loss: 0.099\n",
      "[86] Training loss: 0.100\t Validation loss: 0.097\n",
      "[87] Training loss: 0.098\t Validation loss: 0.096\n",
      "[88] Training loss: 0.097\t Validation loss: 0.095\n",
      "[89] Training loss: 0.096\t Validation loss: 0.093\n",
      "[90] Training loss: 0.094\t Validation loss: 0.092\n",
      "[91] Training loss: 0.093\t Validation loss: 0.090\n",
      "[92] Training loss: 0.091\t Validation loss: 0.089\n",
      "[93] Training loss: 0.090\t Validation loss: 0.088\n",
      "[94] Training loss: 0.088\t Validation loss: 0.086\n",
      "[95] Training loss: 0.087\t Validation loss: 0.085\n",
      "[96] Training loss: 0.086\t Validation loss: 0.084\n",
      "[97] Training loss: 0.084\t Validation loss: 0.082\n",
      "[98] Training loss: 0.083\t Validation loss: 0.081\n",
      "[99] Training loss: 0.082\t Validation loss: 0.080\n",
      "[100] Training loss: 0.081\t Validation loss: 0.079\n",
      "[101] Training loss: 0.079\t Validation loss: 0.077\n",
      "[102] Training loss: 0.078\t Validation loss: 0.076\n",
      "[103] Training loss: 0.077\t Validation loss: 0.075\n",
      "[104] Training loss: 0.076\t Validation loss: 0.074\n",
      "[105] Training loss: 0.074\t Validation loss: 0.073\n",
      "[106] Training loss: 0.073\t Validation loss: 0.072\n",
      "[107] Training loss: 0.072\t Validation loss: 0.070\n",
      "[108] Training loss: 0.071\t Validation loss: 0.069\n",
      "[109] Training loss: 0.070\t Validation loss: 0.068\n",
      "[110] Training loss: 0.069\t Validation loss: 0.067\n",
      "[111] Training loss: 0.068\t Validation loss: 0.066\n",
      "[112] Training loss: 0.067\t Validation loss: 0.065\n",
      "[113] Training loss: 0.066\t Validation loss: 0.064\n",
      "[114] Training loss: 0.064\t Validation loss: 0.063\n",
      "[115] Training loss: 0.063\t Validation loss: 0.062\n",
      "[116] Training loss: 0.062\t Validation loss: 0.061\n",
      "[117] Training loss: 0.061\t Validation loss: 0.060\n",
      "[118] Training loss: 0.060\t Validation loss: 0.059\n",
      "[119] Training loss: 0.059\t Validation loss: 0.058\n",
      "[120] Training loss: 0.058\t Validation loss: 0.057\n",
      "[121] Training loss: 0.058\t Validation loss: 0.056\n",
      "[122] Training loss: 0.057\t Validation loss: 0.055\n",
      "[123] Training loss: 0.056\t Validation loss: 0.054\n",
      "[124] Training loss: 0.055\t Validation loss: 0.054\n",
      "[125] Training loss: 0.054\t Validation loss: 0.053\n",
      "[126] Training loss: 0.053\t Validation loss: 0.052\n",
      "[127] Training loss: 0.052\t Validation loss: 0.051\n",
      "[128] Training loss: 0.051\t Validation loss: 0.050\n",
      "[129] Training loss: 0.050\t Validation loss: 0.049\n",
      "[130] Training loss: 0.050\t Validation loss: 0.049\n",
      "[131] Training loss: 0.049\t Validation loss: 0.048\n",
      "[132] Training loss: 0.048\t Validation loss: 0.047\n",
      "[133] Training loss: 0.047\t Validation loss: 0.046\n",
      "[134] Training loss: 0.046\t Validation loss: 0.046\n",
      "[135] Training loss: 0.046\t Validation loss: 0.045\n",
      "[136] Training loss: 0.045\t Validation loss: 0.044\n",
      "[137] Training loss: 0.044\t Validation loss: 0.043\n",
      "[138] Training loss: 0.043\t Validation loss: 0.043\n",
      "[139] Training loss: 0.043\t Validation loss: 0.042\n",
      "[140] Training loss: 0.042\t Validation loss: 0.041\n",
      "[141] Training loss: 0.041\t Validation loss: 0.041\n",
      "[142] Training loss: 0.041\t Validation loss: 0.040\n",
      "[143] Training loss: 0.040\t Validation loss: 0.039\n",
      "[144] Training loss: 0.039\t Validation loss: 0.039\n",
      "[145] Training loss: 0.039\t Validation loss: 0.038\n",
      "[146] Training loss: 0.038\t Validation loss: 0.037\n",
      "[147] Training loss: 0.037\t Validation loss: 0.037\n",
      "[148] Training loss: 0.037\t Validation loss: 0.036\n",
      "[149] Training loss: 0.036\t Validation loss: 0.036\n",
      "[150] Training loss: 0.036\t Validation loss: 0.035\n",
      "[151] Training loss: 0.035\t Validation loss: 0.034\n",
      "[152] Training loss: 0.034\t Validation loss: 0.034\n",
      "[153] Training loss: 0.034\t Validation loss: 0.033\n",
      "[154] Training loss: 0.033\t Validation loss: 0.033\n",
      "[155] Training loss: 0.033\t Validation loss: 0.032\n",
      "[156] Training loss: 0.032\t Validation loss: 0.032\n",
      "[157] Training loss: 0.032\t Validation loss: 0.031\n",
      "[158] Training loss: 0.031\t Validation loss: 0.031\n",
      "[159] Training loss: 0.031\t Validation loss: 0.030\n",
      "[160] Training loss: 0.030\t Validation loss: 0.030\n",
      "[161] Training loss: 0.030\t Validation loss: 0.029\n",
      "[162] Training loss: 0.029\t Validation loss: 0.029\n",
      "[163] Training loss: 0.029\t Validation loss: 0.028\n",
      "[164] Training loss: 0.028\t Validation loss: 0.028\n",
      "[165] Training loss: 0.028\t Validation loss: 0.027\n",
      "[166] Training loss: 0.027\t Validation loss: 0.027\n",
      "[167] Training loss: 0.027\t Validation loss: 0.026\n",
      "[168] Training loss: 0.026\t Validation loss: 0.026\n",
      "[169] Training loss: 0.026\t Validation loss: 0.026\n",
      "[170] Training loss: 0.025\t Validation loss: 0.025\n",
      "[171] Training loss: 0.025\t Validation loss: 0.025\n",
      "[172] Training loss: 0.025\t Validation loss: 0.024\n",
      "[173] Training loss: 0.024\t Validation loss: 0.024\n",
      "[174] Training loss: 0.024\t Validation loss: 0.024\n",
      "[175] Training loss: 0.023\t Validation loss: 0.023\n",
      "[176] Training loss: 0.023\t Validation loss: 0.023\n",
      "[177] Training loss: 0.023\t Validation loss: 0.022\n",
      "[178] Training loss: 0.022\t Validation loss: 0.022\n",
      "[179] Training loss: 0.022\t Validation loss: 0.022\n",
      "[180] Training loss: 0.022\t Validation loss: 0.021\n",
      "[181] Training loss: 0.021\t Validation loss: 0.021\n",
      "[182] Training loss: 0.021\t Validation loss: 0.021\n",
      "[183] Training loss: 0.021\t Validation loss: 0.020\n",
      "[184] Training loss: 0.020\t Validation loss: 0.020\n",
      "[185] Training loss: 0.020\t Validation loss: 0.020\n",
      "[186] Training loss: 0.020\t Validation loss: 0.019\n",
      "[187] Training loss: 0.019\t Validation loss: 0.019\n",
      "[188] Training loss: 0.019\t Validation loss: 0.019\n",
      "[189] Training loss: 0.019\t Validation loss: 0.019\n",
      "[190] Training loss: 0.018\t Validation loss: 0.018\n",
      "[191] Training loss: 0.018\t Validation loss: 0.018\n",
      "[192] Training loss: 0.018\t Validation loss: 0.018\n",
      "[193] Training loss: 0.018\t Validation loss: 0.017\n",
      "[194] Training loss: 0.017\t Validation loss: 0.017\n",
      "[195] Training loss: 0.017\t Validation loss: 0.017\n",
      "[196] Training loss: 0.017\t Validation loss: 0.017\n",
      "[197] Training loss: 0.016\t Validation loss: 0.016\n",
      "[198] Training loss: 0.016\t Validation loss: 0.016\n",
      "[199] Training loss: 0.016\t Validation loss: 0.016\n",
      "[200] Training loss: 0.016\t Validation loss: 0.016\n",
      "[201] Training loss: 0.015\t Validation loss: 0.015\n",
      "[202] Training loss: 0.015\t Validation loss: 0.015\n",
      "[203] Training loss: 0.015\t Validation loss: 0.015\n",
      "[204] Training loss: 0.015\t Validation loss: 0.015\n",
      "[205] Training loss: 0.015\t Validation loss: 0.015\n",
      "[206] Training loss: 0.014\t Validation loss: 0.014\n",
      "[207] Training loss: 0.014\t Validation loss: 0.014\n",
      "[208] Training loss: 0.014\t Validation loss: 0.014\n",
      "[209] Training loss: 0.014\t Validation loss: 0.014\n",
      "[210] Training loss: 0.014\t Validation loss: 0.013\n",
      "[211] Training loss: 0.013\t Validation loss: 0.013\n",
      "[212] Training loss: 0.013\t Validation loss: 0.013\n",
      "[213] Training loss: 0.013\t Validation loss: 0.013\n",
      "[214] Training loss: 0.013\t Validation loss: 0.013\n",
      "[215] Training loss: 0.013\t Validation loss: 0.013\n",
      "[216] Training loss: 0.012\t Validation loss: 0.012\n",
      "[217] Training loss: 0.012\t Validation loss: 0.012\n",
      "[218] Training loss: 0.012\t Validation loss: 0.012\n",
      "[219] Training loss: 0.012\t Validation loss: 0.012\n",
      "[220] Training loss: 0.012\t Validation loss: 0.012\n",
      "[221] Training loss: 0.012\t Validation loss: 0.012\n",
      "[222] Training loss: 0.011\t Validation loss: 0.011\n",
      "[223] Training loss: 0.011\t Validation loss: 0.011\n",
      "[224] Training loss: 0.011\t Validation loss: 0.011\n",
      "[225] Training loss: 0.011\t Validation loss: 0.011\n",
      "[226] Training loss: 0.011\t Validation loss: 0.011\n",
      "[227] Training loss: 0.011\t Validation loss: 0.011\n",
      "[228] Training loss: 0.010\t Validation loss: 0.011\n",
      "[229] Training loss: 0.010\t Validation loss: 0.010\n",
      "[230] Training loss: 0.010\t Validation loss: 0.010\n",
      "[231] Training loss: 0.010\t Validation loss: 0.010\n",
      "[232] Training loss: 0.010\t Validation loss: 0.010\n",
      "[233] Training loss: 0.010\t Validation loss: 0.010\n",
      "[234] Training loss: 0.010\t Validation loss: 0.010\n",
      "[235] Training loss: 0.010\t Validation loss: 0.010\n",
      "[236] Training loss: 0.009\t Validation loss: 0.010\n",
      "[237] Training loss: 0.009\t Validation loss: 0.009\n",
      "[238] Training loss: 0.009\t Validation loss: 0.009\n",
      "[239] Training loss: 0.009\t Validation loss: 0.009\n",
      "[240] Training loss: 0.009\t Validation loss: 0.009\n",
      "[241] Training loss: 0.009\t Validation loss: 0.009\n",
      "[242] Training loss: 0.009\t Validation loss: 0.009\n",
      "[243] Training loss: 0.009\t Validation loss: 0.009\n",
      "[244] Training loss: 0.009\t Validation loss: 0.009\n",
      "[245] Training loss: 0.009\t Validation loss: 0.009\n",
      "[246] Training loss: 0.008\t Validation loss: 0.009\n",
      "[247] Training loss: 0.008\t Validation loss: 0.008\n",
      "[248] Training loss: 0.008\t Validation loss: 0.008\n",
      "[249] Training loss: 0.008\t Validation loss: 0.008\n",
      "[250] Training loss: 0.008\t Validation loss: 0.008\n",
      "[251] Training loss: 0.008\t Validation loss: 0.008\n",
      "[252] Training loss: 0.008\t Validation loss: 0.008\n",
      "[253] Training loss: 0.008\t Validation loss: 0.008\n",
      "[254] Training loss: 0.008\t Validation loss: 0.008\n",
      "[255] Training loss: 0.008\t Validation loss: 0.008\n",
      "[256] Training loss: 0.008\t Validation loss: 0.008\n",
      "[257] Training loss: 0.008\t Validation loss: 0.008\n",
      "[258] Training loss: 0.007\t Validation loss: 0.008\n",
      "[259] Training loss: 0.007\t Validation loss: 0.007\n",
      "[260] Training loss: 0.007\t Validation loss: 0.007\n",
      "[261] Training loss: 0.007\t Validation loss: 0.007\n",
      "[262] Training loss: 0.007\t Validation loss: 0.007\n",
      "[263] Training loss: 0.007\t Validation loss: 0.007\n",
      "[264] Training loss: 0.007\t Validation loss: 0.007\n",
      "[265] Training loss: 0.007\t Validation loss: 0.007\n",
      "[266] Training loss: 0.007\t Validation loss: 0.007\n",
      "[267] Training loss: 0.007\t Validation loss: 0.007\n",
      "[268] Training loss: 0.007\t Validation loss: 0.007\n",
      "[269] Training loss: 0.007\t Validation loss: 0.007\n",
      "[270] Training loss: 0.007\t Validation loss: 0.007\n",
      "[271] Training loss: 0.007\t Validation loss: 0.007\n",
      "[272] Training loss: 0.007\t Validation loss: 0.007\n",
      "[273] Training loss: 0.006\t Validation loss: 0.007\n",
      "[274] Training loss: 0.006\t Validation loss: 0.007\n",
      "[275] Training loss: 0.006\t Validation loss: 0.006\n",
      "[276] Training loss: 0.006\t Validation loss: 0.006\n",
      "[277] Training loss: 0.006\t Validation loss: 0.006\n",
      "[278] Training loss: 0.006\t Validation loss: 0.006\n",
      "[279] Training loss: 0.006\t Validation loss: 0.006\n",
      "[280] Training loss: 0.006\t Validation loss: 0.006\n",
      "[281] Training loss: 0.006\t Validation loss: 0.006\n",
      "[282] Training loss: 0.006\t Validation loss: 0.006\n",
      "[283] Training loss: 0.006\t Validation loss: 0.006\n",
      "[284] Training loss: 0.006\t Validation loss: 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[285] Training loss: 0.006\t Validation loss: 0.006\n",
      "[286] Training loss: 0.006\t Validation loss: 0.006\n",
      "[287] Training loss: 0.006\t Validation loss: 0.006\n",
      "[288] Training loss: 0.006\t Validation loss: 0.006\n",
      "[289] Training loss: 0.006\t Validation loss: 0.006\n",
      "[290] Training loss: 0.006\t Validation loss: 0.006\n",
      "[291] Training loss: 0.006\t Validation loss: 0.006\n",
      "[292] Training loss: 0.006\t Validation loss: 0.006\n",
      "[293] Training loss: 0.006\t Validation loss: 0.006\n",
      "[294] Training loss: 0.006\t Validation loss: 0.006\n",
      "[295] Training loss: 0.006\t Validation loss: 0.006\n",
      "[296] Training loss: 0.006\t Validation loss: 0.006\n",
      "[297] Training loss: 0.005\t Validation loss: 0.006\n",
      "[298] Training loss: 0.005\t Validation loss: 0.006\n",
      "[299] Training loss: 0.005\t Validation loss: 0.006\n",
      "[300] Training loss: 0.005\t Validation loss: 0.006\n",
      "[301] Training loss: 0.005\t Validation loss: 0.005\n",
      "[302] Training loss: 0.005\t Validation loss: 0.005\n",
      "[303] Training loss: 0.005\t Validation loss: 0.005\n",
      "[304] Training loss: 0.005\t Validation loss: 0.005\n",
      "[305] Training loss: 0.005\t Validation loss: 0.005\n",
      "[306] Training loss: 0.005\t Validation loss: 0.005\n",
      "[307] Training loss: 0.005\t Validation loss: 0.005\n",
      "[308] Training loss: 0.005\t Validation loss: 0.005\n",
      "[309] Training loss: 0.005\t Validation loss: 0.005\n",
      "[310] Training loss: 0.005\t Validation loss: 0.005\n",
      "[311] Training loss: 0.005\t Validation loss: 0.005\n",
      "[312] Training loss: 0.005\t Validation loss: 0.005\n",
      "[313] Training loss: 0.005\t Validation loss: 0.005\n",
      "[314] Training loss: 0.005\t Validation loss: 0.005\n",
      "[315] Training loss: 0.005\t Validation loss: 0.005\n",
      "[316] Training loss: 0.005\t Validation loss: 0.005\n",
      "[317] Training loss: 0.005\t Validation loss: 0.005\n",
      "[318] Training loss: 0.005\t Validation loss: 0.005\n",
      "[319] Training loss: 0.005\t Validation loss: 0.005\n",
      "[320] Training loss: 0.005\t Validation loss: 0.005\n",
      "[321] Training loss: 0.005\t Validation loss: 0.005\n",
      "[322] Training loss: 0.005\t Validation loss: 0.005\n",
      "[323] Training loss: 0.005\t Validation loss: 0.005\n",
      "[324] Training loss: 0.005\t Validation loss: 0.005\n",
      "[325] Training loss: 0.005\t Validation loss: 0.005\n",
      "[326] Training loss: 0.005\t Validation loss: 0.005\n",
      "[327] Training loss: 0.005\t Validation loss: 0.005\n",
      "[328] Training loss: 0.005\t Validation loss: 0.005\n",
      "[329] Training loss: 0.005\t Validation loss: 0.005\n",
      "[330] Training loss: 0.005\t Validation loss: 0.005\n",
      "[331] Training loss: 0.005\t Validation loss: 0.005\n",
      "[332] Training loss: 0.005\t Validation loss: 0.005\n",
      "[333] Training loss: 0.005\t Validation loss: 0.005\n",
      "[334] Training loss: 0.005\t Validation loss: 0.005\n",
      "[335] Training loss: 0.005\t Validation loss: 0.005\n",
      "[336] Training loss: 0.005\t Validation loss: 0.005\n",
      "[337] Training loss: 0.005\t Validation loss: 0.005\n",
      "[338] Training loss: 0.005\t Validation loss: 0.005\n",
      "[339] Training loss: 0.005\t Validation loss: 0.005\n",
      "[340] Training loss: 0.005\t Validation loss: 0.005\n",
      "[341] Training loss: 0.004\t Validation loss: 0.005\n",
      "[342] Training loss: 0.004\t Validation loss: 0.005\n",
      "[343] Training loss: 0.004\t Validation loss: 0.005\n",
      "[344] Training loss: 0.004\t Validation loss: 0.005\n",
      "[345] Training loss: 0.004\t Validation loss: 0.005\n",
      "[346] Training loss: 0.004\t Validation loss: 0.005\n",
      "[347] Training loss: 0.004\t Validation loss: 0.004\n",
      "[348] Training loss: 0.004\t Validation loss: 0.004\n",
      "[349] Training loss: 0.004\t Validation loss: 0.004\n",
      "[350] Training loss: 0.004\t Validation loss: 0.004\n",
      "[351] Training loss: 0.004\t Validation loss: 0.004\n",
      "[352] Training loss: 0.004\t Validation loss: 0.004\n",
      "[353] Training loss: 0.004\t Validation loss: 0.004\n",
      "[354] Training loss: 0.004\t Validation loss: 0.004\n",
      "[355] Training loss: 0.004\t Validation loss: 0.004\n",
      "[356] Training loss: 0.004\t Validation loss: 0.004\n",
      "[357] Training loss: 0.004\t Validation loss: 0.004\n",
      "[358] Training loss: 0.004\t Validation loss: 0.004\n",
      "[359] Training loss: 0.004\t Validation loss: 0.004\n",
      "[360] Training loss: 0.004\t Validation loss: 0.004\n",
      "[361] Training loss: 0.004\t Validation loss: 0.004\n",
      "[362] Training loss: 0.004\t Validation loss: 0.004\n",
      "[363] Training loss: 0.004\t Validation loss: 0.004\n",
      "[364] Training loss: 0.004\t Validation loss: 0.004\n",
      "[365] Training loss: 0.004\t Validation loss: 0.004\n",
      "[366] Training loss: 0.004\t Validation loss: 0.004\n",
      "[367] Training loss: 0.004\t Validation loss: 0.004\n",
      "[368] Training loss: 0.004\t Validation loss: 0.004\n",
      "[369] Training loss: 0.004\t Validation loss: 0.004\n",
      "[370] Training loss: 0.004\t Validation loss: 0.004\n",
      "[371] Training loss: 0.004\t Validation loss: 0.004\n",
      "[372] Training loss: 0.004\t Validation loss: 0.004\n",
      "[373] Training loss: 0.004\t Validation loss: 0.004\n",
      "[374] Training loss: 0.004\t Validation loss: 0.004\n",
      "[375] Training loss: 0.004\t Validation loss: 0.004\n",
      "[376] Training loss: 0.004\t Validation loss: 0.004\n",
      "[377] Training loss: 0.004\t Validation loss: 0.004\n",
      "[378] Training loss: 0.004\t Validation loss: 0.004\n",
      "[379] Training loss: 0.004\t Validation loss: 0.004\n",
      "[380] Training loss: 0.004\t Validation loss: 0.004\n",
      "[381] Training loss: 0.004\t Validation loss: 0.004\n",
      "[382] Training loss: 0.004\t Validation loss: 0.004\n",
      "[383] Training loss: 0.004\t Validation loss: 0.004\n",
      "[384] Training loss: 0.004\t Validation loss: 0.004\n",
      "[385] Training loss: 0.004\t Validation loss: 0.004\n",
      "[386] Training loss: 0.004\t Validation loss: 0.004\n",
      "[387] Training loss: 0.004\t Validation loss: 0.004\n",
      "[388] Training loss: 0.004\t Validation loss: 0.004\n",
      "[389] Training loss: 0.004\t Validation loss: 0.004\n",
      "[390] Training loss: 0.004\t Validation loss: 0.004\n",
      "[391] Training loss: 0.004\t Validation loss: 0.004\n",
      "[392] Training loss: 0.004\t Validation loss: 0.004\n",
      "[393] Training loss: 0.004\t Validation loss: 0.004\n",
      "[394] Training loss: 0.004\t Validation loss: 0.004\n",
      "[395] Training loss: 0.004\t Validation loss: 0.004\n",
      "[396] Training loss: 0.004\t Validation loss: 0.004\n",
      "[397] Training loss: 0.004\t Validation loss: 0.004\n",
      "[398] Training loss: 0.004\t Validation loss: 0.004\n",
      "[399] Training loss: 0.004\t Validation loss: 0.004\n",
      "[400] Training loss: 0.004\t Validation loss: 0.004\n",
      "[401] Training loss: 0.004\t Validation loss: 0.004\n",
      "[402] Training loss: 0.004\t Validation loss: 0.004\n",
      "[403] Training loss: 0.004\t Validation loss: 0.004\n",
      "[404] Training loss: 0.004\t Validation loss: 0.004\n",
      "[405] Training loss: 0.004\t Validation loss: 0.004\n",
      "[406] Training loss: 0.004\t Validation loss: 0.004\n",
      "[407] Training loss: 0.004\t Validation loss: 0.004\n",
      "[408] Training loss: 0.004\t Validation loss: 0.004\n",
      "[409] Training loss: 0.004\t Validation loss: 0.004\n",
      "[410] Training loss: 0.004\t Validation loss: 0.004\n",
      "[411] Training loss: 0.004\t Validation loss: 0.004\n",
      "[412] Training loss: 0.004\t Validation loss: 0.004\n",
      "[413] Training loss: 0.004\t Validation loss: 0.004\n",
      "[414] Training loss: 0.004\t Validation loss: 0.004\n",
      "[415] Training loss: 0.004\t Validation loss: 0.004\n",
      "[416] Training loss: 0.004\t Validation loss: 0.004\n",
      "[417] Training loss: 0.004\t Validation loss: 0.004\n",
      "[418] Training loss: 0.004\t Validation loss: 0.004\n",
      "[419] Training loss: 0.004\t Validation loss: 0.004\n",
      "[420] Training loss: 0.004\t Validation loss: 0.004\n",
      "[421] Training loss: 0.004\t Validation loss: 0.004\n",
      "[422] Training loss: 0.004\t Validation loss: 0.004\n",
      "[423] Training loss: 0.004\t Validation loss: 0.004\n",
      "[424] Training loss: 0.004\t Validation loss: 0.004\n",
      "[425] Training loss: 0.004\t Validation loss: 0.004\n",
      "[426] Training loss: 0.004\t Validation loss: 0.004\n",
      "[427] Training loss: 0.004\t Validation loss: 0.004\n",
      "[428] Training loss: 0.004\t Validation loss: 0.004\n",
      "[429] Training loss: 0.004\t Validation loss: 0.004\n",
      "[430] Training loss: 0.004\t Validation loss: 0.004\n",
      "[431] Training loss: 0.004\t Validation loss: 0.004\n",
      "[432] Training loss: 0.004\t Validation loss: 0.004\n",
      "[433] Training loss: 0.003\t Validation loss: 0.004\n",
      "[434] Training loss: 0.003\t Validation loss: 0.004\n",
      "[435] Training loss: 0.003\t Validation loss: 0.004\n",
      "[436] Training loss: 0.003\t Validation loss: 0.004\n",
      "[437] Training loss: 0.003\t Validation loss: 0.004\n",
      "[438] Training loss: 0.003\t Validation loss: 0.004\n",
      "[439] Training loss: 0.003\t Validation loss: 0.004\n",
      "[440] Training loss: 0.003\t Validation loss: 0.003\n",
      "[441] Training loss: 0.003\t Validation loss: 0.003\n",
      "[442] Training loss: 0.003\t Validation loss: 0.003\n",
      "[443] Training loss: 0.003\t Validation loss: 0.003\n",
      "[444] Training loss: 0.003\t Validation loss: 0.003\n",
      "[445] Training loss: 0.003\t Validation loss: 0.003\n",
      "[446] Training loss: 0.003\t Validation loss: 0.003\n",
      "[447] Training loss: 0.003\t Validation loss: 0.003\n",
      "[448] Training loss: 0.003\t Validation loss: 0.003\n",
      "[449] Training loss: 0.003\t Validation loss: 0.003\n",
      "[450] Training loss: 0.003\t Validation loss: 0.003\n",
      "[451] Training loss: 0.003\t Validation loss: 0.003\n",
      "[452] Training loss: 0.003\t Validation loss: 0.003\n",
      "[453] Training loss: 0.003\t Validation loss: 0.003\n",
      "[454] Training loss: 0.003\t Validation loss: 0.003\n",
      "[455] Training loss: 0.003\t Validation loss: 0.003\n",
      "[456] Training loss: 0.003\t Validation loss: 0.003\n",
      "[457] Training loss: 0.003\t Validation loss: 0.003\n",
      "[458] Training loss: 0.003\t Validation loss: 0.003\n",
      "[459] Training loss: 0.003\t Validation loss: 0.003\n",
      "[460] Training loss: 0.003\t Validation loss: 0.003\n",
      "[461] Training loss: 0.003\t Validation loss: 0.003\n",
      "[462] Training loss: 0.003\t Validation loss: 0.003\n",
      "[463] Training loss: 0.003\t Validation loss: 0.003\n",
      "[464] Training loss: 0.003\t Validation loss: 0.003\n",
      "[465] Training loss: 0.003\t Validation loss: 0.003\n",
      "[466] Training loss: 0.003\t Validation loss: 0.003\n",
      "[467] Training loss: 0.003\t Validation loss: 0.003\n",
      "[468] Training loss: 0.003\t Validation loss: 0.003\n",
      "[469] Training loss: 0.003\t Validation loss: 0.003\n",
      "[470] Training loss: 0.003\t Validation loss: 0.003\n",
      "[471] Training loss: 0.003\t Validation loss: 0.003\n",
      "[472] Training loss: 0.003\t Validation loss: 0.003\n",
      "[473] Training loss: 0.003\t Validation loss: 0.003\n",
      "[474] Training loss: 0.003\t Validation loss: 0.003\n",
      "[475] Training loss: 0.003\t Validation loss: 0.003\n",
      "[476] Training loss: 0.003\t Validation loss: 0.003\n",
      "[477] Training loss: 0.003\t Validation loss: 0.003\n",
      "[478] Training loss: 0.003\t Validation loss: 0.003\n",
      "[479] Training loss: 0.003\t Validation loss: 0.003\n",
      "[480] Training loss: 0.003\t Validation loss: 0.003\n",
      "[481] Training loss: 0.003\t Validation loss: 0.003\n",
      "[482] Training loss: 0.003\t Validation loss: 0.003\n",
      "[483] Training loss: 0.003\t Validation loss: 0.003\n",
      "[484] Training loss: 0.003\t Validation loss: 0.003\n",
      "[485] Training loss: 0.003\t Validation loss: 0.003\n",
      "[486] Training loss: 0.003\t Validation loss: 0.003\n",
      "[487] Training loss: 0.003\t Validation loss: 0.003\n",
      "[488] Training loss: 0.003\t Validation loss: 0.003\n",
      "[489] Training loss: 0.003\t Validation loss: 0.003\n",
      "[490] Training loss: 0.003\t Validation loss: 0.003\n",
      "[491] Training loss: 0.003\t Validation loss: 0.003\n",
      "[492] Training loss: 0.003\t Validation loss: 0.003\n",
      "[493] Training loss: 0.003\t Validation loss: 0.003\n",
      "[494] Training loss: 0.003\t Validation loss: 0.003\n",
      "[495] Training loss: 0.003\t Validation loss: 0.003\n",
      "[496] Training loss: 0.003\t Validation loss: 0.003\n",
      "[497] Training loss: 0.003\t Validation loss: 0.003\n",
      "[498] Training loss: 0.003\t Validation loss: 0.003\n",
      "[499] Training loss: 0.003\t Validation loss: 0.003\n",
      "[500] Training loss: 0.003\t Validation loss: 0.003\n",
      "[501] Training loss: 0.003\t Validation loss: 0.003\n",
      "[502] Training loss: 0.003\t Validation loss: 0.003\n",
      "[503] Training loss: 0.003\t Validation loss: 0.003\n",
      "[504] Training loss: 0.003\t Validation loss: 0.003\n",
      "[505] Training loss: 0.003\t Validation loss: 0.003\n",
      "[506] Training loss: 0.003\t Validation loss: 0.003\n",
      "[507] Training loss: 0.003\t Validation loss: 0.003\n",
      "[508] Training loss: 0.003\t Validation loss: 0.003\n",
      "[509] Training loss: 0.003\t Validation loss: 0.003\n",
      "[510] Training loss: 0.003\t Validation loss: 0.003\n",
      "[511] Training loss: 0.003\t Validation loss: 0.003\n",
      "[512] Training loss: 0.003\t Validation loss: 0.003\n",
      "[513] Training loss: 0.003\t Validation loss: 0.003\n",
      "[514] Training loss: 0.003\t Validation loss: 0.003\n",
      "[515] Training loss: 0.003\t Validation loss: 0.003\n",
      "[516] Training loss: 0.003\t Validation loss: 0.003\n",
      "[517] Training loss: 0.003\t Validation loss: 0.003\n",
      "[518] Training loss: 0.003\t Validation loss: 0.003\n",
      "[519] Training loss: 0.003\t Validation loss: 0.003\n",
      "[520] Training loss: 0.003\t Validation loss: 0.003\n",
      "[521] Training loss: 0.003\t Validation loss: 0.003\n",
      "[522] Training loss: 0.003\t Validation loss: 0.003\n",
      "[523] Training loss: 0.003\t Validation loss: 0.003\n",
      "[524] Training loss: 0.003\t Validation loss: 0.003\n",
      "[525] Training loss: 0.003\t Validation loss: 0.003\n",
      "[526] Training loss: 0.003\t Validation loss: 0.003\n",
      "[527] Training loss: 0.003\t Validation loss: 0.003\n",
      "[528] Training loss: 0.003\t Validation loss: 0.003\n",
      "[529] Training loss: 0.003\t Validation loss: 0.003\n",
      "[530] Training loss: 0.003\t Validation loss: 0.003\n",
      "[531] Training loss: 0.003\t Validation loss: 0.003\n",
      "[532] Training loss: 0.003\t Validation loss: 0.003\n",
      "[533] Training loss: 0.003\t Validation loss: 0.003\n",
      "[534] Training loss: 0.003\t Validation loss: 0.003\n",
      "[535] Training loss: 0.003\t Validation loss: 0.003\n",
      "[536] Training loss: 0.003\t Validation loss: 0.003\n",
      "[537] Training loss: 0.003\t Validation loss: 0.003\n",
      "[538] Training loss: 0.003\t Validation loss: 0.003\n",
      "[539] Training loss: 0.003\t Validation loss: 0.003\n",
      "[540] Training loss: 0.003\t Validation loss: 0.003\n",
      "[541] Training loss: 0.003\t Validation loss: 0.003\n",
      "[542] Training loss: 0.003\t Validation loss: 0.003\n",
      "[543] Training loss: 0.003\t Validation loss: 0.003\n",
      "[544] Training loss: 0.003\t Validation loss: 0.003\n",
      "[545] Training loss: 0.003\t Validation loss: 0.003\n",
      "[546] Training loss: 0.003\t Validation loss: 0.003\n",
      "[547] Training loss: 0.003\t Validation loss: 0.003\n",
      "[548] Training loss: 0.003\t Validation loss: 0.003\n",
      "[549] Training loss: 0.003\t Validation loss: 0.003\n",
      "[550] Training loss: 0.003\t Validation loss: 0.003\n",
      "[551] Training loss: 0.003\t Validation loss: 0.003\n",
      "[552] Training loss: 0.003\t Validation loss: 0.003\n",
      "[553] Training loss: 0.003\t Validation loss: 0.003\n",
      "[554] Training loss: 0.003\t Validation loss: 0.003\n",
      "[555] Training loss: 0.003\t Validation loss: 0.003\n",
      "[556] Training loss: 0.003\t Validation loss: 0.003\n",
      "[557] Training loss: 0.003\t Validation loss: 0.003\n",
      "[558] Training loss: 0.003\t Validation loss: 0.003\n",
      "[559] Training loss: 0.003\t Validation loss: 0.003\n",
      "[560] Training loss: 0.003\t Validation loss: 0.003\n",
      "[561] Training loss: 0.002\t Validation loss: 0.003\n",
      "[562] Training loss: 0.002\t Validation loss: 0.003\n",
      "[563] Training loss: 0.002\t Validation loss: 0.003\n",
      "[564] Training loss: 0.002\t Validation loss: 0.003\n",
      "[565] Training loss: 0.002\t Validation loss: 0.003\n",
      "[566] Training loss: 0.002\t Validation loss: 0.003\n",
      "[567] Training loss: 0.002\t Validation loss: 0.002\n",
      "[568] Training loss: 0.002\t Validation loss: 0.002\n",
      "[569] Training loss: 0.002\t Validation loss: 0.002\n",
      "[570] Training loss: 0.002\t Validation loss: 0.002\n",
      "[571] Training loss: 0.002\t Validation loss: 0.002\n",
      "[572] Training loss: 0.002\t Validation loss: 0.002\n",
      "[573] Training loss: 0.002\t Validation loss: 0.002\n",
      "[574] Training loss: 0.002\t Validation loss: 0.002\n",
      "[575] Training loss: 0.002\t Validation loss: 0.002\n",
      "[576] Training loss: 0.002\t Validation loss: 0.002\n",
      "[577] Training loss: 0.002\t Validation loss: 0.002\n",
      "[578] Training loss: 0.002\t Validation loss: 0.002\n",
      "[579] Training loss: 0.002\t Validation loss: 0.002\n",
      "[580] Training loss: 0.002\t Validation loss: 0.002\n",
      "[581] Training loss: 0.002\t Validation loss: 0.002\n",
      "[582] Training loss: 0.002\t Validation loss: 0.002\n",
      "[583] Training loss: 0.002\t Validation loss: 0.002\n",
      "[584] Training loss: 0.002\t Validation loss: 0.002\n",
      "[585] Training loss: 0.002\t Validation loss: 0.002\n",
      "[586] Training loss: 0.002\t Validation loss: 0.002\n",
      "[587] Training loss: 0.002\t Validation loss: 0.002\n",
      "[588] Training loss: 0.002\t Validation loss: 0.002\n",
      "[589] Training loss: 0.002\t Validation loss: 0.002\n",
      "[590] Training loss: 0.002\t Validation loss: 0.002\n",
      "[591] Training loss: 0.002\t Validation loss: 0.002\n",
      "[592] Training loss: 0.002\t Validation loss: 0.002\n",
      "[593] Training loss: 0.002\t Validation loss: 0.002\n",
      "[594] Training loss: 0.002\t Validation loss: 0.002\n",
      "[595] Training loss: 0.002\t Validation loss: 0.002\n",
      "[596] Training loss: 0.002\t Validation loss: 0.002\n",
      "[597] Training loss: 0.002\t Validation loss: 0.002\n",
      "[598] Training loss: 0.002\t Validation loss: 0.002\n",
      "[599] Training loss: 0.002\t Validation loss: 0.002\n",
      "[600] Training loss: 0.002\t Validation loss: 0.002\n",
      "[601] Training loss: 0.002\t Validation loss: 0.002\n",
      "[602] Training loss: 0.002\t Validation loss: 0.002\n",
      "[603] Training loss: 0.002\t Validation loss: 0.002\n",
      "[604] Training loss: 0.002\t Validation loss: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[605] Training loss: 0.002\t Validation loss: 0.002\n",
      "[606] Training loss: 0.002\t Validation loss: 0.002\n",
      "[607] Training loss: 0.002\t Validation loss: 0.002\n",
      "[608] Training loss: 0.002\t Validation loss: 0.002\n",
      "[609] Training loss: 0.002\t Validation loss: 0.002\n",
      "[610] Training loss: 0.002\t Validation loss: 0.002\n",
      "[611] Training loss: 0.002\t Validation loss: 0.002\n",
      "[612] Training loss: 0.002\t Validation loss: 0.002\n",
      "[613] Training loss: 0.002\t Validation loss: 0.002\n",
      "[614] Training loss: 0.002\t Validation loss: 0.002\n",
      "[615] Training loss: 0.002\t Validation loss: 0.002\n",
      "[616] Training loss: 0.002\t Validation loss: 0.002\n",
      "[617] Training loss: 0.002\t Validation loss: 0.002\n",
      "[618] Training loss: 0.002\t Validation loss: 0.002\n",
      "[619] Training loss: 0.002\t Validation loss: 0.002\n",
      "[620] Training loss: 0.002\t Validation loss: 0.002\n",
      "[621] Training loss: 0.002\t Validation loss: 0.002\n",
      "[622] Training loss: 0.002\t Validation loss: 0.002\n",
      "[623] Training loss: 0.002\t Validation loss: 0.002\n",
      "[624] Training loss: 0.002\t Validation loss: 0.002\n",
      "[625] Training loss: 0.002\t Validation loss: 0.002\n",
      "[626] Training loss: 0.002\t Validation loss: 0.002\n",
      "[627] Training loss: 0.002\t Validation loss: 0.002\n",
      "[628] Training loss: 0.002\t Validation loss: 0.002\n",
      "[629] Training loss: 0.002\t Validation loss: 0.002\n",
      "[630] Training loss: 0.002\t Validation loss: 0.002\n",
      "[631] Training loss: 0.002\t Validation loss: 0.002\n",
      "[632] Training loss: 0.002\t Validation loss: 0.002\n",
      "[633] Training loss: 0.002\t Validation loss: 0.002\n",
      "[634] Training loss: 0.002\t Validation loss: 0.002\n",
      "[635] Training loss: 0.002\t Validation loss: 0.002\n",
      "[636] Training loss: 0.002\t Validation loss: 0.002\n",
      "[637] Training loss: 0.002\t Validation loss: 0.002\n",
      "[638] Training loss: 0.002\t Validation loss: 0.002\n",
      "[639] Training loss: 0.002\t Validation loss: 0.002\n",
      "[640] Training loss: 0.002\t Validation loss: 0.002\n",
      "[641] Training loss: 0.002\t Validation loss: 0.002\n",
      "[642] Training loss: 0.002\t Validation loss: 0.002\n",
      "[643] Training loss: 0.002\t Validation loss: 0.002\n",
      "[644] Training loss: 0.002\t Validation loss: 0.002\n",
      "[645] Training loss: 0.002\t Validation loss: 0.002\n",
      "[646] Training loss: 0.002\t Validation loss: 0.002\n",
      "[647] Training loss: 0.002\t Validation loss: 0.002\n",
      "[648] Training loss: 0.002\t Validation loss: 0.002\n",
      "[649] Training loss: 0.002\t Validation loss: 0.002\n",
      "[650] Training loss: 0.002\t Validation loss: 0.002\n",
      "[651] Training loss: 0.002\t Validation loss: 0.002\n",
      "[652] Training loss: 0.002\t Validation loss: 0.002\n",
      "[653] Training loss: 0.002\t Validation loss: 0.002\n",
      "[654] Training loss: 0.002\t Validation loss: 0.002\n",
      "[655] Training loss: 0.002\t Validation loss: 0.002\n",
      "[656] Training loss: 0.002\t Validation loss: 0.002\n",
      "[657] Training loss: 0.002\t Validation loss: 0.002\n",
      "[658] Training loss: 0.002\t Validation loss: 0.002\n",
      "[659] Training loss: 0.002\t Validation loss: 0.002\n",
      "[660] Training loss: 0.002\t Validation loss: 0.002\n",
      "[661] Training loss: 0.002\t Validation loss: 0.002\n",
      "[662] Training loss: 0.002\t Validation loss: 0.002\n",
      "[663] Training loss: 0.002\t Validation loss: 0.002\n",
      "[664] Training loss: 0.002\t Validation loss: 0.002\n",
      "[665] Training loss: 0.002\t Validation loss: 0.002\n",
      "[666] Training loss: 0.002\t Validation loss: 0.002\n",
      "[667] Training loss: 0.002\t Validation loss: 0.002\n",
      "[668] Training loss: 0.002\t Validation loss: 0.002\n",
      "[669] Training loss: 0.002\t Validation loss: 0.002\n",
      "[670] Training loss: 0.002\t Validation loss: 0.002\n",
      "[671] Training loss: 0.002\t Validation loss: 0.002\n",
      "[672] Training loss: 0.002\t Validation loss: 0.002\n",
      "[673] Training loss: 0.002\t Validation loss: 0.002\n",
      "[674] Training loss: 0.002\t Validation loss: 0.002\n",
      "[675] Training loss: 0.002\t Validation loss: 0.002\n",
      "[676] Training loss: 0.002\t Validation loss: 0.002\n",
      "[677] Training loss: 0.002\t Validation loss: 0.002\n",
      "[678] Training loss: 0.002\t Validation loss: 0.002\n",
      "[679] Training loss: 0.002\t Validation loss: 0.002\n",
      "[680] Training loss: 0.002\t Validation loss: 0.002\n",
      "[681] Training loss: 0.002\t Validation loss: 0.002\n",
      "[682] Training loss: 0.002\t Validation loss: 0.002\n",
      "[683] Training loss: 0.002\t Validation loss: 0.002\n",
      "[684] Training loss: 0.002\t Validation loss: 0.002\n",
      "[685] Training loss: 0.002\t Validation loss: 0.002\n",
      "[686] Training loss: 0.002\t Validation loss: 0.002\n",
      "[687] Training loss: 0.002\t Validation loss: 0.002\n",
      "[688] Training loss: 0.002\t Validation loss: 0.002\n",
      "[689] Training loss: 0.002\t Validation loss: 0.002\n",
      "[690] Training loss: 0.002\t Validation loss: 0.002\n",
      "[691] Training loss: 0.002\t Validation loss: 0.002\n",
      "[692] Training loss: 0.002\t Validation loss: 0.002\n",
      "[693] Training loss: 0.002\t Validation loss: 0.002\n",
      "[694] Training loss: 0.002\t Validation loss: 0.002\n",
      "[695] Training loss: 0.002\t Validation loss: 0.002\n",
      "[696] Training loss: 0.002\t Validation loss: 0.002\n",
      "[697] Training loss: 0.002\t Validation loss: 0.002\n",
      "[698] Training loss: 0.002\t Validation loss: 0.002\n",
      "[699] Training loss: 0.002\t Validation loss: 0.002\n",
      "[700] Training loss: 0.002\t Validation loss: 0.002\n",
      "[701] Training loss: 0.002\t Validation loss: 0.002\n",
      "[702] Training loss: 0.002\t Validation loss: 0.002\n",
      "[703] Training loss: 0.002\t Validation loss: 0.002\n",
      "[704] Training loss: 0.002\t Validation loss: 0.002\n",
      "[705] Training loss: 0.002\t Validation loss: 0.002\n",
      "[706] Training loss: 0.002\t Validation loss: 0.002\n",
      "[707] Training loss: 0.002\t Validation loss: 0.002\n",
      "[708] Training loss: 0.002\t Validation loss: 0.002\n",
      "[709] Training loss: 0.002\t Validation loss: 0.002\n",
      "[710] Training loss: 0.002\t Validation loss: 0.002\n",
      "[711] Training loss: 0.002\t Validation loss: 0.002\n",
      "[712] Training loss: 0.002\t Validation loss: 0.002\n",
      "[713] Training loss: 0.002\t Validation loss: 0.002\n",
      "[714] Training loss: 0.002\t Validation loss: 0.002\n",
      "[715] Training loss: 0.002\t Validation loss: 0.002\n",
      "[716] Training loss: 0.002\t Validation loss: 0.002\n",
      "[717] Training loss: 0.002\t Validation loss: 0.002\n",
      "[718] Training loss: 0.002\t Validation loss: 0.002\n",
      "[719] Training loss: 0.002\t Validation loss: 0.002\n",
      "[720] Training loss: 0.002\t Validation loss: 0.002\n",
      "[721] Training loss: 0.002\t Validation loss: 0.002\n",
      "[722] Training loss: 0.002\t Validation loss: 0.002\n",
      "[723] Training loss: 0.002\t Validation loss: 0.002\n",
      "[724] Training loss: 0.002\t Validation loss: 0.002\n",
      "[725] Training loss: 0.002\t Validation loss: 0.002\n",
      "[726] Training loss: 0.002\t Validation loss: 0.002\n",
      "[727] Training loss: 0.001\t Validation loss: 0.002\n",
      "[728] Training loss: 0.001\t Validation loss: 0.002\n",
      "[729] Training loss: 0.001\t Validation loss: 0.002\n",
      "[730] Training loss: 0.001\t Validation loss: 0.002\n",
      "[731] Training loss: 0.001\t Validation loss: 0.001\n",
      "[732] Training loss: 0.001\t Validation loss: 0.001\n",
      "[733] Training loss: 0.001\t Validation loss: 0.001\n",
      "[734] Training loss: 0.001\t Validation loss: 0.001\n",
      "[735] Training loss: 0.001\t Validation loss: 0.001\n",
      "[736] Training loss: 0.001\t Validation loss: 0.001\n",
      "[737] Training loss: 0.001\t Validation loss: 0.001\n",
      "[738] Training loss: 0.001\t Validation loss: 0.001\n",
      "[739] Training loss: 0.001\t Validation loss: 0.001\n",
      "[740] Training loss: 0.001\t Validation loss: 0.001\n",
      "[741] Training loss: 0.001\t Validation loss: 0.001\n",
      "[742] Training loss: 0.001\t Validation loss: 0.001\n",
      "[743] Training loss: 0.001\t Validation loss: 0.001\n",
      "[744] Training loss: 0.001\t Validation loss: 0.001\n",
      "[745] Training loss: 0.001\t Validation loss: 0.001\n",
      "[746] Training loss: 0.001\t Validation loss: 0.001\n",
      "[747] Training loss: 0.001\t Validation loss: 0.001\n",
      "[748] Training loss: 0.001\t Validation loss: 0.001\n",
      "[749] Training loss: 0.001\t Validation loss: 0.001\n",
      "[750] Training loss: 0.001\t Validation loss: 0.001\n",
      "[751] Training loss: 0.001\t Validation loss: 0.001\n",
      "[752] Training loss: 0.001\t Validation loss: 0.001\n",
      "[753] Training loss: 0.001\t Validation loss: 0.001\n",
      "[754] Training loss: 0.001\t Validation loss: 0.001\n",
      "[755] Training loss: 0.001\t Validation loss: 0.001\n",
      "[756] Training loss: 0.001\t Validation loss: 0.001\n",
      "[757] Training loss: 0.001\t Validation loss: 0.001\n",
      "[758] Training loss: 0.001\t Validation loss: 0.001\n",
      "[759] Training loss: 0.001\t Validation loss: 0.001\n",
      "[760] Training loss: 0.001\t Validation loss: 0.001\n",
      "[761] Training loss: 0.001\t Validation loss: 0.001\n",
      "[762] Training loss: 0.001\t Validation loss: 0.001\n",
      "[763] Training loss: 0.001\t Validation loss: 0.001\n",
      "[764] Training loss: 0.001\t Validation loss: 0.001\n",
      "[765] Training loss: 0.001\t Validation loss: 0.001\n",
      "[766] Training loss: 0.001\t Validation loss: 0.001\n",
      "[767] Training loss: 0.001\t Validation loss: 0.001\n",
      "[768] Training loss: 0.001\t Validation loss: 0.001\n",
      "[769] Training loss: 0.001\t Validation loss: 0.001\n",
      "[770] Training loss: 0.001\t Validation loss: 0.001\n",
      "[771] Training loss: 0.001\t Validation loss: 0.001\n",
      "[772] Training loss: 0.001\t Validation loss: 0.001\n",
      "[773] Training loss: 0.001\t Validation loss: 0.001\n",
      "[774] Training loss: 0.001\t Validation loss: 0.001\n",
      "[775] Training loss: 0.001\t Validation loss: 0.001\n",
      "[776] Training loss: 0.001\t Validation loss: 0.001\n",
      "[777] Training loss: 0.001\t Validation loss: 0.001\n",
      "[778] Training loss: 0.001\t Validation loss: 0.001\n",
      "[779] Training loss: 0.001\t Validation loss: 0.001\n",
      "[780] Training loss: 0.001\t Validation loss: 0.001\n",
      "[781] Training loss: 0.001\t Validation loss: 0.001\n",
      "[782] Training loss: 0.001\t Validation loss: 0.001\n",
      "[783] Training loss: 0.001\t Validation loss: 0.001\n",
      "[784] Training loss: 0.001\t Validation loss: 0.001\n",
      "[785] Training loss: 0.001\t Validation loss: 0.001\n",
      "[786] Training loss: 0.001\t Validation loss: 0.001\n",
      "[787] Training loss: 0.001\t Validation loss: 0.001\n",
      "[788] Training loss: 0.001\t Validation loss: 0.001\n",
      "[789] Training loss: 0.001\t Validation loss: 0.001\n",
      "[790] Training loss: 0.001\t Validation loss: 0.001\n",
      "[791] Training loss: 0.001\t Validation loss: 0.001\n",
      "[792] Training loss: 0.001\t Validation loss: 0.001\n",
      "[793] Training loss: 0.001\t Validation loss: 0.001\n",
      "[794] Training loss: 0.001\t Validation loss: 0.001\n",
      "[795] Training loss: 0.001\t Validation loss: 0.001\n",
      "[796] Training loss: 0.001\t Validation loss: 0.001\n",
      "[797] Training loss: 0.001\t Validation loss: 0.001\n",
      "[798] Training loss: 0.001\t Validation loss: 0.001\n",
      "[799] Training loss: 0.001\t Validation loss: 0.001\n",
      "[800] Training loss: 0.001\t Validation loss: 0.001\n",
      "[801] Training loss: 0.001\t Validation loss: 0.001\n",
      "[802] Training loss: 0.001\t Validation loss: 0.001\n",
      "[803] Training loss: 0.001\t Validation loss: 0.001\n",
      "[804] Training loss: 0.001\t Validation loss: 0.001\n",
      "[805] Training loss: 0.001\t Validation loss: 0.001\n",
      "[806] Training loss: 0.001\t Validation loss: 0.001\n",
      "[807] Training loss: 0.001\t Validation loss: 0.001\n",
      "[808] Training loss: 0.001\t Validation loss: 0.001\n",
      "[809] Training loss: 0.001\t Validation loss: 0.001\n",
      "[810] Training loss: 0.001\t Validation loss: 0.001\n",
      "[811] Training loss: 0.001\t Validation loss: 0.001\n",
      "[812] Training loss: 0.001\t Validation loss: 0.001\n",
      "[813] Training loss: 0.001\t Validation loss: 0.001\n",
      "[814] Training loss: 0.001\t Validation loss: 0.001\n",
      "[815] Training loss: 0.001\t Validation loss: 0.001\n",
      "[816] Training loss: 0.001\t Validation loss: 0.001\n",
      "[817] Training loss: 0.001\t Validation loss: 0.001\n",
      "[818] Training loss: 0.001\t Validation loss: 0.001\n",
      "[819] Training loss: 0.001\t Validation loss: 0.001\n",
      "[820] Training loss: 0.001\t Validation loss: 0.001\n",
      "[821] Training loss: 0.001\t Validation loss: 0.001\n",
      "[822] Training loss: 0.001\t Validation loss: 0.001\n",
      "[823] Training loss: 0.001\t Validation loss: 0.001\n",
      "[824] Training loss: 0.001\t Validation loss: 0.001\n",
      "[825] Training loss: 0.001\t Validation loss: 0.001\n",
      "[826] Training loss: 0.001\t Validation loss: 0.001\n",
      "[827] Training loss: 0.001\t Validation loss: 0.001\n",
      "[828] Training loss: 0.001\t Validation loss: 0.001\n",
      "[829] Training loss: 0.001\t Validation loss: 0.001\n",
      "[830] Training loss: 0.001\t Validation loss: 0.001\n",
      "[831] Training loss: 0.001\t Validation loss: 0.001\n",
      "[832] Training loss: 0.001\t Validation loss: 0.001\n",
      "[833] Training loss: 0.001\t Validation loss: 0.001\n",
      "[834] Training loss: 0.001\t Validation loss: 0.001\n",
      "[835] Training loss: 0.001\t Validation loss: 0.001\n",
      "[836] Training loss: 0.001\t Validation loss: 0.001\n",
      "[837] Training loss: 0.001\t Validation loss: 0.001\n",
      "[838] Training loss: 0.001\t Validation loss: 0.001\n",
      "[839] Training loss: 0.001\t Validation loss: 0.001\n",
      "[840] Training loss: 0.001\t Validation loss: 0.001\n",
      "[841] Training loss: 0.001\t Validation loss: 0.001\n",
      "[842] Training loss: 0.001\t Validation loss: 0.001\n",
      "[843] Training loss: 0.001\t Validation loss: 0.001\n",
      "[844] Training loss: 0.001\t Validation loss: 0.001\n",
      "[845] Training loss: 0.001\t Validation loss: 0.001\n",
      "[846] Training loss: 0.001\t Validation loss: 0.001\n",
      "[847] Training loss: 0.001\t Validation loss: 0.001\n",
      "[848] Training loss: 0.001\t Validation loss: 0.001\n",
      "[849] Training loss: 0.001\t Validation loss: 0.001\n",
      "[850] Training loss: 0.001\t Validation loss: 0.001\n",
      "[851] Training loss: 0.001\t Validation loss: 0.001\n",
      "[852] Training loss: 0.001\t Validation loss: 0.001\n",
      "[853] Training loss: 0.001\t Validation loss: 0.001\n",
      "[854] Training loss: 0.001\t Validation loss: 0.001\n",
      "[855] Training loss: 0.001\t Validation loss: 0.001\n",
      "[856] Training loss: 0.001\t Validation loss: 0.001\n",
      "[857] Training loss: 0.001\t Validation loss: 0.001\n",
      "[858] Training loss: 0.001\t Validation loss: 0.001\n",
      "[859] Training loss: 0.001\t Validation loss: 0.001\n",
      "[860] Training loss: 0.001\t Validation loss: 0.001\n",
      "[861] Training loss: 0.001\t Validation loss: 0.001\n",
      "[862] Training loss: 0.001\t Validation loss: 0.001\n",
      "[863] Training loss: 0.001\t Validation loss: 0.001\n",
      "[864] Training loss: 0.001\t Validation loss: 0.001\n",
      "[865] Training loss: 0.001\t Validation loss: 0.001\n",
      "[866] Training loss: 0.001\t Validation loss: 0.001\n",
      "[867] Training loss: 0.001\t Validation loss: 0.001\n",
      "[868] Training loss: 0.001\t Validation loss: 0.001\n",
      "[869] Training loss: 0.001\t Validation loss: 0.001\n",
      "[870] Training loss: 0.001\t Validation loss: 0.001\n",
      "[871] Training loss: 0.001\t Validation loss: 0.001\n",
      "[872] Training loss: 0.001\t Validation loss: 0.001\n",
      "[873] Training loss: 0.001\t Validation loss: 0.001\n",
      "[874] Training loss: 0.001\t Validation loss: 0.001\n",
      "[875] Training loss: 0.001\t Validation loss: 0.001\n",
      "[876] Training loss: 0.001\t Validation loss: 0.001\n",
      "[877] Training loss: 0.001\t Validation loss: 0.001\n",
      "[878] Training loss: 0.001\t Validation loss: 0.001\n",
      "[879] Training loss: 0.001\t Validation loss: 0.001\n",
      "[880] Training loss: 0.001\t Validation loss: 0.001\n",
      "[881] Training loss: 0.001\t Validation loss: 0.001\n",
      "[882] Training loss: 0.001\t Validation loss: 0.001\n",
      "[883] Training loss: 0.001\t Validation loss: 0.001\n",
      "[884] Training loss: 0.001\t Validation loss: 0.001\n",
      "[885] Training loss: 0.001\t Validation loss: 0.001\n",
      "[886] Training loss: 0.001\t Validation loss: 0.001\n",
      "[887] Training loss: 0.001\t Validation loss: 0.001\n",
      "[888] Training loss: 0.001\t Validation loss: 0.001\n",
      "[889] Training loss: 0.001\t Validation loss: 0.001\n",
      "[890] Training loss: 0.001\t Validation loss: 0.001\n",
      "[891] Training loss: 0.001\t Validation loss: 0.001\n",
      "[892] Training loss: 0.001\t Validation loss: 0.001\n",
      "[893] Training loss: 0.001\t Validation loss: 0.001\n",
      "[894] Training loss: 0.001\t Validation loss: 0.001\n",
      "[895] Training loss: 0.001\t Validation loss: 0.001\n",
      "[896] Training loss: 0.001\t Validation loss: 0.001\n",
      "[897] Training loss: 0.001\t Validation loss: 0.001\n",
      "[898] Training loss: 0.001\t Validation loss: 0.001\n",
      "[899] Training loss: 0.001\t Validation loss: 0.001\n",
      "[900] Training loss: 0.001\t Validation loss: 0.001\n",
      "[901] Training loss: 0.001\t Validation loss: 0.001\n",
      "[902] Training loss: 0.001\t Validation loss: 0.001\n",
      "[903] Training loss: 0.001\t Validation loss: 0.001\n",
      "[904] Training loss: 0.001\t Validation loss: 0.001\n",
      "[905] Training loss: 0.001\t Validation loss: 0.001\n",
      "[906] Training loss: 0.001\t Validation loss: 0.001\n",
      "[907] Training loss: 0.001\t Validation loss: 0.001\n",
      "[908] Training loss: 0.001\t Validation loss: 0.001\n",
      "[909] Training loss: 0.001\t Validation loss: 0.001\n",
      "[910] Training loss: 0.001\t Validation loss: 0.001\n",
      "[911] Training loss: 0.001\t Validation loss: 0.001\n",
      "[912] Training loss: 0.001\t Validation loss: 0.001\n",
      "[913] Training loss: 0.001\t Validation loss: 0.001\n",
      "[914] Training loss: 0.001\t Validation loss: 0.001\n",
      "[915] Training loss: 0.001\t Validation loss: 0.001\n",
      "[916] Training loss: 0.001\t Validation loss: 0.001\n",
      "[917] Training loss: 0.001\t Validation loss: 0.001\n",
      "[918] Training loss: 0.001\t Validation loss: 0.001\n",
      "[919] Training loss: 0.001\t Validation loss: 0.001\n",
      "[920] Training loss: 0.001\t Validation loss: 0.001\n",
      "[921] Training loss: 0.001\t Validation loss: 0.001\n",
      "[922] Training loss: 0.001\t Validation loss: 0.001\n",
      "[923] Training loss: 0.001\t Validation loss: 0.001\n",
      "[924] Training loss: 0.001\t Validation loss: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[925] Training loss: 0.001\t Validation loss: 0.001\n",
      "[926] Training loss: 0.001\t Validation loss: 0.001\n",
      "[927] Training loss: 0.001\t Validation loss: 0.001\n",
      "[928] Training loss: 0.001\t Validation loss: 0.001\n",
      "[929] Training loss: 0.001\t Validation loss: 0.001\n",
      "[930] Training loss: 0.001\t Validation loss: 0.001\n",
      "[931] Training loss: 0.001\t Validation loss: 0.001\n",
      "[932] Training loss: 0.001\t Validation loss: 0.001\n",
      "[933] Training loss: 0.001\t Validation loss: 0.001\n",
      "[934] Training loss: 0.001\t Validation loss: 0.001\n",
      "[935] Training loss: 0.001\t Validation loss: 0.001\n",
      "[936] Training loss: 0.001\t Validation loss: 0.001\n",
      "[937] Training loss: 0.001\t Validation loss: 0.001\n",
      "[938] Training loss: 0.001\t Validation loss: 0.001\n",
      "[939] Training loss: 0.001\t Validation loss: 0.001\n",
      "[940] Training loss: 0.001\t Validation loss: 0.001\n",
      "[941] Training loss: 0.001\t Validation loss: 0.001\n",
      "[942] Training loss: 0.001\t Validation loss: 0.001\n",
      "[943] Training loss: 0.001\t Validation loss: 0.001\n",
      "[944] Training loss: 0.001\t Validation loss: 0.001\n",
      "[945] Training loss: 0.001\t Validation loss: 0.001\n",
      "[946] Training loss: 0.001\t Validation loss: 0.001\n",
      "[947] Training loss: 0.001\t Validation loss: 0.001\n",
      "[948] Training loss: 0.001\t Validation loss: 0.001\n",
      "[949] Training loss: 0.001\t Validation loss: 0.001\n",
      "[950] Training loss: 0.001\t Validation loss: 0.001\n",
      "[951] Training loss: 0.001\t Validation loss: 0.001\n",
      "[952] Training loss: 0.001\t Validation loss: 0.001\n",
      "[953] Training loss: 0.001\t Validation loss: 0.001\n",
      "[954] Training loss: 0.001\t Validation loss: 0.001\n",
      "[955] Training loss: 0.001\t Validation loss: 0.001\n",
      "[956] Training loss: 0.001\t Validation loss: 0.001\n",
      "[957] Training loss: 0.001\t Validation loss: 0.001\n",
      "[958] Training loss: 0.001\t Validation loss: 0.001\n",
      "[959] Training loss: 0.001\t Validation loss: 0.001\n",
      "[960] Training loss: 0.001\t Validation loss: 0.001\n",
      "[961] Training loss: 0.001\t Validation loss: 0.001\n",
      "[962] Training loss: 0.001\t Validation loss: 0.001\n",
      "[963] Training loss: 0.001\t Validation loss: 0.001\n",
      "[964] Training loss: 0.001\t Validation loss: 0.001\n",
      "[965] Training loss: 0.001\t Validation loss: 0.001\n",
      "[966] Training loss: 0.001\t Validation loss: 0.001\n",
      "[967] Training loss: 0.001\t Validation loss: 0.001\n",
      "[968] Training loss: 0.001\t Validation loss: 0.001\n",
      "[969] Training loss: 0.001\t Validation loss: 0.001\n",
      "[970] Training loss: 0.001\t Validation loss: 0.001\n",
      "[971] Training loss: 0.001\t Validation loss: 0.001\n",
      "[972] Training loss: 0.001\t Validation loss: 0.001\n",
      "[973] Training loss: 0.001\t Validation loss: 0.001\n",
      "[974] Training loss: 0.001\t Validation loss: 0.001\n",
      "[975] Training loss: 0.001\t Validation loss: 0.001\n",
      "[976] Training loss: 0.001\t Validation loss: 0.001\n",
      "[977] Training loss: 0.001\t Validation loss: 0.001\n",
      "[978] Training loss: 0.001\t Validation loss: 0.001\n",
      "[979] Training loss: 0.001\t Validation loss: 0.001\n",
      "[980] Training loss: 0.001\t Validation loss: 0.001\n",
      "[981] Training loss: 0.001\t Validation loss: 0.001\n",
      "[982] Training loss: 0.001\t Validation loss: 0.001\n",
      "[983] Training loss: 0.001\t Validation loss: 0.001\n",
      "[984] Training loss: 0.001\t Validation loss: 0.001\n",
      "[985] Training loss: 0.001\t Validation loss: 0.001\n",
      "[986] Training loss: 0.001\t Validation loss: 0.001\n",
      "[987] Training loss: 0.001\t Validation loss: 0.001\n",
      "[988] Training loss: 0.001\t Validation loss: 0.001\n",
      "[989] Training loss: 0.001\t Validation loss: 0.001\n",
      "[990] Training loss: 0.001\t Validation loss: 0.001\n",
      "[991] Training loss: 0.001\t Validation loss: 0.001\n",
      "[992] Training loss: 0.001\t Validation loss: 0.001\n",
      "[993] Training loss: 0.001\t Validation loss: 0.001\n",
      "[994] Training loss: 0.001\t Validation loss: 0.001\n",
      "[995] Training loss: 0.001\t Validation loss: 0.001\n",
      "[996] Training loss: 0.001\t Validation loss: 0.001\n",
      "[997] Training loss: 0.001\t Validation loss: 0.001\n",
      "[998] Training loss: 0.001\t Validation loss: 0.001\n",
      "[999] Training loss: 0.001\t Validation loss: 0.001\n",
      "[1000] Training loss: 0.001\t Validation loss: 0.001\n",
      "1357 Samples\n",
      "\n",
      "GraphConvolution()\n",
      "[1] Training loss: 0.355\t Validation loss: 0.354\n",
      "[2] Training loss: 0.352\t Validation loss: 0.350\n",
      "[3] Training loss: 0.348\t Validation loss: 0.346\n",
      "[4] Training loss: 0.344\t Validation loss: 0.343\n",
      "[5] Training loss: 0.340\t Validation loss: 0.339\n",
      "[6] Training loss: 0.337\t Validation loss: 0.335\n",
      "[7] Training loss: 0.333\t Validation loss: 0.332\n",
      "[8] Training loss: 0.329\t Validation loss: 0.328\n",
      "[9] Training loss: 0.326\t Validation loss: 0.324\n",
      "[10] Training loss: 0.322\t Validation loss: 0.321\n",
      "[11] Training loss: 0.319\t Validation loss: 0.317\n",
      "[12] Training loss: 0.315\t Validation loss: 0.314\n",
      "[13] Training loss: 0.312\t Validation loss: 0.310\n",
      "[14] Training loss: 0.308\t Validation loss: 0.307\n",
      "[15] Training loss: 0.305\t Validation loss: 0.303\n",
      "[16] Training loss: 0.301\t Validation loss: 0.300\n",
      "[17] Training loss: 0.298\t Validation loss: 0.296\n",
      "[18] Training loss: 0.294\t Validation loss: 0.293\n",
      "[19] Training loss: 0.291\t Validation loss: 0.289\n",
      "[20] Training loss: 0.288\t Validation loss: 0.286\n",
      "[21] Training loss: 0.284\t Validation loss: 0.283\n",
      "[22] Training loss: 0.281\t Validation loss: 0.280\n",
      "[23] Training loss: 0.278\t Validation loss: 0.276\n",
      "[24] Training loss: 0.274\t Validation loss: 0.273\n",
      "[25] Training loss: 0.271\t Validation loss: 0.270\n",
      "[26] Training loss: 0.268\t Validation loss: 0.267\n",
      "[27] Training loss: 0.265\t Validation loss: 0.263\n",
      "[28] Training loss: 0.262\t Validation loss: 0.260\n",
      "[29] Training loss: 0.259\t Validation loss: 0.257\n",
      "[30] Training loss: 0.256\t Validation loss: 0.254\n",
      "[31] Training loss: 0.252\t Validation loss: 0.251\n",
      "[32] Training loss: 0.249\t Validation loss: 0.248\n",
      "[33] Training loss: 0.246\t Validation loss: 0.245\n",
      "[34] Training loss: 0.243\t Validation loss: 0.242\n",
      "[35] Training loss: 0.240\t Validation loss: 0.239\n",
      "[36] Training loss: 0.238\t Validation loss: 0.236\n",
      "[37] Training loss: 0.235\t Validation loss: 0.233\n",
      "[38] Training loss: 0.232\t Validation loss: 0.230\n",
      "[39] Training loss: 0.229\t Validation loss: 0.227\n",
      "[40] Training loss: 0.226\t Validation loss: 0.225\n",
      "[41] Training loss: 0.223\t Validation loss: 0.222\n",
      "[42] Training loss: 0.220\t Validation loss: 0.219\n",
      "[43] Training loss: 0.218\t Validation loss: 0.216\n",
      "[44] Training loss: 0.215\t Validation loss: 0.214\n",
      "[45] Training loss: 0.212\t Validation loss: 0.211\n",
      "[46] Training loss: 0.210\t Validation loss: 0.208\n",
      "[47] Training loss: 0.207\t Validation loss: 0.206\n",
      "[48] Training loss: 0.204\t Validation loss: 0.203\n",
      "[49] Training loss: 0.202\t Validation loss: 0.200\n",
      "[50] Training loss: 0.199\t Validation loss: 0.198\n",
      "[51] Training loss: 0.197\t Validation loss: 0.195\n",
      "[52] Training loss: 0.194\t Validation loss: 0.193\n",
      "[53] Training loss: 0.192\t Validation loss: 0.190\n",
      "[54] Training loss: 0.189\t Validation loss: 0.188\n",
      "[55] Training loss: 0.187\t Validation loss: 0.185\n",
      "[56] Training loss: 0.184\t Validation loss: 0.183\n",
      "[57] Training loss: 0.182\t Validation loss: 0.181\n",
      "[58] Training loss: 0.179\t Validation loss: 0.178\n",
      "[59] Training loss: 0.177\t Validation loss: 0.176\n",
      "[60] Training loss: 0.175\t Validation loss: 0.174\n",
      "[61] Training loss: 0.172\t Validation loss: 0.171\n",
      "[62] Training loss: 0.170\t Validation loss: 0.169\n",
      "[63] Training loss: 0.168\t Validation loss: 0.167\n",
      "[64] Training loss: 0.166\t Validation loss: 0.165\n",
      "[65] Training loss: 0.164\t Validation loss: 0.162\n",
      "[66] Training loss: 0.161\t Validation loss: 0.160\n",
      "[67] Training loss: 0.159\t Validation loss: 0.158\n",
      "[68] Training loss: 0.157\t Validation loss: 0.156\n",
      "[69] Training loss: 0.155\t Validation loss: 0.154\n",
      "[70] Training loss: 0.153\t Validation loss: 0.152\n",
      "[71] Training loss: 0.151\t Validation loss: 0.150\n",
      "[72] Training loss: 0.149\t Validation loss: 0.148\n",
      "[73] Training loss: 0.147\t Validation loss: 0.146\n",
      "[74] Training loss: 0.145\t Validation loss: 0.144\n",
      "[75] Training loss: 0.143\t Validation loss: 0.142\n",
      "[76] Training loss: 0.141\t Validation loss: 0.140\n",
      "[77] Training loss: 0.139\t Validation loss: 0.138\n",
      "[78] Training loss: 0.137\t Validation loss: 0.136\n",
      "[79] Training loss: 0.135\t Validation loss: 0.134\n",
      "[80] Training loss: 0.133\t Validation loss: 0.132\n",
      "[81] Training loss: 0.131\t Validation loss: 0.130\n",
      "[82] Training loss: 0.129\t Validation loss: 0.128\n",
      "[83] Training loss: 0.128\t Validation loss: 0.126\n",
      "[84] Training loss: 0.126\t Validation loss: 0.125\n",
      "[85] Training loss: 0.124\t Validation loss: 0.123\n",
      "[86] Training loss: 0.122\t Validation loss: 0.121\n",
      "[87] Training loss: 0.120\t Validation loss: 0.119\n",
      "[88] Training loss: 0.119\t Validation loss: 0.118\n",
      "[89] Training loss: 0.117\t Validation loss: 0.116\n",
      "[90] Training loss: 0.115\t Validation loss: 0.114\n",
      "[91] Training loss: 0.114\t Validation loss: 0.113\n",
      "[92] Training loss: 0.112\t Validation loss: 0.111\n",
      "[93] Training loss: 0.110\t Validation loss: 0.109\n",
      "[94] Training loss: 0.109\t Validation loss: 0.108\n",
      "[95] Training loss: 0.107\t Validation loss: 0.106\n",
      "[96] Training loss: 0.106\t Validation loss: 0.105\n",
      "[97] Training loss: 0.104\t Validation loss: 0.103\n",
      "[98] Training loss: 0.103\t Validation loss: 0.102\n",
      "[99] Training loss: 0.101\t Validation loss: 0.100\n",
      "[100] Training loss: 0.100\t Validation loss: 0.099\n",
      "[101] Training loss: 0.098\t Validation loss: 0.097\n",
      "[102] Training loss: 0.097\t Validation loss: 0.096\n",
      "[103] Training loss: 0.095\t Validation loss: 0.094\n",
      "[104] Training loss: 0.094\t Validation loss: 0.093\n",
      "[105] Training loss: 0.092\t Validation loss: 0.092\n",
      "[106] Training loss: 0.091\t Validation loss: 0.090\n",
      "[107] Training loss: 0.090\t Validation loss: 0.089\n",
      "[108] Training loss: 0.088\t Validation loss: 0.087\n",
      "[109] Training loss: 0.087\t Validation loss: 0.086\n",
      "[110] Training loss: 0.086\t Validation loss: 0.085\n",
      "[111] Training loss: 0.084\t Validation loss: 0.084\n",
      "[112] Training loss: 0.083\t Validation loss: 0.082\n",
      "[113] Training loss: 0.082\t Validation loss: 0.081\n",
      "[114] Training loss: 0.081\t Validation loss: 0.080\n",
      "[115] Training loss: 0.079\t Validation loss: 0.079\n",
      "[116] Training loss: 0.078\t Validation loss: 0.077\n",
      "[117] Training loss: 0.077\t Validation loss: 0.076\n",
      "[118] Training loss: 0.076\t Validation loss: 0.075\n",
      "[119] Training loss: 0.074\t Validation loss: 0.074\n",
      "[120] Training loss: 0.073\t Validation loss: 0.073\n",
      "[121] Training loss: 0.072\t Validation loss: 0.071\n",
      "[122] Training loss: 0.071\t Validation loss: 0.070\n",
      "[123] Training loss: 0.070\t Validation loss: 0.069\n",
      "[124] Training loss: 0.069\t Validation loss: 0.068\n",
      "[125] Training loss: 0.068\t Validation loss: 0.067\n",
      "[126] Training loss: 0.067\t Validation loss: 0.066\n",
      "[127] Training loss: 0.066\t Validation loss: 0.065\n",
      "[128] Training loss: 0.065\t Validation loss: 0.064\n",
      "[129] Training loss: 0.064\t Validation loss: 0.063\n",
      "[130] Training loss: 0.063\t Validation loss: 0.062\n",
      "[131] Training loss: 0.062\t Validation loss: 0.061\n",
      "[132] Training loss: 0.061\t Validation loss: 0.060\n",
      "[133] Training loss: 0.060\t Validation loss: 0.059\n",
      "[134] Training loss: 0.059\t Validation loss: 0.058\n",
      "[135] Training loss: 0.058\t Validation loss: 0.057\n",
      "[136] Training loss: 0.057\t Validation loss: 0.056\n",
      "[137] Training loss: 0.056\t Validation loss: 0.055\n",
      "[138] Training loss: 0.055\t Validation loss: 0.054\n",
      "[139] Training loss: 0.054\t Validation loss: 0.053\n",
      "[140] Training loss: 0.053\t Validation loss: 0.052\n",
      "[141] Training loss: 0.052\t Validation loss: 0.052\n",
      "[142] Training loss: 0.051\t Validation loss: 0.051\n",
      "[143] Training loss: 0.050\t Validation loss: 0.050\n",
      "[144] Training loss: 0.050\t Validation loss: 0.049\n",
      "[145] Training loss: 0.049\t Validation loss: 0.048\n",
      "[146] Training loss: 0.048\t Validation loss: 0.047\n",
      "[147] Training loss: 0.047\t Validation loss: 0.047\n",
      "[148] Training loss: 0.046\t Validation loss: 0.046\n",
      "[149] Training loss: 0.046\t Validation loss: 0.045\n",
      "[150] Training loss: 0.045\t Validation loss: 0.044\n",
      "[151] Training loss: 0.044\t Validation loss: 0.044\n",
      "[152] Training loss: 0.043\t Validation loss: 0.043\n",
      "[153] Training loss: 0.043\t Validation loss: 0.042\n",
      "[154] Training loss: 0.042\t Validation loss: 0.041\n",
      "[155] Training loss: 0.041\t Validation loss: 0.041\n",
      "[156] Training loss: 0.040\t Validation loss: 0.040\n",
      "[157] Training loss: 0.040\t Validation loss: 0.039\n",
      "[158] Training loss: 0.039\t Validation loss: 0.039\n",
      "[159] Training loss: 0.038\t Validation loss: 0.038\n",
      "[160] Training loss: 0.038\t Validation loss: 0.037\n",
      "[161] Training loss: 0.037\t Validation loss: 0.037\n",
      "[162] Training loss: 0.036\t Validation loss: 0.036\n",
      "[163] Training loss: 0.036\t Validation loss: 0.035\n",
      "[164] Training loss: 0.035\t Validation loss: 0.035\n",
      "[165] Training loss: 0.035\t Validation loss: 0.034\n",
      "[166] Training loss: 0.034\t Validation loss: 0.034\n",
      "[167] Training loss: 0.033\t Validation loss: 0.033\n",
      "[168] Training loss: 0.033\t Validation loss: 0.032\n",
      "[169] Training loss: 0.032\t Validation loss: 0.032\n",
      "[170] Training loss: 0.032\t Validation loss: 0.031\n",
      "[171] Training loss: 0.031\t Validation loss: 0.031\n",
      "[172] Training loss: 0.031\t Validation loss: 0.030\n",
      "[173] Training loss: 0.030\t Validation loss: 0.030\n",
      "[174] Training loss: 0.029\t Validation loss: 0.029\n",
      "[175] Training loss: 0.029\t Validation loss: 0.029\n",
      "[176] Training loss: 0.028\t Validation loss: 0.028\n",
      "[177] Training loss: 0.028\t Validation loss: 0.028\n",
      "[178] Training loss: 0.027\t Validation loss: 0.027\n",
      "[179] Training loss: 0.027\t Validation loss: 0.027\n",
      "[180] Training loss: 0.026\t Validation loss: 0.026\n",
      "[181] Training loss: 0.026\t Validation loss: 0.026\n",
      "[182] Training loss: 0.025\t Validation loss: 0.025\n",
      "[183] Training loss: 0.025\t Validation loss: 0.025\n",
      "[184] Training loss: 0.025\t Validation loss: 0.024\n",
      "[185] Training loss: 0.024\t Validation loss: 0.024\n",
      "[186] Training loss: 0.024\t Validation loss: 0.023\n",
      "[187] Training loss: 0.023\t Validation loss: 0.023\n",
      "[188] Training loss: 0.023\t Validation loss: 0.022\n",
      "[189] Training loss: 0.022\t Validation loss: 0.022\n",
      "[190] Training loss: 0.022\t Validation loss: 0.022\n",
      "[191] Training loss: 0.022\t Validation loss: 0.021\n",
      "[192] Training loss: 0.021\t Validation loss: 0.021\n",
      "[193] Training loss: 0.021\t Validation loss: 0.020\n",
      "[194] Training loss: 0.020\t Validation loss: 0.020\n",
      "[195] Training loss: 0.020\t Validation loss: 0.020\n",
      "[196] Training loss: 0.020\t Validation loss: 0.019\n",
      "[197] Training loss: 0.019\t Validation loss: 0.019\n",
      "[198] Training loss: 0.019\t Validation loss: 0.019\n",
      "[199] Training loss: 0.019\t Validation loss: 0.018\n",
      "[200] Training loss: 0.018\t Validation loss: 0.018\n",
      "[201] Training loss: 0.018\t Validation loss: 0.018\n",
      "[202] Training loss: 0.018\t Validation loss: 0.017\n",
      "[203] Training loss: 0.017\t Validation loss: 0.017\n",
      "[204] Training loss: 0.017\t Validation loss: 0.017\n",
      "[205] Training loss: 0.017\t Validation loss: 0.016\n",
      "[206] Training loss: 0.016\t Validation loss: 0.016\n",
      "[207] Training loss: 0.016\t Validation loss: 0.016\n",
      "[208] Training loss: 0.016\t Validation loss: 0.015\n",
      "[209] Training loss: 0.015\t Validation loss: 0.015\n",
      "[210] Training loss: 0.015\t Validation loss: 0.015\n",
      "[211] Training loss: 0.015\t Validation loss: 0.015\n",
      "[212] Training loss: 0.014\t Validation loss: 0.014\n",
      "[213] Training loss: 0.014\t Validation loss: 0.014\n",
      "[214] Training loss: 0.014\t Validation loss: 0.014\n",
      "[215] Training loss: 0.014\t Validation loss: 0.013\n",
      "[216] Training loss: 0.013\t Validation loss: 0.013\n",
      "[217] Training loss: 0.013\t Validation loss: 0.013\n",
      "[218] Training loss: 0.013\t Validation loss: 0.013\n",
      "[219] Training loss: 0.013\t Validation loss: 0.012\n",
      "[220] Training loss: 0.012\t Validation loss: 0.012\n",
      "[221] Training loss: 0.012\t Validation loss: 0.012\n",
      "[222] Training loss: 0.012\t Validation loss: 0.012\n",
      "[223] Training loss: 0.012\t Validation loss: 0.011\n",
      "[224] Training loss: 0.011\t Validation loss: 0.011\n",
      "[225] Training loss: 0.011\t Validation loss: 0.011\n",
      "[226] Training loss: 0.011\t Validation loss: 0.011\n",
      "[227] Training loss: 0.011\t Validation loss: 0.011\n",
      "[228] Training loss: 0.011\t Validation loss: 0.010\n",
      "[229] Training loss: 0.010\t Validation loss: 0.010\n",
      "[230] Training loss: 0.010\t Validation loss: 0.010\n",
      "[231] Training loss: 0.010\t Validation loss: 0.010\n",
      "[232] Training loss: 0.010\t Validation loss: 0.010\n",
      "[233] Training loss: 0.010\t Validation loss: 0.009\n",
      "[234] Training loss: 0.009\t Validation loss: 0.009\n",
      "[235] Training loss: 0.009\t Validation loss: 0.009\n",
      "[236] Training loss: 0.009\t Validation loss: 0.009\n",
      "[237] Training loss: 0.009\t Validation loss: 0.009\n",
      "[238] Training loss: 0.009\t Validation loss: 0.009\n",
      "[239] Training loss: 0.009\t Validation loss: 0.008\n",
      "[240] Training loss: 0.008\t Validation loss: 0.008\n",
      "[241] Training loss: 0.008\t Validation loss: 0.008\n",
      "[242] Training loss: 0.008\t Validation loss: 0.008\n",
      "[243] Training loss: 0.008\t Validation loss: 0.008\n",
      "[244] Training loss: 0.008\t Validation loss: 0.008\n",
      "[245] Training loss: 0.008\t Validation loss: 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[246] Training loss: 0.007\t Validation loss: 0.007\n",
      "[247] Training loss: 0.007\t Validation loss: 0.007\n",
      "[248] Training loss: 0.007\t Validation loss: 0.007\n",
      "[249] Training loss: 0.007\t Validation loss: 0.007\n",
      "[250] Training loss: 0.007\t Validation loss: 0.007\n",
      "[251] Training loss: 0.007\t Validation loss: 0.007\n",
      "[252] Training loss: 0.007\t Validation loss: 0.006\n",
      "[253] Training loss: 0.006\t Validation loss: 0.006\n",
      "[254] Training loss: 0.006\t Validation loss: 0.006\n",
      "[255] Training loss: 0.006\t Validation loss: 0.006\n",
      "[256] Training loss: 0.006\t Validation loss: 0.006\n",
      "[257] Training loss: 0.006\t Validation loss: 0.006\n",
      "[258] Training loss: 0.006\t Validation loss: 0.006\n",
      "[259] Training loss: 0.006\t Validation loss: 0.006\n",
      "[260] Training loss: 0.006\t Validation loss: 0.006\n",
      "[261] Training loss: 0.006\t Validation loss: 0.005\n",
      "[262] Training loss: 0.005\t Validation loss: 0.005\n",
      "[263] Training loss: 0.005\t Validation loss: 0.005\n",
      "[264] Training loss: 0.005\t Validation loss: 0.005\n",
      "[265] Training loss: 0.005\t Validation loss: 0.005\n",
      "[266] Training loss: 0.005\t Validation loss: 0.005\n",
      "[267] Training loss: 0.005\t Validation loss: 0.005\n",
      "[268] Training loss: 0.005\t Validation loss: 0.005\n",
      "[269] Training loss: 0.005\t Validation loss: 0.005\n",
      "[270] Training loss: 0.005\t Validation loss: 0.005\n",
      "[271] Training loss: 0.005\t Validation loss: 0.004\n",
      "[272] Training loss: 0.004\t Validation loss: 0.004\n",
      "[273] Training loss: 0.004\t Validation loss: 0.004\n",
      "[274] Training loss: 0.004\t Validation loss: 0.004\n",
      "[275] Training loss: 0.004\t Validation loss: 0.004\n",
      "[276] Training loss: 0.004\t Validation loss: 0.004\n",
      "[277] Training loss: 0.004\t Validation loss: 0.004\n",
      "[278] Training loss: 0.004\t Validation loss: 0.004\n",
      "[279] Training loss: 0.004\t Validation loss: 0.004\n",
      "[280] Training loss: 0.004\t Validation loss: 0.004\n",
      "[281] Training loss: 0.004\t Validation loss: 0.004\n",
      "[282] Training loss: 0.004\t Validation loss: 0.004\n",
      "[283] Training loss: 0.004\t Validation loss: 0.004\n",
      "[284] Training loss: 0.004\t Validation loss: 0.003\n",
      "[285] Training loss: 0.003\t Validation loss: 0.003\n",
      "[286] Training loss: 0.003\t Validation loss: 0.003\n",
      "[287] Training loss: 0.003\t Validation loss: 0.003\n",
      "[288] Training loss: 0.003\t Validation loss: 0.003\n",
      "[289] Training loss: 0.003\t Validation loss: 0.003\n",
      "[290] Training loss: 0.003\t Validation loss: 0.003\n",
      "[291] Training loss: 0.003\t Validation loss: 0.003\n",
      "[292] Training loss: 0.003\t Validation loss: 0.003\n",
      "[293] Training loss: 0.003\t Validation loss: 0.003\n",
      "[294] Training loss: 0.003\t Validation loss: 0.003\n",
      "[295] Training loss: 0.003\t Validation loss: 0.003\n",
      "[296] Training loss: 0.003\t Validation loss: 0.003\n",
      "[297] Training loss: 0.003\t Validation loss: 0.003\n",
      "[298] Training loss: 0.003\t Validation loss: 0.003\n",
      "[299] Training loss: 0.003\t Validation loss: 0.003\n",
      "[300] Training loss: 0.003\t Validation loss: 0.003\n",
      "[301] Training loss: 0.003\t Validation loss: 0.003\n",
      "[302] Training loss: 0.003\t Validation loss: 0.002\n",
      "[303] Training loss: 0.002\t Validation loss: 0.002\n",
      "[304] Training loss: 0.002\t Validation loss: 0.002\n",
      "[305] Training loss: 0.002\t Validation loss: 0.002\n",
      "[306] Training loss: 0.002\t Validation loss: 0.002\n",
      "[307] Training loss: 0.002\t Validation loss: 0.002\n",
      "[308] Training loss: 0.002\t Validation loss: 0.002\n",
      "[309] Training loss: 0.002\t Validation loss: 0.002\n",
      "[310] Training loss: 0.002\t Validation loss: 0.002\n",
      "[311] Training loss: 0.002\t Validation loss: 0.002\n",
      "[312] Training loss: 0.002\t Validation loss: 0.002\n",
      "[313] Training loss: 0.002\t Validation loss: 0.002\n",
      "[314] Training loss: 0.002\t Validation loss: 0.002\n",
      "[315] Training loss: 0.002\t Validation loss: 0.002\n",
      "[316] Training loss: 0.002\t Validation loss: 0.002\n",
      "[317] Training loss: 0.002\t Validation loss: 0.002\n",
      "[318] Training loss: 0.002\t Validation loss: 0.002\n",
      "[319] Training loss: 0.002\t Validation loss: 0.002\n",
      "[320] Training loss: 0.002\t Validation loss: 0.002\n",
      "[321] Training loss: 0.002\t Validation loss: 0.002\n",
      "[322] Training loss: 0.002\t Validation loss: 0.002\n",
      "[323] Training loss: 0.002\t Validation loss: 0.002\n",
      "[324] Training loss: 0.002\t Validation loss: 0.002\n",
      "[325] Training loss: 0.002\t Validation loss: 0.002\n",
      "[326] Training loss: 0.002\t Validation loss: 0.002\n",
      "[327] Training loss: 0.002\t Validation loss: 0.002\n",
      "[328] Training loss: 0.002\t Validation loss: 0.002\n",
      "[329] Training loss: 0.002\t Validation loss: 0.002\n",
      "[330] Training loss: 0.002\t Validation loss: 0.002\n",
      "[331] Training loss: 0.002\t Validation loss: 0.002\n",
      "[332] Training loss: 0.002\t Validation loss: 0.002\n",
      "[333] Training loss: 0.002\t Validation loss: 0.002\n",
      "[334] Training loss: 0.002\t Validation loss: 0.001\n",
      "[335] Training loss: 0.002\t Validation loss: 0.001\n",
      "[336] Training loss: 0.001\t Validation loss: 0.001\n",
      "[337] Training loss: 0.001\t Validation loss: 0.001\n",
      "[338] Training loss: 0.001\t Validation loss: 0.001\n",
      "[339] Training loss: 0.001\t Validation loss: 0.001\n",
      "[340] Training loss: 0.001\t Validation loss: 0.001\n",
      "[341] Training loss: 0.001\t Validation loss: 0.001\n",
      "[342] Training loss: 0.001\t Validation loss: 0.001\n",
      "[343] Training loss: 0.001\t Validation loss: 0.001\n",
      "[344] Training loss: 0.001\t Validation loss: 0.001\n",
      "[345] Training loss: 0.001\t Validation loss: 0.001\n",
      "[346] Training loss: 0.001\t Validation loss: 0.001\n",
      "[347] Training loss: 0.001\t Validation loss: 0.001\n",
      "[348] Training loss: 0.001\t Validation loss: 0.001\n",
      "[349] Training loss: 0.001\t Validation loss: 0.001\n",
      "[350] Training loss: 0.001\t Validation loss: 0.001\n",
      "[351] Training loss: 0.001\t Validation loss: 0.001\n",
      "[352] Training loss: 0.001\t Validation loss: 0.001\n",
      "[353] Training loss: 0.001\t Validation loss: 0.001\n",
      "[354] Training loss: 0.001\t Validation loss: 0.001\n",
      "[355] Training loss: 0.001\t Validation loss: 0.001\n",
      "[356] Training loss: 0.001\t Validation loss: 0.001\n",
      "[357] Training loss: 0.001\t Validation loss: 0.001\n",
      "[358] Training loss: 0.001\t Validation loss: 0.001\n",
      "[359] Training loss: 0.001\t Validation loss: 0.001\n",
      "[360] Training loss: 0.001\t Validation loss: 0.001\n",
      "[361] Training loss: 0.001\t Validation loss: 0.001\n",
      "[362] Training loss: 0.001\t Validation loss: 0.001\n",
      "[363] Training loss: 0.001\t Validation loss: 0.001\n",
      "[364] Training loss: 0.001\t Validation loss: 0.001\n",
      "[365] Training loss: 0.001\t Validation loss: 0.001\n",
      "[366] Training loss: 0.001\t Validation loss: 0.001\n",
      "[367] Training loss: 0.001\t Validation loss: 0.001\n",
      "[368] Training loss: 0.001\t Validation loss: 0.001\n",
      "[369] Training loss: 0.001\t Validation loss: 0.001\n",
      "[370] Training loss: 0.001\t Validation loss: 0.001\n",
      "[371] Training loss: 0.001\t Validation loss: 0.001\n",
      "[372] Training loss: 0.001\t Validation loss: 0.001\n",
      "[373] Training loss: 0.001\t Validation loss: 0.001\n",
      "[374] Training loss: 0.001\t Validation loss: 0.001\n",
      "[375] Training loss: 0.001\t Validation loss: 0.001\n",
      "[376] Training loss: 0.001\t Validation loss: 0.001\n",
      "[377] Training loss: 0.001\t Validation loss: 0.001\n",
      "[378] Training loss: 0.001\t Validation loss: 0.001\n",
      "[379] Training loss: 0.001\t Validation loss: 0.001\n",
      "[380] Training loss: 0.001\t Validation loss: 0.001\n",
      "[381] Training loss: 0.001\t Validation loss: 0.001\n",
      "[382] Training loss: 0.001\t Validation loss: 0.001\n",
      "[383] Training loss: 0.001\t Validation loss: 0.001\n",
      "[384] Training loss: 0.001\t Validation loss: 0.001\n",
      "[385] Training loss: 0.001\t Validation loss: 0.001\n",
      "[386] Training loss: 0.001\t Validation loss: 0.001\n",
      "[387] Training loss: 0.001\t Validation loss: 0.001\n",
      "[388] Training loss: 0.001\t Validation loss: 0.001\n",
      "[389] Training loss: 0.001\t Validation loss: 0.001\n",
      "[390] Training loss: 0.001\t Validation loss: 0.001\n",
      "[391] Training loss: 0.001\t Validation loss: 0.001\n",
      "[392] Training loss: 0.001\t Validation loss: 0.001\n",
      "[393] Training loss: 0.001\t Validation loss: 0.001\n",
      "[394] Training loss: 0.001\t Validation loss: 0.001\n",
      "[395] Training loss: 0.001\t Validation loss: 0.001\n",
      "[396] Training loss: 0.001\t Validation loss: 0.001\n",
      "[397] Training loss: 0.001\t Validation loss: 0.001\n",
      "[398] Training loss: 0.001\t Validation loss: 0.001\n",
      "[399] Training loss: 0.001\t Validation loss: 0.001\n",
      "[400] Training loss: 0.001\t Validation loss: 0.001\n",
      "[401] Training loss: 0.001\t Validation loss: 0.001\n",
      "[402] Training loss: 0.001\t Validation loss: 0.001\n",
      "[403] Training loss: 0.001\t Validation loss: 0.001\n",
      "[404] Training loss: 0.001\t Validation loss: 0.001\n",
      "[405] Training loss: 0.001\t Validation loss: 0.001\n",
      "[406] Training loss: 0.001\t Validation loss: 0.001\n",
      "[407] Training loss: 0.001\t Validation loss: 0.001\n",
      "[408] Training loss: 0.001\t Validation loss: 0.001\n",
      "[409] Training loss: 0.001\t Validation loss: 0.001\n",
      "[410] Training loss: 0.001\t Validation loss: 0.001\n",
      "[411] Training loss: 0.001\t Validation loss: 0.001\n",
      "[412] Training loss: 0.001\t Validation loss: 0.001\n",
      "[413] Training loss: 0.001\t Validation loss: 0.001\n",
      "[414] Training loss: 0.001\t Validation loss: 0.001\n",
      "[415] Training loss: 0.001\t Validation loss: 0.001\n",
      "[416] Training loss: 0.001\t Validation loss: 0.001\n",
      "[417] Training loss: 0.001\t Validation loss: 0.001\n",
      "[418] Training loss: 0.001\t Validation loss: 0.001\n",
      "[419] Training loss: 0.001\t Validation loss: 0.001\n",
      "[420] Training loss: 0.001\t Validation loss: 0.001\n",
      "[421] Training loss: 0.001\t Validation loss: 0.001\n",
      "[422] Training loss: 0.001\t Validation loss: 0.001\n",
      "[423] Training loss: 0.001\t Validation loss: 0.001\n",
      "[424] Training loss: 0.001\t Validation loss: 0.001\n",
      "[425] Training loss: 0.001\t Validation loss: 0.001\n",
      "[426] Training loss: 0.001\t Validation loss: 0.001\n",
      "[427] Training loss: 0.001\t Validation loss: 0.001\n",
      "[428] Training loss: 0.001\t Validation loss: 0.001\n",
      "[429] Training loss: 0.001\t Validation loss: 0.001\n",
      "[430] Training loss: 0.001\t Validation loss: 0.001\n",
      "[431] Training loss: 0.001\t Validation loss: 0.001\n",
      "[432] Training loss: 0.001\t Validation loss: 0.001\n",
      "[433] Training loss: 0.001\t Validation loss: 0.001\n",
      "[434] Training loss: 0.001\t Validation loss: 0.001\n",
      "[435] Training loss: 0.001\t Validation loss: 0.001\n",
      "[436] Training loss: 0.001\t Validation loss: 0.001\n",
      "[437] Training loss: 0.001\t Validation loss: 0.001\n",
      "[438] Training loss: 0.001\t Validation loss: 0.001\n",
      "[439] Training loss: 0.001\t Validation loss: 0.001\n",
      "[440] Training loss: 0.001\t Validation loss: 0.001\n",
      "[441] Training loss: 0.001\t Validation loss: 0.001\n",
      "[442] Training loss: 0.001\t Validation loss: 0.001\n",
      "[443] Training loss: 0.001\t Validation loss: 0.001\n",
      "[444] Training loss: 0.001\t Validation loss: 0.001\n",
      "[445] Training loss: 0.001\t Validation loss: 0.001\n",
      "[446] Training loss: 0.001\t Validation loss: 0.001\n",
      "[447] Training loss: 0.001\t Validation loss: 0.001\n",
      "[448] Training loss: 0.001\t Validation loss: 0.001\n",
      "[449] Training loss: 0.001\t Validation loss: 0.001\n",
      "[450] Training loss: 0.001\t Validation loss: 0.001\n",
      "[451] Training loss: 0.001\t Validation loss: 0.001\n",
      "[452] Training loss: 0.001\t Validation loss: 0.001\n",
      "[453] Training loss: 0.001\t Validation loss: 0.001\n",
      "[454] Training loss: 0.001\t Validation loss: 0.001\n",
      "[455] Training loss: 0.001\t Validation loss: 0.001\n",
      "[456] Training loss: 0.001\t Validation loss: 0.001\n",
      "[457] Training loss: 0.001\t Validation loss: 0.001\n",
      "[458] Training loss: 0.001\t Validation loss: 0.001\n",
      "[459] Training loss: 0.001\t Validation loss: 0.001\n",
      "[460] Training loss: 0.001\t Validation loss: 0.001\n",
      "[461] Training loss: 0.001\t Validation loss: 0.001\n",
      "[462] Training loss: 0.001\t Validation loss: 0.001\n",
      "[463] Training loss: 0.001\t Validation loss: 0.001\n",
      "[464] Training loss: 0.001\t Validation loss: 0.001\n",
      "[465] Training loss: 0.001\t Validation loss: 0.001\n",
      "[466] Training loss: 0.001\t Validation loss: 0.001\n",
      "[467] Training loss: 0.001\t Validation loss: 0.001\n",
      "[468] Training loss: 0.001\t Validation loss: 0.001\n",
      "[469] Training loss: 0.001\t Validation loss: 0.001\n",
      "[470] Training loss: 0.001\t Validation loss: 0.001\n",
      "[471] Training loss: 0.001\t Validation loss: 0.001\n",
      "[472] Training loss: 0.001\t Validation loss: 0.001\n",
      "[473] Training loss: 0.001\t Validation loss: 0.001\n",
      "[474] Training loss: 0.001\t Validation loss: 0.001\n",
      "[475] Training loss: 0.001\t Validation loss: 0.001\n",
      "[476] Training loss: 0.001\t Validation loss: 0.001\n",
      "[477] Training loss: 0.001\t Validation loss: 0.001\n",
      "[478] Training loss: 0.001\t Validation loss: 0.001\n",
      "[479] Training loss: 0.001\t Validation loss: 0.001\n",
      "[480] Training loss: 0.001\t Validation loss: 0.001\n",
      "[481] Training loss: 0.001\t Validation loss: 0.001\n",
      "[482] Training loss: 0.001\t Validation loss: 0.001\n",
      "[483] Training loss: 0.001\t Validation loss: 0.001\n",
      "[484] Training loss: 0.001\t Validation loss: 0.001\n",
      "[485] Training loss: 0.001\t Validation loss: 0.001\n",
      "[486] Training loss: 0.001\t Validation loss: 0.001\n",
      "[487] Training loss: 0.001\t Validation loss: 0.001\n",
      "[488] Training loss: 0.001\t Validation loss: 0.001\n",
      "[489] Training loss: 0.001\t Validation loss: 0.001\n",
      "[490] Training loss: 0.001\t Validation loss: 0.001\n",
      "[491] Training loss: 0.001\t Validation loss: 0.001\n",
      "[492] Training loss: 0.001\t Validation loss: 0.001\n",
      "[493] Training loss: 0.001\t Validation loss: 0.001\n",
      "[494] Training loss: 0.001\t Validation loss: 0.001\n",
      "[495] Training loss: 0.001\t Validation loss: 0.001\n",
      "[496] Training loss: 0.001\t Validation loss: 0.001\n",
      "[497] Training loss: 0.001\t Validation loss: 0.001\n",
      "[498] Training loss: 0.001\t Validation loss: 0.001\n",
      "[499] Training loss: 0.001\t Validation loss: 0.001\n",
      "[500] Training loss: 0.001\t Validation loss: 0.001\n",
      "[501] Training loss: 0.001\t Validation loss: 0.001\n",
      "[502] Training loss: 0.001\t Validation loss: 0.001\n",
      "[503] Training loss: 0.001\t Validation loss: 0.001\n",
      "[504] Training loss: 0.001\t Validation loss: 0.001\n",
      "[505] Training loss: 0.001\t Validation loss: 0.001\n",
      "[506] Training loss: 0.001\t Validation loss: 0.001\n",
      "[507] Training loss: 0.001\t Validation loss: 0.001\n",
      "[508] Training loss: 0.001\t Validation loss: 0.001\n",
      "[509] Training loss: 0.001\t Validation loss: 0.001\n",
      "[510] Training loss: 0.001\t Validation loss: 0.001\n",
      "[511] Training loss: 0.001\t Validation loss: 0.001\n",
      "[512] Training loss: 0.001\t Validation loss: 0.001\n",
      "[513] Training loss: 0.001\t Validation loss: 0.001\n",
      "[514] Training loss: 0.001\t Validation loss: 0.001\n",
      "[515] Training loss: 0.001\t Validation loss: 0.001\n",
      "[516] Training loss: 0.001\t Validation loss: 0.001\n",
      "[517] Training loss: 0.001\t Validation loss: 0.001\n",
      "[518] Training loss: 0.001\t Validation loss: 0.001\n",
      "[519] Training loss: 0.001\t Validation loss: 0.001\n",
      "[520] Training loss: 0.001\t Validation loss: 0.001\n",
      "[521] Training loss: 0.001\t Validation loss: 0.001\n",
      "[522] Training loss: 0.001\t Validation loss: 0.001\n",
      "[523] Training loss: 0.001\t Validation loss: 0.001\n",
      "[524] Training loss: 0.001\t Validation loss: 0.001\n",
      "[525] Training loss: 0.001\t Validation loss: 0.001\n",
      "[526] Training loss: 0.001\t Validation loss: 0.001\n",
      "[527] Training loss: 0.001\t Validation loss: 0.001\n",
      "[528] Training loss: 0.001\t Validation loss: 0.001\n",
      "[529] Training loss: 0.001\t Validation loss: 0.001\n",
      "[530] Training loss: 0.001\t Validation loss: 0.001\n",
      "[531] Training loss: 0.001\t Validation loss: 0.001\n",
      "[532] Training loss: 0.001\t Validation loss: 0.001\n",
      "[533] Training loss: 0.001\t Validation loss: 0.001\n",
      "[534] Training loss: 0.001\t Validation loss: 0.001\n",
      "[535] Training loss: 0.001\t Validation loss: 0.001\n",
      "[536] Training loss: 0.001\t Validation loss: 0.001\n",
      "[537] Training loss: 0.001\t Validation loss: 0.000\n",
      "[538] Training loss: 0.001\t Validation loss: 0.000\n",
      "[539] Training loss: 0.001\t Validation loss: 0.000\n",
      "[540] Training loss: 0.000\t Validation loss: 0.000\n",
      "[541] Training loss: 0.000\t Validation loss: 0.000\n",
      "[542] Training loss: 0.000\t Validation loss: 0.000\n",
      "[543] Training loss: 0.000\t Validation loss: 0.000\n",
      "[544] Training loss: 0.000\t Validation loss: 0.000\n",
      "[545] Training loss: 0.000\t Validation loss: 0.000\n",
      "[546] Training loss: 0.000\t Validation loss: 0.000\n",
      "[547] Training loss: 0.000\t Validation loss: 0.000\n",
      "[548] Training loss: 0.000\t Validation loss: 0.000\n",
      "[549] Training loss: 0.000\t Validation loss: 0.000\n",
      "[550] Training loss: 0.000\t Validation loss: 0.000\n",
      "[551] Training loss: 0.000\t Validation loss: 0.000\n",
      "[552] Training loss: 0.000\t Validation loss: 0.000\n",
      "[553] Training loss: 0.000\t Validation loss: 0.000\n",
      "[554] Training loss: 0.000\t Validation loss: 0.000\n",
      "[555] Training loss: 0.000\t Validation loss: 0.000\n",
      "[556] Training loss: 0.000\t Validation loss: 0.000\n",
      "[557] Training loss: 0.000\t Validation loss: 0.000\n",
      "[558] Training loss: 0.000\t Validation loss: 0.000\n",
      "[559] Training loss: 0.000\t Validation loss: 0.000\n",
      "[560] Training loss: 0.000\t Validation loss: 0.000\n",
      "[561] Training loss: 0.000\t Validation loss: 0.000\n",
      "[562] Training loss: 0.000\t Validation loss: 0.000\n",
      "[563] Training loss: 0.000\t Validation loss: 0.000\n",
      "[564] Training loss: 0.000\t Validation loss: 0.000\n",
      "[565] Training loss: 0.000\t Validation loss: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[566] Training loss: 0.000\t Validation loss: 0.000\n",
      "[567] Training loss: 0.000\t Validation loss: 0.000\n",
      "[568] Training loss: 0.000\t Validation loss: 0.000\n",
      "[569] Training loss: 0.000\t Validation loss: 0.000\n",
      "[570] Training loss: 0.000\t Validation loss: 0.000\n",
      "[571] Training loss: 0.000\t Validation loss: 0.000\n",
      "[572] Training loss: 0.000\t Validation loss: 0.000\n",
      "[573] Training loss: 0.000\t Validation loss: 0.000\n",
      "[574] Training loss: 0.000\t Validation loss: 0.000\n",
      "[575] Training loss: 0.000\t Validation loss: 0.000\n",
      "[576] Training loss: 0.000\t Validation loss: 0.000\n",
      "[577] Training loss: 0.000\t Validation loss: 0.000\n",
      "[578] Training loss: 0.000\t Validation loss: 0.000\n",
      "[579] Training loss: 0.000\t Validation loss: 0.000\n",
      "[580] Training loss: 0.000\t Validation loss: 0.000\n",
      "[581] Training loss: 0.000\t Validation loss: 0.000\n",
      "[582] Training loss: 0.000\t Validation loss: 0.000\n",
      "[583] Training loss: 0.000\t Validation loss: 0.000\n",
      "[584] Training loss: 0.000\t Validation loss: 0.000\n",
      "[585] Training loss: 0.000\t Validation loss: 0.000\n",
      "[586] Training loss: 0.000\t Validation loss: 0.000\n",
      "[587] Training loss: 0.000\t Validation loss: 0.000\n",
      "[588] Training loss: 0.000\t Validation loss: 0.000\n",
      "[589] Training loss: 0.000\t Validation loss: 0.000\n",
      "[590] Training loss: 0.000\t Validation loss: 0.000\n",
      "[591] Training loss: 0.000\t Validation loss: 0.000\n",
      "[592] Training loss: 0.000\t Validation loss: 0.000\n",
      "[593] Training loss: 0.000\t Validation loss: 0.000\n",
      "[594] Training loss: 0.000\t Validation loss: 0.000\n",
      "[595] Training loss: 0.000\t Validation loss: 0.000\n",
      "[596] Training loss: 0.000\t Validation loss: 0.000\n",
      "[597] Training loss: 0.000\t Validation loss: 0.000\n",
      "[598] Training loss: 0.000\t Validation loss: 0.000\n",
      "[599] Training loss: 0.000\t Validation loss: 0.000\n",
      "[600] Training loss: 0.000\t Validation loss: 0.000\n",
      "[601] Training loss: 0.000\t Validation loss: 0.000\n",
      "[602] Training loss: 0.000\t Validation loss: 0.000\n",
      "[603] Training loss: 0.000\t Validation loss: 0.000\n",
      "[604] Training loss: 0.000\t Validation loss: 0.000\n",
      "[605] Training loss: 0.000\t Validation loss: 0.000\n",
      "[606] Training loss: 0.000\t Validation loss: 0.000\n",
      "[607] Training loss: 0.000\t Validation loss: 0.000\n",
      "[608] Training loss: 0.000\t Validation loss: 0.000\n",
      "[609] Training loss: 0.000\t Validation loss: 0.000\n",
      "[610] Training loss: 0.000\t Validation loss: 0.000\n",
      "[611] Training loss: 0.000\t Validation loss: 0.000\n",
      "[612] Training loss: 0.000\t Validation loss: 0.000\n",
      "[613] Training loss: 0.000\t Validation loss: 0.000\n",
      "[614] Training loss: 0.000\t Validation loss: 0.000\n",
      "[615] Training loss: 0.000\t Validation loss: 0.000\n",
      "[616] Training loss: 0.000\t Validation loss: 0.000\n",
      "[617] Training loss: 0.000\t Validation loss: 0.000\n",
      "[618] Training loss: 0.000\t Validation loss: 0.000\n",
      "[619] Training loss: 0.000\t Validation loss: 0.000\n",
      "[620] Training loss: 0.000\t Validation loss: 0.000\n",
      "[621] Training loss: 0.000\t Validation loss: 0.000\n",
      "[622] Training loss: 0.000\t Validation loss: 0.000\n",
      "[623] Training loss: 0.000\t Validation loss: 0.000\n",
      "[624] Training loss: 0.000\t Validation loss: 0.000\n",
      "[625] Training loss: 0.000\t Validation loss: 0.000\n",
      "[626] Training loss: 0.000\t Validation loss: 0.000\n",
      "[627] Training loss: 0.000\t Validation loss: 0.000\n",
      "[628] Training loss: 0.000\t Validation loss: 0.000\n",
      "[629] Training loss: 0.000\t Validation loss: 0.000\n",
      "[630] Training loss: 0.000\t Validation loss: 0.000\n",
      "[631] Training loss: 0.000\t Validation loss: 0.000\n",
      "[632] Training loss: 0.000\t Validation loss: 0.000\n",
      "[633] Training loss: 0.000\t Validation loss: 0.000\n",
      "[634] Training loss: 0.000\t Validation loss: 0.000\n",
      "[635] Training loss: 0.000\t Validation loss: 0.000\n",
      "[636] Training loss: 0.000\t Validation loss: 0.000\n",
      "[637] Training loss: 0.000\t Validation loss: 0.000\n",
      "[638] Training loss: 0.000\t Validation loss: 0.000\n",
      "[639] Training loss: 0.000\t Validation loss: 0.000\n",
      "[640] Training loss: 0.000\t Validation loss: 0.000\n",
      "[641] Training loss: 0.000\t Validation loss: 0.000\n",
      "[642] Training loss: 0.000\t Validation loss: 0.000\n",
      "[643] Training loss: 0.000\t Validation loss: 0.000\n",
      "[644] Training loss: 0.000\t Validation loss: 0.000\n",
      "[645] Training loss: 0.000\t Validation loss: 0.000\n",
      "[646] Training loss: 0.000\t Validation loss: 0.000\n",
      "[647] Training loss: 0.000\t Validation loss: 0.000\n",
      "[648] Training loss: 0.000\t Validation loss: 0.000\n",
      "[649] Training loss: 0.000\t Validation loss: 0.000\n",
      "[650] Training loss: 0.000\t Validation loss: 0.000\n",
      "[651] Training loss: 0.000\t Validation loss: 0.000\n",
      "[652] Training loss: 0.000\t Validation loss: 0.000\n",
      "[653] Training loss: 0.000\t Validation loss: 0.000\n",
      "[654] Training loss: 0.000\t Validation loss: 0.000\n",
      "[655] Training loss: 0.000\t Validation loss: 0.000\n",
      "[656] Training loss: 0.000\t Validation loss: 0.000\n",
      "[657] Training loss: 0.000\t Validation loss: 0.000\n",
      "[658] Training loss: 0.000\t Validation loss: 0.000\n",
      "[659] Training loss: 0.000\t Validation loss: 0.000\n",
      "[660] Training loss: 0.000\t Validation loss: 0.000\n",
      "[661] Training loss: 0.000\t Validation loss: 0.000\n",
      "[662] Training loss: 0.000\t Validation loss: 0.000\n",
      "[663] Training loss: 0.000\t Validation loss: 0.000\n",
      "[664] Training loss: 0.000\t Validation loss: 0.000\n",
      "[665] Training loss: 0.000\t Validation loss: 0.000\n",
      "[666] Training loss: 0.000\t Validation loss: 0.000\n",
      "[667] Training loss: 0.000\t Validation loss: 0.000\n",
      "[668] Training loss: 0.000\t Validation loss: 0.000\n",
      "[669] Training loss: 0.000\t Validation loss: 0.000\n",
      "[670] Training loss: 0.000\t Validation loss: 0.000\n",
      "[671] Training loss: 0.000\t Validation loss: 0.000\n",
      "[672] Training loss: 0.000\t Validation loss: 0.000\n",
      "[673] Training loss: 0.000\t Validation loss: 0.000\n",
      "[674] Training loss: 0.000\t Validation loss: 0.000\n",
      "[675] Training loss: 0.000\t Validation loss: 0.000\n",
      "[676] Training loss: 0.000\t Validation loss: 0.000\n",
      "[677] Training loss: 0.000\t Validation loss: 0.000\n",
      "[678] Training loss: 0.000\t Validation loss: 0.000\n",
      "[679] Training loss: 0.000\t Validation loss: 0.000\n",
      "[680] Training loss: 0.000\t Validation loss: 0.000\n",
      "[681] Training loss: 0.000\t Validation loss: 0.000\n",
      "[682] Training loss: 0.000\t Validation loss: 0.000\n",
      "[683] Training loss: 0.000\t Validation loss: 0.000\n",
      "[684] Training loss: 0.000\t Validation loss: 0.000\n",
      "[685] Training loss: 0.000\t Validation loss: 0.000\n",
      "[686] Training loss: 0.000\t Validation loss: 0.000\n",
      "[687] Training loss: 0.000\t Validation loss: 0.000\n",
      "[688] Training loss: 0.000\t Validation loss: 0.000\n",
      "[689] Training loss: 0.000\t Validation loss: 0.000\n",
      "[690] Training loss: 0.000\t Validation loss: 0.000\n",
      "[691] Training loss: 0.000\t Validation loss: 0.000\n",
      "[692] Training loss: 0.000\t Validation loss: 0.000\n",
      "[693] Training loss: 0.000\t Validation loss: 0.000\n",
      "[694] Training loss: 0.000\t Validation loss: 0.000\n",
      "[695] Training loss: 0.000\t Validation loss: 0.000\n",
      "[696] Training loss: 0.000\t Validation loss: 0.000\n",
      "[697] Training loss: 0.000\t Validation loss: 0.000\n",
      "[698] Training loss: 0.000\t Validation loss: 0.000\n",
      "[699] Training loss: 0.000\t Validation loss: 0.000\n",
      "[700] Training loss: 0.000\t Validation loss: 0.000\n",
      "[701] Training loss: 0.000\t Validation loss: 0.000\n",
      "[702] Training loss: 0.000\t Validation loss: 0.000\n",
      "[703] Training loss: 0.000\t Validation loss: 0.000\n",
      "[704] Training loss: 0.000\t Validation loss: 0.000\n",
      "[705] Training loss: 0.000\t Validation loss: 0.000\n",
      "[706] Training loss: 0.000\t Validation loss: 0.000\n",
      "[707] Training loss: 0.000\t Validation loss: 0.000\n",
      "[708] Training loss: 0.000\t Validation loss: 0.000\n",
      "[709] Training loss: 0.000\t Validation loss: 0.000\n",
      "[710] Training loss: 0.000\t Validation loss: 0.000\n",
      "[711] Training loss: 0.000\t Validation loss: 0.000\n",
      "[712] Training loss: 0.000\t Validation loss: 0.000\n",
      "[713] Training loss: 0.000\t Validation loss: 0.000\n",
      "[714] Training loss: 0.000\t Validation loss: 0.000\n",
      "[715] Training loss: 0.000\t Validation loss: 0.000\n",
      "[716] Training loss: 0.000\t Validation loss: 0.000\n",
      "[717] Training loss: 0.000\t Validation loss: 0.000\n",
      "[718] Training loss: 0.000\t Validation loss: 0.000\n",
      "[719] Training loss: 0.000\t Validation loss: 0.000\n",
      "[720] Training loss: 0.000\t Validation loss: 0.000\n",
      "[721] Training loss: 0.000\t Validation loss: 0.000\n",
      "[722] Training loss: 0.000\t Validation loss: 0.000\n",
      "[723] Training loss: 0.000\t Validation loss: 0.000\n",
      "[724] Training loss: 0.000\t Validation loss: 0.000\n",
      "[725] Training loss: 0.000\t Validation loss: 0.000\n",
      "[726] Training loss: 0.000\t Validation loss: 0.000\n",
      "[727] Training loss: 0.000\t Validation loss: 0.000\n",
      "[728] Training loss: 0.000\t Validation loss: 0.000\n",
      "[729] Training loss: 0.000\t Validation loss: 0.000\n",
      "[730] Training loss: 0.000\t Validation loss: 0.000\n",
      "[731] Training loss: 0.000\t Validation loss: 0.000\n",
      "[732] Training loss: 0.000\t Validation loss: 0.000\n",
      "[733] Training loss: 0.000\t Validation loss: 0.000\n",
      "[734] Training loss: 0.000\t Validation loss: 0.000\n",
      "[735] Training loss: 0.000\t Validation loss: 0.000\n",
      "[736] Training loss: 0.000\t Validation loss: 0.000\n",
      "[737] Training loss: 0.000\t Validation loss: 0.000\n",
      "[738] Training loss: 0.000\t Validation loss: 0.000\n",
      "[739] Training loss: 0.000\t Validation loss: 0.000\n",
      "[740] Training loss: 0.000\t Validation loss: 0.000\n",
      "[741] Training loss: 0.000\t Validation loss: 0.000\n",
      "[742] Training loss: 0.000\t Validation loss: 0.000\n",
      "[743] Training loss: 0.000\t Validation loss: 0.000\n",
      "[744] Training loss: 0.000\t Validation loss: 0.000\n",
      "[745] Training loss: 0.000\t Validation loss: 0.000\n",
      "[746] Training loss: 0.000\t Validation loss: 0.000\n",
      "[747] Training loss: 0.000\t Validation loss: 0.000\n",
      "[748] Training loss: 0.000\t Validation loss: 0.000\n",
      "[749] Training loss: 0.000\t Validation loss: 0.000\n",
      "[750] Training loss: 0.000\t Validation loss: 0.000\n",
      "[751] Training loss: 0.000\t Validation loss: 0.000\n",
      "[752] Training loss: 0.000\t Validation loss: 0.000\n",
      "[753] Training loss: 0.000\t Validation loss: 0.000\n",
      "[754] Training loss: 0.000\t Validation loss: 0.000\n",
      "[755] Training loss: 0.000\t Validation loss: 0.000\n",
      "[756] Training loss: 0.000\t Validation loss: 0.000\n",
      "[757] Training loss: 0.000\t Validation loss: 0.000\n",
      "[758] Training loss: 0.000\t Validation loss: 0.000\n",
      "[759] Training loss: 0.000\t Validation loss: 0.000\n",
      "[760] Training loss: 0.000\t Validation loss: 0.000\n",
      "[761] Training loss: 0.000\t Validation loss: 0.000\n",
      "[762] Training loss: 0.000\t Validation loss: 0.000\n",
      "[763] Training loss: 0.000\t Validation loss: 0.000\n",
      "[764] Training loss: 0.000\t Validation loss: 0.000\n",
      "[765] Training loss: 0.000\t Validation loss: 0.000\n",
      "[766] Training loss: 0.000\t Validation loss: 0.000\n",
      "[767] Training loss: 0.000\t Validation loss: 0.000\n",
      "[768] Training loss: 0.000\t Validation loss: 0.000\n",
      "[769] Training loss: 0.000\t Validation loss: 0.000\n",
      "[770] Training loss: 0.000\t Validation loss: 0.000\n",
      "[771] Training loss: 0.000\t Validation loss: 0.000\n",
      "[772] Training loss: 0.000\t Validation loss: 0.000\n",
      "[773] Training loss: 0.000\t Validation loss: 0.000\n",
      "[774] Training loss: 0.000\t Validation loss: 0.000\n",
      "[775] Training loss: 0.000\t Validation loss: 0.000\n",
      "[776] Training loss: 0.000\t Validation loss: 0.000\n",
      "[777] Training loss: 0.000\t Validation loss: 0.000\n",
      "[778] Training loss: 0.000\t Validation loss: 0.000\n",
      "[779] Training loss: 0.000\t Validation loss: 0.000\n",
      "[780] Training loss: 0.000\t Validation loss: 0.000\n",
      "[781] Training loss: 0.000\t Validation loss: 0.000\n",
      "[782] Training loss: 0.000\t Validation loss: 0.000\n",
      "[783] Training loss: 0.000\t Validation loss: 0.000\n",
      "[784] Training loss: 0.000\t Validation loss: 0.000\n",
      "[785] Training loss: 0.000\t Validation loss: 0.000\n",
      "[786] Training loss: 0.000\t Validation loss: 0.000\n",
      "[787] Training loss: 0.000\t Validation loss: 0.000\n",
      "[788] Training loss: 0.000\t Validation loss: 0.000\n",
      "[789] Training loss: 0.000\t Validation loss: 0.000\n",
      "[790] Training loss: 0.000\t Validation loss: 0.000\n",
      "[791] Training loss: 0.000\t Validation loss: 0.000\n",
      "[792] Training loss: 0.000\t Validation loss: 0.000\n",
      "[793] Training loss: 0.000\t Validation loss: 0.000\n",
      "[794] Training loss: 0.000\t Validation loss: 0.000\n",
      "[795] Training loss: 0.000\t Validation loss: 0.000\n",
      "[796] Training loss: 0.000\t Validation loss: 0.000\n",
      "[797] Training loss: 0.000\t Validation loss: 0.000\n",
      "[798] Training loss: 0.000\t Validation loss: 0.000\n",
      "[799] Training loss: 0.000\t Validation loss: 0.000\n",
      "[800] Training loss: 0.000\t Validation loss: 0.000\n",
      "[801] Training loss: 0.000\t Validation loss: 0.000\n",
      "[802] Training loss: 0.000\t Validation loss: 0.000\n",
      "[803] Training loss: 0.000\t Validation loss: 0.000\n",
      "[804] Training loss: 0.000\t Validation loss: 0.000\n",
      "[805] Training loss: 0.000\t Validation loss: 0.000\n",
      "[806] Training loss: 0.000\t Validation loss: 0.000\n",
      "[807] Training loss: 0.000\t Validation loss: 0.000\n",
      "[808] Training loss: 0.000\t Validation loss: 0.000\n",
      "[809] Training loss: 0.000\t Validation loss: 0.000\n",
      "[810] Training loss: 0.000\t Validation loss: 0.000\n",
      "[811] Training loss: 0.000\t Validation loss: 0.000\n",
      "[812] Training loss: 0.000\t Validation loss: 0.000\n",
      "[813] Training loss: 0.000\t Validation loss: 0.000\n",
      "[814] Training loss: 0.000\t Validation loss: 0.000\n",
      "[815] Training loss: 0.000\t Validation loss: 0.000\n",
      "[816] Training loss: 0.000\t Validation loss: 0.000\n",
      "[817] Training loss: 0.000\t Validation loss: 0.000\n",
      "[818] Training loss: 0.000\t Validation loss: 0.000\n",
      "[819] Training loss: 0.000\t Validation loss: 0.000\n",
      "[820] Training loss: 0.000\t Validation loss: 0.000\n",
      "[821] Training loss: 0.000\t Validation loss: 0.000\n",
      "[822] Training loss: 0.000\t Validation loss: 0.000\n",
      "[823] Training loss: 0.000\t Validation loss: 0.000\n",
      "[824] Training loss: 0.000\t Validation loss: 0.000\n",
      "[825] Training loss: 0.000\t Validation loss: 0.000\n",
      "[826] Training loss: 0.000\t Validation loss: 0.000\n",
      "[827] Training loss: 0.000\t Validation loss: 0.000\n",
      "[828] Training loss: 0.000\t Validation loss: 0.000\n",
      "[829] Training loss: 0.000\t Validation loss: 0.000\n",
      "[830] Training loss: 0.000\t Validation loss: 0.000\n",
      "[831] Training loss: 0.000\t Validation loss: 0.000\n",
      "[832] Training loss: 0.000\t Validation loss: 0.000\n",
      "[833] Training loss: 0.000\t Validation loss: 0.000\n",
      "[834] Training loss: 0.000\t Validation loss: 0.000\n",
      "[835] Training loss: 0.000\t Validation loss: 0.000\n",
      "[836] Training loss: 0.000\t Validation loss: 0.000\n",
      "[837] Training loss: 0.000\t Validation loss: 0.000\n",
      "[838] Training loss: 0.000\t Validation loss: 0.000\n",
      "[839] Training loss: 0.000\t Validation loss: 0.000\n",
      "[840] Training loss: 0.000\t Validation loss: 0.000\n",
      "[841] Training loss: 0.000\t Validation loss: 0.000\n",
      "[842] Training loss: 0.000\t Validation loss: 0.000\n",
      "[843] Training loss: 0.000\t Validation loss: 0.000\n",
      "[844] Training loss: 0.000\t Validation loss: 0.000\n",
      "[845] Training loss: 0.000\t Validation loss: 0.000\n",
      "[846] Training loss: 0.000\t Validation loss: 0.000\n",
      "[847] Training loss: 0.000\t Validation loss: 0.000\n",
      "[848] Training loss: 0.000\t Validation loss: 0.000\n",
      "[849] Training loss: 0.000\t Validation loss: 0.000\n",
      "[850] Training loss: 0.000\t Validation loss: 0.000\n",
      "[851] Training loss: 0.000\t Validation loss: 0.000\n",
      "[852] Training loss: 0.000\t Validation loss: 0.000\n",
      "[853] Training loss: 0.000\t Validation loss: 0.000\n",
      "[854] Training loss: 0.000\t Validation loss: 0.000\n",
      "[855] Training loss: 0.000\t Validation loss: 0.000\n",
      "[856] Training loss: 0.000\t Validation loss: 0.000\n",
      "[857] Training loss: 0.000\t Validation loss: 0.000\n",
      "[858] Training loss: 0.000\t Validation loss: 0.000\n",
      "[859] Training loss: 0.000\t Validation loss: 0.000\n",
      "[860] Training loss: 0.000\t Validation loss: 0.000\n",
      "[861] Training loss: 0.000\t Validation loss: 0.000\n",
      "[862] Training loss: 0.000\t Validation loss: 0.000\n",
      "[863] Training loss: 0.000\t Validation loss: 0.000\n",
      "[864] Training loss: 0.000\t Validation loss: 0.000\n",
      "[865] Training loss: 0.000\t Validation loss: 0.000\n",
      "[866] Training loss: 0.000\t Validation loss: 0.000\n",
      "[867] Training loss: 0.000\t Validation loss: 0.000\n",
      "[868] Training loss: 0.000\t Validation loss: 0.000\n",
      "[869] Training loss: 0.000\t Validation loss: 0.000\n",
      "[870] Training loss: 0.000\t Validation loss: 0.000\n",
      "[871] Training loss: 0.000\t Validation loss: 0.000\n",
      "[872] Training loss: 0.000\t Validation loss: 0.000\n",
      "[873] Training loss: 0.000\t Validation loss: 0.000\n",
      "[874] Training loss: 0.000\t Validation loss: 0.000\n",
      "[875] Training loss: 0.000\t Validation loss: 0.000\n",
      "[876] Training loss: 0.000\t Validation loss: 0.000\n",
      "[877] Training loss: 0.000\t Validation loss: 0.000\n",
      "[878] Training loss: 0.000\t Validation loss: 0.000\n",
      "[879] Training loss: 0.000\t Validation loss: 0.000\n",
      "[880] Training loss: 0.000\t Validation loss: 0.000\n",
      "[881] Training loss: 0.000\t Validation loss: 0.000\n",
      "[882] Training loss: 0.000\t Validation loss: 0.000\n",
      "[883] Training loss: 0.000\t Validation loss: 0.000\n",
      "[884] Training loss: 0.000\t Validation loss: 0.000\n",
      "[885] Training loss: 0.000\t Validation loss: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[886] Training loss: 0.000\t Validation loss: 0.000\n",
      "[887] Training loss: 0.000\t Validation loss: 0.000\n",
      "[888] Training loss: 0.000\t Validation loss: 0.000\n",
      "[889] Training loss: 0.000\t Validation loss: 0.000\n",
      "[890] Training loss: 0.000\t Validation loss: 0.000\n",
      "[891] Training loss: 0.000\t Validation loss: 0.000\n",
      "[892] Training loss: 0.000\t Validation loss: 0.000\n",
      "[893] Training loss: 0.000\t Validation loss: 0.000\n",
      "[894] Training loss: 0.000\t Validation loss: 0.000\n",
      "[895] Training loss: 0.000\t Validation loss: 0.000\n",
      "[896] Training loss: 0.000\t Validation loss: 0.000\n",
      "[897] Training loss: 0.000\t Validation loss: 0.000\n",
      "[898] Training loss: 0.000\t Validation loss: 0.000\n",
      "[899] Training loss: 0.000\t Validation loss: 0.000\n",
      "[900] Training loss: 0.000\t Validation loss: 0.000\n",
      "[901] Training loss: 0.000\t Validation loss: 0.000\n",
      "[902] Training loss: 0.000\t Validation loss: 0.000\n",
      "[903] Training loss: 0.000\t Validation loss: 0.000\n",
      "[904] Training loss: 0.000\t Validation loss: 0.000\n",
      "[905] Training loss: 0.000\t Validation loss: 0.000\n",
      "[906] Training loss: 0.000\t Validation loss: 0.000\n",
      "[907] Training loss: 0.000\t Validation loss: 0.000\n",
      "[908] Training loss: 0.000\t Validation loss: 0.000\n",
      "[909] Training loss: 0.000\t Validation loss: 0.000\n",
      "[910] Training loss: 0.000\t Validation loss: 0.000\n",
      "[911] Training loss: 0.000\t Validation loss: 0.000\n",
      "[912] Training loss: 0.000\t Validation loss: 0.000\n",
      "[913] Training loss: 0.000\t Validation loss: 0.000\n",
      "[914] Training loss: 0.000\t Validation loss: 0.000\n",
      "[915] Training loss: 0.000\t Validation loss: 0.000\n",
      "[916] Training loss: 0.000\t Validation loss: 0.000\n",
      "[917] Training loss: 0.000\t Validation loss: 0.000\n",
      "[918] Training loss: 0.000\t Validation loss: 0.000\n",
      "[919] Training loss: 0.000\t Validation loss: 0.000\n",
      "[920] Training loss: 0.000\t Validation loss: 0.000\n",
      "[921] Training loss: 0.000\t Validation loss: 0.000\n",
      "[922] Training loss: 0.000\t Validation loss: 0.000\n",
      "[923] Training loss: 0.000\t Validation loss: 0.000\n",
      "[924] Training loss: 0.000\t Validation loss: 0.000\n",
      "[925] Training loss: 0.000\t Validation loss: 0.000\n",
      "[926] Training loss: 0.000\t Validation loss: 0.000\n",
      "[927] Training loss: 0.000\t Validation loss: 0.000\n",
      "[928] Training loss: 0.000\t Validation loss: 0.000\n",
      "[929] Training loss: 0.000\t Validation loss: 0.000\n",
      "[930] Training loss: 0.000\t Validation loss: 0.000\n",
      "[931] Training loss: 0.000\t Validation loss: 0.000\n",
      "[932] Training loss: 0.000\t Validation loss: 0.000\n",
      "[933] Training loss: 0.000\t Validation loss: 0.000\n",
      "[934] Training loss: 0.000\t Validation loss: 0.000\n",
      "[935] Training loss: 0.000\t Validation loss: 0.000\n",
      "[936] Training loss: 0.000\t Validation loss: 0.000\n",
      "[937] Training loss: 0.000\t Validation loss: 0.000\n",
      "[938] Training loss: 0.000\t Validation loss: 0.000\n",
      "[939] Training loss: 0.000\t Validation loss: 0.000\n",
      "[940] Training loss: 0.000\t Validation loss: 0.000\n",
      "[941] Training loss: 0.000\t Validation loss: 0.000\n",
      "[942] Training loss: 0.000\t Validation loss: 0.000\n",
      "[943] Training loss: 0.000\t Validation loss: 0.000\n",
      "[944] Training loss: 0.000\t Validation loss: 0.000\n",
      "[945] Training loss: 0.000\t Validation loss: 0.000\n",
      "[946] Training loss: 0.000\t Validation loss: 0.000\n",
      "[947] Training loss: 0.000\t Validation loss: 0.000\n",
      "[948] Training loss: 0.000\t Validation loss: 0.000\n",
      "[949] Training loss: 0.000\t Validation loss: 0.000\n",
      "[950] Training loss: 0.000\t Validation loss: 0.000\n",
      "[951] Training loss: 0.000\t Validation loss: 0.000\n",
      "[952] Training loss: 0.000\t Validation loss: 0.000\n",
      "[953] Training loss: 0.000\t Validation loss: 0.000\n",
      "[954] Training loss: 0.000\t Validation loss: 0.000\n",
      "[955] Training loss: 0.000\t Validation loss: 0.000\n",
      "[956] Training loss: 0.000\t Validation loss: 0.000\n",
      "[957] Training loss: 0.000\t Validation loss: 0.000\n",
      "[958] Training loss: 0.000\t Validation loss: 0.000\n",
      "[959] Training loss: 0.000\t Validation loss: 0.000\n",
      "[960] Training loss: 0.000\t Validation loss: 0.000\n",
      "[961] Training loss: 0.000\t Validation loss: 0.000\n",
      "[962] Training loss: 0.000\t Validation loss: 0.000\n",
      "[963] Training loss: 0.000\t Validation loss: 0.000\n",
      "[964] Training loss: 0.000\t Validation loss: 0.000\n",
      "[965] Training loss: 0.000\t Validation loss: 0.000\n",
      "[966] Training loss: 0.000\t Validation loss: 0.000\n",
      "[967] Training loss: 0.000\t Validation loss: 0.000\n",
      "[968] Training loss: 0.000\t Validation loss: 0.000\n",
      "[969] Training loss: 0.000\t Validation loss: 0.000\n",
      "[970] Training loss: 0.000\t Validation loss: 0.000\n",
      "[971] Training loss: 0.000\t Validation loss: 0.000\n",
      "[972] Training loss: 0.000\t Validation loss: 0.000\n",
      "[973] Training loss: 0.000\t Validation loss: 0.000\n",
      "[974] Training loss: 0.000\t Validation loss: 0.000\n",
      "[975] Training loss: 0.000\t Validation loss: 0.000\n",
      "[976] Training loss: 0.000\t Validation loss: 0.000\n",
      "[977] Training loss: 0.000\t Validation loss: 0.000\n",
      "[978] Training loss: 0.000\t Validation loss: 0.000\n",
      "[979] Training loss: 0.000\t Validation loss: 0.000\n",
      "[980] Training loss: 0.000\t Validation loss: 0.000\n",
      "[981] Training loss: 0.000\t Validation loss: 0.000\n",
      "[982] Training loss: 0.000\t Validation loss: 0.000\n",
      "[983] Training loss: 0.000\t Validation loss: 0.000\n",
      "[984] Training loss: 0.000\t Validation loss: 0.000\n",
      "[985] Training loss: 0.000\t Validation loss: 0.000\n",
      "[986] Training loss: 0.000\t Validation loss: 0.000\n",
      "[987] Training loss: 0.000\t Validation loss: 0.000\n",
      "[988] Training loss: 0.000\t Validation loss: 0.000\n",
      "[989] Training loss: 0.000\t Validation loss: 0.000\n",
      "[990] Training loss: 0.000\t Validation loss: 0.000\n",
      "[991] Training loss: 0.000\t Validation loss: 0.000\n",
      "[992] Training loss: 0.000\t Validation loss: 0.000\n",
      "[993] Training loss: 0.000\t Validation loss: 0.000\n",
      "[994] Training loss: 0.000\t Validation loss: 0.000\n",
      "[995] Training loss: 0.000\t Validation loss: 0.000\n",
      "[996] Training loss: 0.000\t Validation loss: 0.000\n",
      "[997] Training loss: 0.000\t Validation loss: 0.000\n",
      "[998] Training loss: 0.000\t Validation loss: 0.000\n",
      "[999] Training loss: 0.000\t Validation loss: 0.000\n",
      "[1000] Training loss: 0.000\t Validation loss: 0.000\n",
      "499 Samples\n",
      "\n",
      "GraphConvolution()\n",
      "[1] Training loss: 1.458\t Validation loss: 1.421\n",
      "[2] Training loss: 1.451\t Validation loss: 1.413\n",
      "[3] Training loss: 1.443\t Validation loss: 1.406\n",
      "[4] Training loss: 1.436\t Validation loss: 1.399\n",
      "[5] Training loss: 1.428\t Validation loss: 1.391\n",
      "[6] Training loss: 1.421\t Validation loss: 1.384\n",
      "[7] Training loss: 1.413\t Validation loss: 1.377\n",
      "[8] Training loss: 1.406\t Validation loss: 1.369\n",
      "[9] Training loss: 1.398\t Validation loss: 1.362\n",
      "[10] Training loss: 1.391\t Validation loss: 1.355\n",
      "[11] Training loss: 1.384\t Validation loss: 1.347\n",
      "[12] Training loss: 1.376\t Validation loss: 1.340\n",
      "[13] Training loss: 1.369\t Validation loss: 1.333\n",
      "[14] Training loss: 1.362\t Validation loss: 1.326\n",
      "[15] Training loss: 1.354\t Validation loss: 1.319\n",
      "[16] Training loss: 1.347\t Validation loss: 1.312\n",
      "[17] Training loss: 1.340\t Validation loss: 1.305\n",
      "[18] Training loss: 1.333\t Validation loss: 1.298\n",
      "[19] Training loss: 1.325\t Validation loss: 1.291\n",
      "[20] Training loss: 1.318\t Validation loss: 1.284\n",
      "[21] Training loss: 1.311\t Validation loss: 1.277\n",
      "[22] Training loss: 1.304\t Validation loss: 1.270\n",
      "[23] Training loss: 1.297\t Validation loss: 1.263\n",
      "[24] Training loss: 1.290\t Validation loss: 1.256\n",
      "[25] Training loss: 1.283\t Validation loss: 1.249\n",
      "[26] Training loss: 1.276\t Validation loss: 1.242\n",
      "[27] Training loss: 1.269\t Validation loss: 1.235\n",
      "[28] Training loss: 1.262\t Validation loss: 1.228\n",
      "[29] Training loss: 1.255\t Validation loss: 1.222\n",
      "[30] Training loss: 1.248\t Validation loss: 1.215\n",
      "[31] Training loss: 1.241\t Validation loss: 1.208\n",
      "[32] Training loss: 1.234\t Validation loss: 1.202\n",
      "[33] Training loss: 1.228\t Validation loss: 1.195\n",
      "[34] Training loss: 1.221\t Validation loss: 1.188\n",
      "[35] Training loss: 1.214\t Validation loss: 1.182\n",
      "[36] Training loss: 1.207\t Validation loss: 1.175\n",
      "[37] Training loss: 1.201\t Validation loss: 1.169\n",
      "[38] Training loss: 1.194\t Validation loss: 1.162\n",
      "[39] Training loss: 1.187\t Validation loss: 1.156\n",
      "[40] Training loss: 1.181\t Validation loss: 1.149\n",
      "[41] Training loss: 1.174\t Validation loss: 1.143\n",
      "[42] Training loss: 1.168\t Validation loss: 1.136\n",
      "[43] Training loss: 1.161\t Validation loss: 1.130\n",
      "[44] Training loss: 1.155\t Validation loss: 1.123\n",
      "[45] Training loss: 1.148\t Validation loss: 1.117\n",
      "[46] Training loss: 1.142\t Validation loss: 1.111\n",
      "[47] Training loss: 1.135\t Validation loss: 1.105\n",
      "[48] Training loss: 1.129\t Validation loss: 1.098\n",
      "[49] Training loss: 1.123\t Validation loss: 1.092\n",
      "[50] Training loss: 1.116\t Validation loss: 1.086\n",
      "[51] Training loss: 1.110\t Validation loss: 1.080\n",
      "[52] Training loss: 1.104\t Validation loss: 1.074\n",
      "[53] Training loss: 1.098\t Validation loss: 1.068\n",
      "[54] Training loss: 1.091\t Validation loss: 1.062\n",
      "[55] Training loss: 1.085\t Validation loss: 1.055\n",
      "[56] Training loss: 1.079\t Validation loss: 1.049\n",
      "[57] Training loss: 1.073\t Validation loss: 1.043\n",
      "[58] Training loss: 1.067\t Validation loss: 1.038\n",
      "[59] Training loss: 1.061\t Validation loss: 1.032\n",
      "[60] Training loss: 1.055\t Validation loss: 1.026\n",
      "[61] Training loss: 1.049\t Validation loss: 1.020\n",
      "[62] Training loss: 1.043\t Validation loss: 1.014\n",
      "[63] Training loss: 1.037\t Validation loss: 1.008\n",
      "[64] Training loss: 1.031\t Validation loss: 1.002\n",
      "[65] Training loss: 1.025\t Validation loss: 0.997\n",
      "[66] Training loss: 1.019\t Validation loss: 0.991\n",
      "[67] Training loss: 1.013\t Validation loss: 0.985\n",
      "[68] Training loss: 1.007\t Validation loss: 0.979\n",
      "[69] Training loss: 1.002\t Validation loss: 0.974\n",
      "[70] Training loss: 0.996\t Validation loss: 0.968\n",
      "[71] Training loss: 0.990\t Validation loss: 0.962\n",
      "[72] Training loss: 0.984\t Validation loss: 0.957\n",
      "[73] Training loss: 0.979\t Validation loss: 0.951\n",
      "[74] Training loss: 0.973\t Validation loss: 0.946\n",
      "[75] Training loss: 0.967\t Validation loss: 0.940\n",
      "[76] Training loss: 0.962\t Validation loss: 0.935\n",
      "[77] Training loss: 0.956\t Validation loss: 0.929\n",
      "[78] Training loss: 0.951\t Validation loss: 0.924\n",
      "[79] Training loss: 0.945\t Validation loss: 0.918\n",
      "[80] Training loss: 0.940\t Validation loss: 0.913\n",
      "[81] Training loss: 0.934\t Validation loss: 0.908\n",
      "[82] Training loss: 0.929\t Validation loss: 0.902\n",
      "[83] Training loss: 0.923\t Validation loss: 0.897\n",
      "[84] Training loss: 0.918\t Validation loss: 0.892\n",
      "[85] Training loss: 0.912\t Validation loss: 0.887\n",
      "[86] Training loss: 0.907\t Validation loss: 0.881\n",
      "[87] Training loss: 0.902\t Validation loss: 0.876\n",
      "[88] Training loss: 0.896\t Validation loss: 0.871\n",
      "[89] Training loss: 0.891\t Validation loss: 0.866\n",
      "[90] Training loss: 0.886\t Validation loss: 0.861\n",
      "[91] Training loss: 0.881\t Validation loss: 0.856\n",
      "[92] Training loss: 0.875\t Validation loss: 0.850\n",
      "[93] Training loss: 0.870\t Validation loss: 0.845\n",
      "[94] Training loss: 0.865\t Validation loss: 0.840\n",
      "[95] Training loss: 0.860\t Validation loss: 0.835\n",
      "[96] Training loss: 0.855\t Validation loss: 0.830\n",
      "[97] Training loss: 0.850\t Validation loss: 0.825\n",
      "[98] Training loss: 0.845\t Validation loss: 0.821\n",
      "[99] Training loss: 0.840\t Validation loss: 0.816\n",
      "[100] Training loss: 0.835\t Validation loss: 0.811\n",
      "[101] Training loss: 0.830\t Validation loss: 0.806\n",
      "[102] Training loss: 0.825\t Validation loss: 0.801\n",
      "[103] Training loss: 0.820\t Validation loss: 0.796\n",
      "[104] Training loss: 0.815\t Validation loss: 0.791\n",
      "[105] Training loss: 0.810\t Validation loss: 0.787\n",
      "[106] Training loss: 0.805\t Validation loss: 0.782\n",
      "[107] Training loss: 0.801\t Validation loss: 0.777\n",
      "[108] Training loss: 0.796\t Validation loss: 0.773\n",
      "[109] Training loss: 0.791\t Validation loss: 0.768\n",
      "[110] Training loss: 0.786\t Validation loss: 0.763\n",
      "[111] Training loss: 0.781\t Validation loss: 0.759\n",
      "[112] Training loss: 0.777\t Validation loss: 0.754\n",
      "[113] Training loss: 0.772\t Validation loss: 0.750\n",
      "[114] Training loss: 0.767\t Validation loss: 0.745\n",
      "[115] Training loss: 0.763\t Validation loss: 0.740\n",
      "[116] Training loss: 0.758\t Validation loss: 0.736\n",
      "[117] Training loss: 0.754\t Validation loss: 0.731\n",
      "[118] Training loss: 0.749\t Validation loss: 0.727\n",
      "[119] Training loss: 0.745\t Validation loss: 0.723\n",
      "[120] Training loss: 0.740\t Validation loss: 0.718\n",
      "[121] Training loss: 0.736\t Validation loss: 0.714\n",
      "[122] Training loss: 0.731\t Validation loss: 0.709\n",
      "[123] Training loss: 0.727\t Validation loss: 0.705\n",
      "[124] Training loss: 0.722\t Validation loss: 0.701\n",
      "[125] Training loss: 0.718\t Validation loss: 0.696\n",
      "[126] Training loss: 0.713\t Validation loss: 0.692\n",
      "[127] Training loss: 0.709\t Validation loss: 0.688\n",
      "[128] Training loss: 0.705\t Validation loss: 0.684\n",
      "[129] Training loss: 0.700\t Validation loss: 0.679\n",
      "[130] Training loss: 0.696\t Validation loss: 0.675\n",
      "[131] Training loss: 0.692\t Validation loss: 0.671\n",
      "[132] Training loss: 0.688\t Validation loss: 0.667\n",
      "[133] Training loss: 0.683\t Validation loss: 0.663\n",
      "[134] Training loss: 0.679\t Validation loss: 0.659\n",
      "[135] Training loss: 0.675\t Validation loss: 0.655\n",
      "[136] Training loss: 0.671\t Validation loss: 0.651\n",
      "[137] Training loss: 0.667\t Validation loss: 0.647\n",
      "[138] Training loss: 0.663\t Validation loss: 0.643\n",
      "[139] Training loss: 0.658\t Validation loss: 0.639\n",
      "[140] Training loss: 0.654\t Validation loss: 0.635\n",
      "[141] Training loss: 0.650\t Validation loss: 0.631\n",
      "[142] Training loss: 0.646\t Validation loss: 0.627\n",
      "[143] Training loss: 0.642\t Validation loss: 0.623\n",
      "[144] Training loss: 0.638\t Validation loss: 0.619\n",
      "[145] Training loss: 0.634\t Validation loss: 0.615\n",
      "[146] Training loss: 0.630\t Validation loss: 0.611\n",
      "[147] Training loss: 0.627\t Validation loss: 0.607\n",
      "[148] Training loss: 0.623\t Validation loss: 0.604\n",
      "[149] Training loss: 0.619\t Validation loss: 0.600\n",
      "[150] Training loss: 0.615\t Validation loss: 0.596\n",
      "[151] Training loss: 0.611\t Validation loss: 0.592\n",
      "[152] Training loss: 0.607\t Validation loss: 0.589\n",
      "[153] Training loss: 0.603\t Validation loss: 0.585\n",
      "[154] Training loss: 0.600\t Validation loss: 0.581\n",
      "[155] Training loss: 0.596\t Validation loss: 0.578\n",
      "[156] Training loss: 0.592\t Validation loss: 0.574\n",
      "[157] Training loss: 0.589\t Validation loss: 0.570\n",
      "[158] Training loss: 0.585\t Validation loss: 0.567\n",
      "[159] Training loss: 0.581\t Validation loss: 0.563\n",
      "[160] Training loss: 0.577\t Validation loss: 0.560\n",
      "[161] Training loss: 0.574\t Validation loss: 0.556\n",
      "[162] Training loss: 0.570\t Validation loss: 0.553\n",
      "[163] Training loss: 0.567\t Validation loss: 0.549\n",
      "[164] Training loss: 0.563\t Validation loss: 0.546\n",
      "[165] Training loss: 0.560\t Validation loss: 0.542\n",
      "[166] Training loss: 0.556\t Validation loss: 0.539\n",
      "[167] Training loss: 0.552\t Validation loss: 0.535\n",
      "[168] Training loss: 0.549\t Validation loss: 0.532\n",
      "[169] Training loss: 0.546\t Validation loss: 0.528\n",
      "[170] Training loss: 0.542\t Validation loss: 0.525\n",
      "[171] Training loss: 0.539\t Validation loss: 0.522\n",
      "[172] Training loss: 0.535\t Validation loss: 0.518\n",
      "[173] Training loss: 0.532\t Validation loss: 0.515\n",
      "[174] Training loss: 0.528\t Validation loss: 0.512\n",
      "[175] Training loss: 0.525\t Validation loss: 0.509\n",
      "[176] Training loss: 0.522\t Validation loss: 0.505\n",
      "[177] Training loss: 0.518\t Validation loss: 0.502\n",
      "[178] Training loss: 0.515\t Validation loss: 0.499\n",
      "[179] Training loss: 0.512\t Validation loss: 0.496\n",
      "[180] Training loss: 0.509\t Validation loss: 0.492\n",
      "[181] Training loss: 0.505\t Validation loss: 0.489\n",
      "[182] Training loss: 0.502\t Validation loss: 0.486\n",
      "[183] Training loss: 0.499\t Validation loss: 0.483\n",
      "[184] Training loss: 0.496\t Validation loss: 0.480\n",
      "[185] Training loss: 0.493\t Validation loss: 0.477\n",
      "[186] Training loss: 0.489\t Validation loss: 0.474\n",
      "[187] Training loss: 0.486\t Validation loss: 0.471\n",
      "[188] Training loss: 0.483\t Validation loss: 0.468\n",
      "[189] Training loss: 0.480\t Validation loss: 0.465\n",
      "[190] Training loss: 0.477\t Validation loss: 0.462\n",
      "[191] Training loss: 0.474\t Validation loss: 0.459\n",
      "[192] Training loss: 0.471\t Validation loss: 0.456\n",
      "[193] Training loss: 0.468\t Validation loss: 0.453\n",
      "[194] Training loss: 0.465\t Validation loss: 0.450\n",
      "[195] Training loss: 0.462\t Validation loss: 0.447\n",
      "[196] Training loss: 0.459\t Validation loss: 0.444\n",
      "[197] Training loss: 0.456\t Validation loss: 0.441\n",
      "[198] Training loss: 0.453\t Validation loss: 0.438\n",
      "[199] Training loss: 0.450\t Validation loss: 0.435\n",
      "[200] Training loss: 0.447\t Validation loss: 0.433\n",
      "[201] Training loss: 0.444\t Validation loss: 0.430\n",
      "[202] Training loss: 0.441\t Validation loss: 0.427\n",
      "[203] Training loss: 0.439\t Validation loss: 0.424\n",
      "[204] Training loss: 0.436\t Validation loss: 0.421\n",
      "[205] Training loss: 0.433\t Validation loss: 0.419\n",
      "[206] Training loss: 0.430\t Validation loss: 0.416\n",
      "[207] Training loss: 0.427\t Validation loss: 0.413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208] Training loss: 0.425\t Validation loss: 0.411\n",
      "[209] Training loss: 0.422\t Validation loss: 0.408\n",
      "[210] Training loss: 0.419\t Validation loss: 0.405\n",
      "[211] Training loss: 0.416\t Validation loss: 0.403\n",
      "[212] Training loss: 0.414\t Validation loss: 0.400\n",
      "[213] Training loss: 0.411\t Validation loss: 0.397\n",
      "[214] Training loss: 0.408\t Validation loss: 0.395\n",
      "[215] Training loss: 0.406\t Validation loss: 0.392\n",
      "[216] Training loss: 0.403\t Validation loss: 0.390\n",
      "[217] Training loss: 0.400\t Validation loss: 0.387\n",
      "[218] Training loss: 0.398\t Validation loss: 0.385\n",
      "[219] Training loss: 0.395\t Validation loss: 0.382\n",
      "[220] Training loss: 0.393\t Validation loss: 0.380\n",
      "[221] Training loss: 0.390\t Validation loss: 0.377\n",
      "[222] Training loss: 0.388\t Validation loss: 0.375\n",
      "[223] Training loss: 0.385\t Validation loss: 0.372\n",
      "[224] Training loss: 0.382\t Validation loss: 0.370\n",
      "[225] Training loss: 0.380\t Validation loss: 0.367\n",
      "[226] Training loss: 0.377\t Validation loss: 0.365\n",
      "[227] Training loss: 0.375\t Validation loss: 0.362\n",
      "[228] Training loss: 0.373\t Validation loss: 0.360\n",
      "[229] Training loss: 0.370\t Validation loss: 0.358\n",
      "[230] Training loss: 0.368\t Validation loss: 0.355\n",
      "[231] Training loss: 0.365\t Validation loss: 0.353\n",
      "[232] Training loss: 0.363\t Validation loss: 0.351\n",
      "[233] Training loss: 0.361\t Validation loss: 0.348\n",
      "[234] Training loss: 0.358\t Validation loss: 0.346\n",
      "[235] Training loss: 0.356\t Validation loss: 0.344\n",
      "[236] Training loss: 0.354\t Validation loss: 0.342\n",
      "[237] Training loss: 0.351\t Validation loss: 0.339\n",
      "[238] Training loss: 0.349\t Validation loss: 0.337\n",
      "[239] Training loss: 0.347\t Validation loss: 0.335\n",
      "[240] Training loss: 0.344\t Validation loss: 0.333\n",
      "[241] Training loss: 0.342\t Validation loss: 0.330\n",
      "[242] Training loss: 0.340\t Validation loss: 0.328\n",
      "[243] Training loss: 0.338\t Validation loss: 0.326\n",
      "[244] Training loss: 0.335\t Validation loss: 0.324\n",
      "[245] Training loss: 0.333\t Validation loss: 0.322\n",
      "[246] Training loss: 0.331\t Validation loss: 0.320\n",
      "[247] Training loss: 0.329\t Validation loss: 0.318\n",
      "[248] Training loss: 0.327\t Validation loss: 0.315\n",
      "[249] Training loss: 0.325\t Validation loss: 0.313\n",
      "[250] Training loss: 0.322\t Validation loss: 0.311\n",
      "[251] Training loss: 0.320\t Validation loss: 0.309\n",
      "[252] Training loss: 0.318\t Validation loss: 0.307\n",
      "[253] Training loss: 0.316\t Validation loss: 0.305\n",
      "[254] Training loss: 0.314\t Validation loss: 0.303\n",
      "[255] Training loss: 0.312\t Validation loss: 0.301\n",
      "[256] Training loss: 0.310\t Validation loss: 0.299\n",
      "[257] Training loss: 0.308\t Validation loss: 0.297\n",
      "[258] Training loss: 0.306\t Validation loss: 0.295\n",
      "[259] Training loss: 0.304\t Validation loss: 0.293\n",
      "[260] Training loss: 0.302\t Validation loss: 0.291\n",
      "[261] Training loss: 0.300\t Validation loss: 0.289\n",
      "[262] Training loss: 0.298\t Validation loss: 0.287\n",
      "[263] Training loss: 0.296\t Validation loss: 0.286\n",
      "[264] Training loss: 0.294\t Validation loss: 0.284\n",
      "[265] Training loss: 0.292\t Validation loss: 0.282\n",
      "[266] Training loss: 0.290\t Validation loss: 0.280\n",
      "[267] Training loss: 0.288\t Validation loss: 0.278\n",
      "[268] Training loss: 0.286\t Validation loss: 0.276\n",
      "[269] Training loss: 0.285\t Validation loss: 0.274\n",
      "[270] Training loss: 0.283\t Validation loss: 0.273\n",
      "[271] Training loss: 0.281\t Validation loss: 0.271\n",
      "[272] Training loss: 0.279\t Validation loss: 0.269\n",
      "[273] Training loss: 0.277\t Validation loss: 0.267\n",
      "[274] Training loss: 0.275\t Validation loss: 0.266\n",
      "[275] Training loss: 0.273\t Validation loss: 0.264\n",
      "[276] Training loss: 0.272\t Validation loss: 0.262\n",
      "[277] Training loss: 0.270\t Validation loss: 0.260\n",
      "[278] Training loss: 0.268\t Validation loss: 0.259\n",
      "[279] Training loss: 0.266\t Validation loss: 0.257\n",
      "[280] Training loss: 0.265\t Validation loss: 0.255\n",
      "[281] Training loss: 0.263\t Validation loss: 0.253\n",
      "[282] Training loss: 0.261\t Validation loss: 0.252\n",
      "[283] Training loss: 0.259\t Validation loss: 0.250\n",
      "[284] Training loss: 0.258\t Validation loss: 0.249\n",
      "[285] Training loss: 0.256\t Validation loss: 0.247\n",
      "[286] Training loss: 0.254\t Validation loss: 0.245\n",
      "[287] Training loss: 0.253\t Validation loss: 0.244\n",
      "[288] Training loss: 0.251\t Validation loss: 0.242\n",
      "[289] Training loss: 0.249\t Validation loss: 0.240\n",
      "[290] Training loss: 0.248\t Validation loss: 0.239\n",
      "[291] Training loss: 0.246\t Validation loss: 0.237\n",
      "[292] Training loss: 0.245\t Validation loss: 0.236\n",
      "[293] Training loss: 0.243\t Validation loss: 0.234\n",
      "[294] Training loss: 0.241\t Validation loss: 0.233\n",
      "[295] Training loss: 0.240\t Validation loss: 0.231\n",
      "[296] Training loss: 0.238\t Validation loss: 0.230\n",
      "[297] Training loss: 0.237\t Validation loss: 0.228\n",
      "[298] Training loss: 0.235\t Validation loss: 0.227\n",
      "[299] Training loss: 0.234\t Validation loss: 0.225\n",
      "[300] Training loss: 0.232\t Validation loss: 0.224\n",
      "[301] Training loss: 0.231\t Validation loss: 0.222\n",
      "[302] Training loss: 0.229\t Validation loss: 0.221\n",
      "[303] Training loss: 0.228\t Validation loss: 0.219\n",
      "[304] Training loss: 0.226\t Validation loss: 0.218\n",
      "[305] Training loss: 0.225\t Validation loss: 0.216\n",
      "[306] Training loss: 0.223\t Validation loss: 0.215\n",
      "[307] Training loss: 0.222\t Validation loss: 0.214\n",
      "[308] Training loss: 0.220\t Validation loss: 0.212\n",
      "[309] Training loss: 0.219\t Validation loss: 0.211\n",
      "[310] Training loss: 0.218\t Validation loss: 0.210\n",
      "[311] Training loss: 0.216\t Validation loss: 0.208\n",
      "[312] Training loss: 0.215\t Validation loss: 0.207\n",
      "[313] Training loss: 0.213\t Validation loss: 0.205\n",
      "[314] Training loss: 0.212\t Validation loss: 0.204\n",
      "[315] Training loss: 0.211\t Validation loss: 0.203\n",
      "[316] Training loss: 0.209\t Validation loss: 0.201\n",
      "[317] Training loss: 0.208\t Validation loss: 0.200\n",
      "[318] Training loss: 0.207\t Validation loss: 0.199\n",
      "[319] Training loss: 0.205\t Validation loss: 0.198\n",
      "[320] Training loss: 0.204\t Validation loss: 0.196\n",
      "[321] Training loss: 0.203\t Validation loss: 0.195\n",
      "[322] Training loss: 0.201\t Validation loss: 0.194\n",
      "[323] Training loss: 0.200\t Validation loss: 0.193\n",
      "[324] Training loss: 0.199\t Validation loss: 0.191\n",
      "[325] Training loss: 0.197\t Validation loss: 0.190\n",
      "[326] Training loss: 0.196\t Validation loss: 0.189\n",
      "[327] Training loss: 0.195\t Validation loss: 0.188\n",
      "[328] Training loss: 0.194\t Validation loss: 0.186\n",
      "[329] Training loss: 0.192\t Validation loss: 0.185\n",
      "[330] Training loss: 0.191\t Validation loss: 0.184\n",
      "[331] Training loss: 0.190\t Validation loss: 0.183\n",
      "[332] Training loss: 0.189\t Validation loss: 0.182\n",
      "[333] Training loss: 0.188\t Validation loss: 0.181\n",
      "[334] Training loss: 0.186\t Validation loss: 0.179\n",
      "[335] Training loss: 0.185\t Validation loss: 0.178\n",
      "[336] Training loss: 0.184\t Validation loss: 0.177\n",
      "[337] Training loss: 0.183\t Validation loss: 0.176\n",
      "[338] Training loss: 0.182\t Validation loss: 0.175\n",
      "[339] Training loss: 0.181\t Validation loss: 0.174\n",
      "[340] Training loss: 0.179\t Validation loss: 0.173\n",
      "[341] Training loss: 0.178\t Validation loss: 0.172\n",
      "[342] Training loss: 0.177\t Validation loss: 0.171\n",
      "[343] Training loss: 0.176\t Validation loss: 0.169\n",
      "[344] Training loss: 0.175\t Validation loss: 0.168\n",
      "[345] Training loss: 0.174\t Validation loss: 0.167\n",
      "[346] Training loss: 0.173\t Validation loss: 0.166\n",
      "[347] Training loss: 0.172\t Validation loss: 0.165\n",
      "[348] Training loss: 0.171\t Validation loss: 0.164\n",
      "[349] Training loss: 0.170\t Validation loss: 0.163\n",
      "[350] Training loss: 0.169\t Validation loss: 0.162\n",
      "[351] Training loss: 0.168\t Validation loss: 0.161\n",
      "[352] Training loss: 0.166\t Validation loss: 0.160\n",
      "[353] Training loss: 0.165\t Validation loss: 0.159\n",
      "[354] Training loss: 0.164\t Validation loss: 0.158\n",
      "[355] Training loss: 0.163\t Validation loss: 0.157\n",
      "[356] Training loss: 0.162\t Validation loss: 0.156\n",
      "[357] Training loss: 0.161\t Validation loss: 0.155\n",
      "[358] Training loss: 0.160\t Validation loss: 0.154\n",
      "[359] Training loss: 0.159\t Validation loss: 0.153\n",
      "[360] Training loss: 0.158\t Validation loss: 0.152\n",
      "[361] Training loss: 0.157\t Validation loss: 0.151\n",
      "[362] Training loss: 0.157\t Validation loss: 0.151\n",
      "[363] Training loss: 0.156\t Validation loss: 0.150\n",
      "[364] Training loss: 0.155\t Validation loss: 0.149\n",
      "[365] Training loss: 0.154\t Validation loss: 0.148\n",
      "[366] Training loss: 0.153\t Validation loss: 0.147\n",
      "[367] Training loss: 0.152\t Validation loss: 0.146\n",
      "[368] Training loss: 0.151\t Validation loss: 0.145\n",
      "[369] Training loss: 0.150\t Validation loss: 0.144\n",
      "[370] Training loss: 0.149\t Validation loss: 0.143\n",
      "[371] Training loss: 0.148\t Validation loss: 0.142\n",
      "[372] Training loss: 0.147\t Validation loss: 0.142\n",
      "[373] Training loss: 0.146\t Validation loss: 0.141\n",
      "[374] Training loss: 0.146\t Validation loss: 0.140\n",
      "[375] Training loss: 0.145\t Validation loss: 0.139\n",
      "[376] Training loss: 0.144\t Validation loss: 0.138\n",
      "[377] Training loss: 0.143\t Validation loss: 0.137\n",
      "[378] Training loss: 0.142\t Validation loss: 0.137\n",
      "[379] Training loss: 0.141\t Validation loss: 0.136\n",
      "[380] Training loss: 0.140\t Validation loss: 0.135\n",
      "[381] Training loss: 0.140\t Validation loss: 0.134\n",
      "[382] Training loss: 0.139\t Validation loss: 0.133\n",
      "[383] Training loss: 0.138\t Validation loss: 0.133\n",
      "[384] Training loss: 0.137\t Validation loss: 0.132\n",
      "[385] Training loss: 0.136\t Validation loss: 0.131\n",
      "[386] Training loss: 0.136\t Validation loss: 0.130\n",
      "[387] Training loss: 0.135\t Validation loss: 0.129\n",
      "[388] Training loss: 0.134\t Validation loss: 0.129\n",
      "[389] Training loss: 0.133\t Validation loss: 0.128\n",
      "[390] Training loss: 0.132\t Validation loss: 0.127\n",
      "[391] Training loss: 0.132\t Validation loss: 0.127\n",
      "[392] Training loss: 0.131\t Validation loss: 0.126\n",
      "[393] Training loss: 0.130\t Validation loss: 0.125\n",
      "[394] Training loss: 0.129\t Validation loss: 0.124\n",
      "[395] Training loss: 0.129\t Validation loss: 0.124\n",
      "[396] Training loss: 0.128\t Validation loss: 0.123\n",
      "[397] Training loss: 0.127\t Validation loss: 0.122\n",
      "[398] Training loss: 0.126\t Validation loss: 0.121\n",
      "[399] Training loss: 0.126\t Validation loss: 0.121\n",
      "[400] Training loss: 0.125\t Validation loss: 0.120\n",
      "[401] Training loss: 0.124\t Validation loss: 0.119\n",
      "[402] Training loss: 0.124\t Validation loss: 0.119\n",
      "[403] Training loss: 0.123\t Validation loss: 0.118\n",
      "[404] Training loss: 0.122\t Validation loss: 0.117\n",
      "[405] Training loss: 0.121\t Validation loss: 0.117\n",
      "[406] Training loss: 0.121\t Validation loss: 0.116\n",
      "[407] Training loss: 0.120\t Validation loss: 0.115\n",
      "[408] Training loss: 0.119\t Validation loss: 0.115\n",
      "[409] Training loss: 0.119\t Validation loss: 0.114\n",
      "[410] Training loss: 0.118\t Validation loss: 0.114\n",
      "[411] Training loss: 0.117\t Validation loss: 0.113\n",
      "[412] Training loss: 0.117\t Validation loss: 0.112\n",
      "[413] Training loss: 0.116\t Validation loss: 0.112\n",
      "[414] Training loss: 0.116\t Validation loss: 0.111\n",
      "[415] Training loss: 0.115\t Validation loss: 0.110\n",
      "[416] Training loss: 0.114\t Validation loss: 0.110\n",
      "[417] Training loss: 0.114\t Validation loss: 0.109\n",
      "[418] Training loss: 0.113\t Validation loss: 0.109\n",
      "[419] Training loss: 0.112\t Validation loss: 0.108\n",
      "[420] Training loss: 0.112\t Validation loss: 0.107\n",
      "[421] Training loss: 0.111\t Validation loss: 0.107\n",
      "[422] Training loss: 0.111\t Validation loss: 0.106\n",
      "[423] Training loss: 0.110\t Validation loss: 0.106\n",
      "[424] Training loss: 0.109\t Validation loss: 0.105\n",
      "[425] Training loss: 0.109\t Validation loss: 0.105\n",
      "[426] Training loss: 0.108\t Validation loss: 0.104\n",
      "[427] Training loss: 0.108\t Validation loss: 0.104\n",
      "[428] Training loss: 0.107\t Validation loss: 0.103\n",
      "[429] Training loss: 0.107\t Validation loss: 0.102\n",
      "[430] Training loss: 0.106\t Validation loss: 0.102\n",
      "[431] Training loss: 0.105\t Validation loss: 0.101\n",
      "[432] Training loss: 0.105\t Validation loss: 0.101\n",
      "[433] Training loss: 0.104\t Validation loss: 0.100\n",
      "[434] Training loss: 0.104\t Validation loss: 0.100\n",
      "[435] Training loss: 0.103\t Validation loss: 0.099\n",
      "[436] Training loss: 0.103\t Validation loss: 0.099\n",
      "[437] Training loss: 0.102\t Validation loss: 0.098\n",
      "[438] Training loss: 0.102\t Validation loss: 0.098\n",
      "[439] Training loss: 0.101\t Validation loss: 0.097\n",
      "[440] Training loss: 0.101\t Validation loss: 0.097\n",
      "[441] Training loss: 0.100\t Validation loss: 0.096\n",
      "[442] Training loss: 0.100\t Validation loss: 0.096\n",
      "[443] Training loss: 0.099\t Validation loss: 0.095\n",
      "[444] Training loss: 0.099\t Validation loss: 0.095\n",
      "[445] Training loss: 0.098\t Validation loss: 0.094\n",
      "[446] Training loss: 0.098\t Validation loss: 0.094\n",
      "[447] Training loss: 0.097\t Validation loss: 0.093\n",
      "[448] Training loss: 0.097\t Validation loss: 0.093\n",
      "[449] Training loss: 0.096\t Validation loss: 0.093\n",
      "[450] Training loss: 0.096\t Validation loss: 0.092\n",
      "[451] Training loss: 0.095\t Validation loss: 0.092\n",
      "[452] Training loss: 0.095\t Validation loss: 0.091\n",
      "[453] Training loss: 0.094\t Validation loss: 0.091\n",
      "[454] Training loss: 0.094\t Validation loss: 0.090\n",
      "[455] Training loss: 0.093\t Validation loss: 0.090\n",
      "[456] Training loss: 0.093\t Validation loss: 0.089\n",
      "[457] Training loss: 0.093\t Validation loss: 0.089\n",
      "[458] Training loss: 0.092\t Validation loss: 0.089\n",
      "[459] Training loss: 0.092\t Validation loss: 0.088\n",
      "[460] Training loss: 0.091\t Validation loss: 0.088\n",
      "[461] Training loss: 0.091\t Validation loss: 0.087\n",
      "[462] Training loss: 0.090\t Validation loss: 0.087\n",
      "[463] Training loss: 0.090\t Validation loss: 0.087\n",
      "[464] Training loss: 0.090\t Validation loss: 0.086\n",
      "[465] Training loss: 0.089\t Validation loss: 0.086\n",
      "[466] Training loss: 0.089\t Validation loss: 0.085\n",
      "[467] Training loss: 0.088\t Validation loss: 0.085\n",
      "[468] Training loss: 0.088\t Validation loss: 0.085\n",
      "[469] Training loss: 0.088\t Validation loss: 0.084\n",
      "[470] Training loss: 0.087\t Validation loss: 0.084\n",
      "[471] Training loss: 0.087\t Validation loss: 0.083\n",
      "[472] Training loss: 0.086\t Validation loss: 0.083\n",
      "[473] Training loss: 0.086\t Validation loss: 0.083\n",
      "[474] Training loss: 0.086\t Validation loss: 0.082\n",
      "[475] Training loss: 0.085\t Validation loss: 0.082\n",
      "[476] Training loss: 0.085\t Validation loss: 0.082\n",
      "[477] Training loss: 0.084\t Validation loss: 0.081\n",
      "[478] Training loss: 0.084\t Validation loss: 0.081\n",
      "[479] Training loss: 0.084\t Validation loss: 0.080\n",
      "[480] Training loss: 0.083\t Validation loss: 0.080\n",
      "[481] Training loss: 0.083\t Validation loss: 0.080\n",
      "[482] Training loss: 0.083\t Validation loss: 0.079\n",
      "[483] Training loss: 0.082\t Validation loss: 0.079\n",
      "[484] Training loss: 0.082\t Validation loss: 0.079\n",
      "[485] Training loss: 0.081\t Validation loss: 0.078\n",
      "[486] Training loss: 0.081\t Validation loss: 0.078\n",
      "[487] Training loss: 0.081\t Validation loss: 0.078\n",
      "[488] Training loss: 0.080\t Validation loss: 0.077\n",
      "[489] Training loss: 0.080\t Validation loss: 0.077\n",
      "[490] Training loss: 0.080\t Validation loss: 0.077\n",
      "[491] Training loss: 0.079\t Validation loss: 0.076\n",
      "[492] Training loss: 0.079\t Validation loss: 0.076\n",
      "[493] Training loss: 0.079\t Validation loss: 0.076\n",
      "[494] Training loss: 0.078\t Validation loss: 0.076\n",
      "[495] Training loss: 0.078\t Validation loss: 0.075\n",
      "[496] Training loss: 0.078\t Validation loss: 0.075\n",
      "[497] Training loss: 0.077\t Validation loss: 0.075\n",
      "[498] Training loss: 0.077\t Validation loss: 0.074\n",
      "[499] Training loss: 0.077\t Validation loss: 0.074\n",
      "[500] Training loss: 0.077\t Validation loss: 0.074\n",
      "[501] Training loss: 0.076\t Validation loss: 0.073\n",
      "[502] Training loss: 0.076\t Validation loss: 0.073\n",
      "[503] Training loss: 0.076\t Validation loss: 0.073\n",
      "[504] Training loss: 0.075\t Validation loss: 0.073\n",
      "[505] Training loss: 0.075\t Validation loss: 0.072\n",
      "[506] Training loss: 0.075\t Validation loss: 0.072\n",
      "[507] Training loss: 0.074\t Validation loss: 0.072\n",
      "[508] Training loss: 0.074\t Validation loss: 0.071\n",
      "[509] Training loss: 0.074\t Validation loss: 0.071\n",
      "[510] Training loss: 0.074\t Validation loss: 0.071\n",
      "[511] Training loss: 0.073\t Validation loss: 0.071\n",
      "[512] Training loss: 0.073\t Validation loss: 0.070\n",
      "[513] Training loss: 0.073\t Validation loss: 0.070\n",
      "[514] Training loss: 0.072\t Validation loss: 0.070\n",
      "[515] Training loss: 0.072\t Validation loss: 0.070\n",
      "[516] Training loss: 0.072\t Validation loss: 0.069\n",
      "[517] Training loss: 0.072\t Validation loss: 0.069\n",
      "[518] Training loss: 0.071\t Validation loss: 0.069\n",
      "[519] Training loss: 0.071\t Validation loss: 0.069\n",
      "[520] Training loss: 0.071\t Validation loss: 0.068\n",
      "[521] Training loss: 0.071\t Validation loss: 0.068\n",
      "[522] Training loss: 0.070\t Validation loss: 0.068\n",
      "[523] Training loss: 0.070\t Validation loss: 0.068\n",
      "[524] Training loss: 0.070\t Validation loss: 0.067\n",
      "[525] Training loss: 0.070\t Validation loss: 0.067\n",
      "[526] Training loss: 0.069\t Validation loss: 0.067\n",
      "[527] Training loss: 0.069\t Validation loss: 0.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[528] Training loss: 0.069\t Validation loss: 0.066\n",
      "[529] Training loss: 0.069\t Validation loss: 0.066\n",
      "[530] Training loss: 0.068\t Validation loss: 0.066\n",
      "[531] Training loss: 0.068\t Validation loss: 0.066\n",
      "[532] Training loss: 0.068\t Validation loss: 0.065\n",
      "[533] Training loss: 0.068\t Validation loss: 0.065\n",
      "[534] Training loss: 0.067\t Validation loss: 0.065\n",
      "[535] Training loss: 0.067\t Validation loss: 0.065\n",
      "[536] Training loss: 0.067\t Validation loss: 0.065\n",
      "[537] Training loss: 0.067\t Validation loss: 0.064\n",
      "[538] Training loss: 0.066\t Validation loss: 0.064\n",
      "[539] Training loss: 0.066\t Validation loss: 0.064\n",
      "[540] Training loss: 0.066\t Validation loss: 0.064\n",
      "[541] Training loss: 0.066\t Validation loss: 0.063\n",
      "[542] Training loss: 0.066\t Validation loss: 0.063\n",
      "[543] Training loss: 0.065\t Validation loss: 0.063\n",
      "[544] Training loss: 0.065\t Validation loss: 0.063\n",
      "[545] Training loss: 0.065\t Validation loss: 0.063\n",
      "[546] Training loss: 0.065\t Validation loss: 0.062\n",
      "[547] Training loss: 0.065\t Validation loss: 0.062\n",
      "[548] Training loss: 0.064\t Validation loss: 0.062\n",
      "[549] Training loss: 0.064\t Validation loss: 0.062\n",
      "[550] Training loss: 0.064\t Validation loss: 0.062\n",
      "[551] Training loss: 0.064\t Validation loss: 0.061\n",
      "[552] Training loss: 0.064\t Validation loss: 0.061\n",
      "[553] Training loss: 0.063\t Validation loss: 0.061\n",
      "[554] Training loss: 0.063\t Validation loss: 0.061\n",
      "[555] Training loss: 0.063\t Validation loss: 0.061\n",
      "[556] Training loss: 0.063\t Validation loss: 0.061\n",
      "[557] Training loss: 0.063\t Validation loss: 0.060\n",
      "[558] Training loss: 0.062\t Validation loss: 0.060\n",
      "[559] Training loss: 0.062\t Validation loss: 0.060\n",
      "[560] Training loss: 0.062\t Validation loss: 0.060\n",
      "[561] Training loss: 0.062\t Validation loss: 0.060\n",
      "[562] Training loss: 0.062\t Validation loss: 0.059\n",
      "[563] Training loss: 0.061\t Validation loss: 0.059\n",
      "[564] Training loss: 0.061\t Validation loss: 0.059\n",
      "[565] Training loss: 0.061\t Validation loss: 0.059\n",
      "[566] Training loss: 0.061\t Validation loss: 0.059\n",
      "[567] Training loss: 0.061\t Validation loss: 0.059\n",
      "[568] Training loss: 0.061\t Validation loss: 0.058\n",
      "[569] Training loss: 0.060\t Validation loss: 0.058\n",
      "[570] Training loss: 0.060\t Validation loss: 0.058\n",
      "[571] Training loss: 0.060\t Validation loss: 0.058\n",
      "[572] Training loss: 0.060\t Validation loss: 0.058\n",
      "[573] Training loss: 0.060\t Validation loss: 0.058\n",
      "[574] Training loss: 0.059\t Validation loss: 0.057\n",
      "[575] Training loss: 0.059\t Validation loss: 0.057\n",
      "[576] Training loss: 0.059\t Validation loss: 0.057\n",
      "[577] Training loss: 0.059\t Validation loss: 0.057\n",
      "[578] Training loss: 0.059\t Validation loss: 0.057\n",
      "[579] Training loss: 0.059\t Validation loss: 0.057\n",
      "[580] Training loss: 0.058\t Validation loss: 0.057\n",
      "[581] Training loss: 0.058\t Validation loss: 0.056\n",
      "[582] Training loss: 0.058\t Validation loss: 0.056\n",
      "[583] Training loss: 0.058\t Validation loss: 0.056\n",
      "[584] Training loss: 0.058\t Validation loss: 0.056\n",
      "[585] Training loss: 0.058\t Validation loss: 0.056\n",
      "[586] Training loss: 0.058\t Validation loss: 0.056\n",
      "[587] Training loss: 0.057\t Validation loss: 0.055\n",
      "[588] Training loss: 0.057\t Validation loss: 0.055\n",
      "[589] Training loss: 0.057\t Validation loss: 0.055\n",
      "[590] Training loss: 0.057\t Validation loss: 0.055\n",
      "[591] Training loss: 0.057\t Validation loss: 0.055\n",
      "[592] Training loss: 0.057\t Validation loss: 0.055\n",
      "[593] Training loss: 0.056\t Validation loss: 0.055\n",
      "[594] Training loss: 0.056\t Validation loss: 0.055\n",
      "[595] Training loss: 0.056\t Validation loss: 0.054\n",
      "[596] Training loss: 0.056\t Validation loss: 0.054\n",
      "[597] Training loss: 0.056\t Validation loss: 0.054\n",
      "[598] Training loss: 0.056\t Validation loss: 0.054\n",
      "[599] Training loss: 0.056\t Validation loss: 0.054\n",
      "[600] Training loss: 0.055\t Validation loss: 0.054\n",
      "[601] Training loss: 0.055\t Validation loss: 0.054\n",
      "[602] Training loss: 0.055\t Validation loss: 0.053\n",
      "[603] Training loss: 0.055\t Validation loss: 0.053\n",
      "[604] Training loss: 0.055\t Validation loss: 0.053\n",
      "[605] Training loss: 0.055\t Validation loss: 0.053\n",
      "[606] Training loss: 0.055\t Validation loss: 0.053\n",
      "[607] Training loss: 0.055\t Validation loss: 0.053\n",
      "[608] Training loss: 0.054\t Validation loss: 0.053\n",
      "[609] Training loss: 0.054\t Validation loss: 0.053\n",
      "[610] Training loss: 0.054\t Validation loss: 0.052\n",
      "[611] Training loss: 0.054\t Validation loss: 0.052\n",
      "[612] Training loss: 0.054\t Validation loss: 0.052\n",
      "[613] Training loss: 0.054\t Validation loss: 0.052\n",
      "[614] Training loss: 0.054\t Validation loss: 0.052\n",
      "[615] Training loss: 0.054\t Validation loss: 0.052\n",
      "[616] Training loss: 0.053\t Validation loss: 0.052\n",
      "[617] Training loss: 0.053\t Validation loss: 0.052\n",
      "[618] Training loss: 0.053\t Validation loss: 0.052\n",
      "[619] Training loss: 0.053\t Validation loss: 0.051\n",
      "[620] Training loss: 0.053\t Validation loss: 0.051\n",
      "[621] Training loss: 0.053\t Validation loss: 0.051\n",
      "[622] Training loss: 0.053\t Validation loss: 0.051\n",
      "[623] Training loss: 0.053\t Validation loss: 0.051\n",
      "[624] Training loss: 0.052\t Validation loss: 0.051\n",
      "[625] Training loss: 0.052\t Validation loss: 0.051\n",
      "[626] Training loss: 0.052\t Validation loss: 0.051\n",
      "[627] Training loss: 0.052\t Validation loss: 0.050\n",
      "[628] Training loss: 0.052\t Validation loss: 0.050\n",
      "[629] Training loss: 0.052\t Validation loss: 0.050\n",
      "[630] Training loss: 0.052\t Validation loss: 0.050\n",
      "[631] Training loss: 0.052\t Validation loss: 0.050\n",
      "[632] Training loss: 0.052\t Validation loss: 0.050\n",
      "[633] Training loss: 0.051\t Validation loss: 0.050\n",
      "[634] Training loss: 0.051\t Validation loss: 0.050\n",
      "[635] Training loss: 0.051\t Validation loss: 0.050\n",
      "[636] Training loss: 0.051\t Validation loss: 0.050\n",
      "[637] Training loss: 0.051\t Validation loss: 0.049\n",
      "[638] Training loss: 0.051\t Validation loss: 0.049\n",
      "[639] Training loss: 0.051\t Validation loss: 0.049\n",
      "[640] Training loss: 0.051\t Validation loss: 0.049\n",
      "[641] Training loss: 0.051\t Validation loss: 0.049\n",
      "[642] Training loss: 0.050\t Validation loss: 0.049\n",
      "[643] Training loss: 0.050\t Validation loss: 0.049\n",
      "[644] Training loss: 0.050\t Validation loss: 0.049\n",
      "[645] Training loss: 0.050\t Validation loss: 0.049\n",
      "[646] Training loss: 0.050\t Validation loss: 0.049\n",
      "[647] Training loss: 0.050\t Validation loss: 0.048\n",
      "[648] Training loss: 0.050\t Validation loss: 0.048\n",
      "[649] Training loss: 0.050\t Validation loss: 0.048\n",
      "[650] Training loss: 0.050\t Validation loss: 0.048\n",
      "[651] Training loss: 0.050\t Validation loss: 0.048\n",
      "[652] Training loss: 0.049\t Validation loss: 0.048\n",
      "[653] Training loss: 0.049\t Validation loss: 0.048\n",
      "[654] Training loss: 0.049\t Validation loss: 0.048\n",
      "[655] Training loss: 0.049\t Validation loss: 0.048\n",
      "[656] Training loss: 0.049\t Validation loss: 0.048\n",
      "[657] Training loss: 0.049\t Validation loss: 0.048\n",
      "[658] Training loss: 0.049\t Validation loss: 0.047\n",
      "[659] Training loss: 0.049\t Validation loss: 0.047\n",
      "[660] Training loss: 0.049\t Validation loss: 0.047\n",
      "[661] Training loss: 0.049\t Validation loss: 0.047\n",
      "[662] Training loss: 0.048\t Validation loss: 0.047\n",
      "[663] Training loss: 0.048\t Validation loss: 0.047\n",
      "[664] Training loss: 0.048\t Validation loss: 0.047\n",
      "[665] Training loss: 0.048\t Validation loss: 0.047\n",
      "[666] Training loss: 0.048\t Validation loss: 0.047\n",
      "[667] Training loss: 0.048\t Validation loss: 0.047\n",
      "[668] Training loss: 0.048\t Validation loss: 0.047\n",
      "[669] Training loss: 0.048\t Validation loss: 0.046\n",
      "[670] Training loss: 0.048\t Validation loss: 0.046\n",
      "[671] Training loss: 0.048\t Validation loss: 0.046\n",
      "[672] Training loss: 0.048\t Validation loss: 0.046\n",
      "[673] Training loss: 0.048\t Validation loss: 0.046\n",
      "[674] Training loss: 0.047\t Validation loss: 0.046\n",
      "[675] Training loss: 0.047\t Validation loss: 0.046\n",
      "[676] Training loss: 0.047\t Validation loss: 0.046\n",
      "[677] Training loss: 0.047\t Validation loss: 0.046\n",
      "[678] Training loss: 0.047\t Validation loss: 0.046\n",
      "[679] Training loss: 0.047\t Validation loss: 0.046\n",
      "[680] Training loss: 0.047\t Validation loss: 0.046\n",
      "[681] Training loss: 0.047\t Validation loss: 0.046\n",
      "[682] Training loss: 0.047\t Validation loss: 0.045\n",
      "[683] Training loss: 0.047\t Validation loss: 0.045\n",
      "[684] Training loss: 0.047\t Validation loss: 0.045\n",
      "[685] Training loss: 0.046\t Validation loss: 0.045\n",
      "[686] Training loss: 0.046\t Validation loss: 0.045\n",
      "[687] Training loss: 0.046\t Validation loss: 0.045\n",
      "[688] Training loss: 0.046\t Validation loss: 0.045\n",
      "[689] Training loss: 0.046\t Validation loss: 0.045\n",
      "[690] Training loss: 0.046\t Validation loss: 0.045\n",
      "[691] Training loss: 0.046\t Validation loss: 0.045\n",
      "[692] Training loss: 0.046\t Validation loss: 0.045\n",
      "[693] Training loss: 0.046\t Validation loss: 0.045\n",
      "[694] Training loss: 0.046\t Validation loss: 0.045\n",
      "[695] Training loss: 0.046\t Validation loss: 0.044\n",
      "[696] Training loss: 0.046\t Validation loss: 0.044\n",
      "[697] Training loss: 0.046\t Validation loss: 0.044\n",
      "[698] Training loss: 0.045\t Validation loss: 0.044\n",
      "[699] Training loss: 0.045\t Validation loss: 0.044\n",
      "[700] Training loss: 0.045\t Validation loss: 0.044\n",
      "[701] Training loss: 0.045\t Validation loss: 0.044\n",
      "[702] Training loss: 0.045\t Validation loss: 0.044\n",
      "[703] Training loss: 0.045\t Validation loss: 0.044\n",
      "[704] Training loss: 0.045\t Validation loss: 0.044\n",
      "[705] Training loss: 0.045\t Validation loss: 0.044\n",
      "[706] Training loss: 0.045\t Validation loss: 0.044\n",
      "[707] Training loss: 0.045\t Validation loss: 0.044\n",
      "[708] Training loss: 0.045\t Validation loss: 0.044\n",
      "[709] Training loss: 0.045\t Validation loss: 0.043\n",
      "[710] Training loss: 0.045\t Validation loss: 0.043\n",
      "[711] Training loss: 0.044\t Validation loss: 0.043\n",
      "[712] Training loss: 0.044\t Validation loss: 0.043\n",
      "[713] Training loss: 0.044\t Validation loss: 0.043\n",
      "[714] Training loss: 0.044\t Validation loss: 0.043\n",
      "[715] Training loss: 0.044\t Validation loss: 0.043\n",
      "[716] Training loss: 0.044\t Validation loss: 0.043\n",
      "[717] Training loss: 0.044\t Validation loss: 0.043\n",
      "[718] Training loss: 0.044\t Validation loss: 0.043\n",
      "[719] Training loss: 0.044\t Validation loss: 0.043\n",
      "[720] Training loss: 0.044\t Validation loss: 0.043\n",
      "[721] Training loss: 0.044\t Validation loss: 0.043\n",
      "[722] Training loss: 0.044\t Validation loss: 0.043\n",
      "[723] Training loss: 0.044\t Validation loss: 0.042\n",
      "[724] Training loss: 0.044\t Validation loss: 0.042\n",
      "[725] Training loss: 0.043\t Validation loss: 0.042\n",
      "[726] Training loss: 0.043\t Validation loss: 0.042\n",
      "[727] Training loss: 0.043\t Validation loss: 0.042\n",
      "[728] Training loss: 0.043\t Validation loss: 0.042\n",
      "[729] Training loss: 0.043\t Validation loss: 0.042\n",
      "[730] Training loss: 0.043\t Validation loss: 0.042\n",
      "[731] Training loss: 0.043\t Validation loss: 0.042\n",
      "[732] Training loss: 0.043\t Validation loss: 0.042\n",
      "[733] Training loss: 0.043\t Validation loss: 0.042\n",
      "[734] Training loss: 0.043\t Validation loss: 0.042\n",
      "[735] Training loss: 0.043\t Validation loss: 0.042\n",
      "[736] Training loss: 0.043\t Validation loss: 0.042\n",
      "[737] Training loss: 0.043\t Validation loss: 0.042\n",
      "[738] Training loss: 0.043\t Validation loss: 0.042\n",
      "[739] Training loss: 0.043\t Validation loss: 0.041\n",
      "[740] Training loss: 0.042\t Validation loss: 0.041\n",
      "[741] Training loss: 0.042\t Validation loss: 0.041\n",
      "[742] Training loss: 0.042\t Validation loss: 0.041\n",
      "[743] Training loss: 0.042\t Validation loss: 0.041\n",
      "[744] Training loss: 0.042\t Validation loss: 0.041\n",
      "[745] Training loss: 0.042\t Validation loss: 0.041\n",
      "[746] Training loss: 0.042\t Validation loss: 0.041\n",
      "[747] Training loss: 0.042\t Validation loss: 0.041\n",
      "[748] Training loss: 0.042\t Validation loss: 0.041\n",
      "[749] Training loss: 0.042\t Validation loss: 0.041\n",
      "[750] Training loss: 0.042\t Validation loss: 0.041\n",
      "[751] Training loss: 0.042\t Validation loss: 0.041\n",
      "[752] Training loss: 0.042\t Validation loss: 0.041\n",
      "[753] Training loss: 0.042\t Validation loss: 0.041\n",
      "[754] Training loss: 0.042\t Validation loss: 0.041\n",
      "[755] Training loss: 0.042\t Validation loss: 0.040\n",
      "[756] Training loss: 0.041\t Validation loss: 0.040\n",
      "[757] Training loss: 0.041\t Validation loss: 0.040\n",
      "[758] Training loss: 0.041\t Validation loss: 0.040\n",
      "[759] Training loss: 0.041\t Validation loss: 0.040\n",
      "[760] Training loss: 0.041\t Validation loss: 0.040\n",
      "[761] Training loss: 0.041\t Validation loss: 0.040\n",
      "[762] Training loss: 0.041\t Validation loss: 0.040\n",
      "[763] Training loss: 0.041\t Validation loss: 0.040\n",
      "[764] Training loss: 0.041\t Validation loss: 0.040\n",
      "[765] Training loss: 0.041\t Validation loss: 0.040\n",
      "[766] Training loss: 0.041\t Validation loss: 0.040\n",
      "[767] Training loss: 0.041\t Validation loss: 0.040\n",
      "[768] Training loss: 0.041\t Validation loss: 0.040\n",
      "[769] Training loss: 0.041\t Validation loss: 0.040\n",
      "[770] Training loss: 0.041\t Validation loss: 0.040\n",
      "[771] Training loss: 0.041\t Validation loss: 0.040\n",
      "[772] Training loss: 0.040\t Validation loss: 0.039\n",
      "[773] Training loss: 0.040\t Validation loss: 0.039\n",
      "[774] Training loss: 0.040\t Validation loss: 0.039\n",
      "[775] Training loss: 0.040\t Validation loss: 0.039\n",
      "[776] Training loss: 0.040\t Validation loss: 0.039\n",
      "[777] Training loss: 0.040\t Validation loss: 0.039\n",
      "[778] Training loss: 0.040\t Validation loss: 0.039\n",
      "[779] Training loss: 0.040\t Validation loss: 0.039\n",
      "[780] Training loss: 0.040\t Validation loss: 0.039\n",
      "[781] Training loss: 0.040\t Validation loss: 0.039\n",
      "[782] Training loss: 0.040\t Validation loss: 0.039\n",
      "[783] Training loss: 0.040\t Validation loss: 0.039\n",
      "[784] Training loss: 0.040\t Validation loss: 0.039\n",
      "[785] Training loss: 0.040\t Validation loss: 0.039\n",
      "[786] Training loss: 0.040\t Validation loss: 0.039\n",
      "[787] Training loss: 0.040\t Validation loss: 0.039\n",
      "[788] Training loss: 0.040\t Validation loss: 0.039\n",
      "[789] Training loss: 0.039\t Validation loss: 0.039\n",
      "[790] Training loss: 0.039\t Validation loss: 0.038\n",
      "[791] Training loss: 0.039\t Validation loss: 0.038\n",
      "[792] Training loss: 0.039\t Validation loss: 0.038\n",
      "[793] Training loss: 0.039\t Validation loss: 0.038\n",
      "[794] Training loss: 0.039\t Validation loss: 0.038\n",
      "[795] Training loss: 0.039\t Validation loss: 0.038\n",
      "[796] Training loss: 0.039\t Validation loss: 0.038\n",
      "[797] Training loss: 0.039\t Validation loss: 0.038\n",
      "[798] Training loss: 0.039\t Validation loss: 0.038\n",
      "[799] Training loss: 0.039\t Validation loss: 0.038\n",
      "[800] Training loss: 0.039\t Validation loss: 0.038\n",
      "[801] Training loss: 0.039\t Validation loss: 0.038\n",
      "[802] Training loss: 0.039\t Validation loss: 0.038\n",
      "[803] Training loss: 0.039\t Validation loss: 0.038\n",
      "[804] Training loss: 0.039\t Validation loss: 0.038\n",
      "[805] Training loss: 0.039\t Validation loss: 0.038\n",
      "[806] Training loss: 0.039\t Validation loss: 0.038\n",
      "[807] Training loss: 0.038\t Validation loss: 0.038\n",
      "[808] Training loss: 0.038\t Validation loss: 0.037\n",
      "[809] Training loss: 0.038\t Validation loss: 0.037\n",
      "[810] Training loss: 0.038\t Validation loss: 0.037\n",
      "[811] Training loss: 0.038\t Validation loss: 0.037\n",
      "[812] Training loss: 0.038\t Validation loss: 0.037\n",
      "[813] Training loss: 0.038\t Validation loss: 0.037\n",
      "[814] Training loss: 0.038\t Validation loss: 0.037\n",
      "[815] Training loss: 0.038\t Validation loss: 0.037\n",
      "[816] Training loss: 0.038\t Validation loss: 0.037\n",
      "[817] Training loss: 0.038\t Validation loss: 0.037\n",
      "[818] Training loss: 0.038\t Validation loss: 0.037\n",
      "[819] Training loss: 0.038\t Validation loss: 0.037\n",
      "[820] Training loss: 0.038\t Validation loss: 0.037\n",
      "[821] Training loss: 0.038\t Validation loss: 0.037\n",
      "[822] Training loss: 0.038\t Validation loss: 0.037\n",
      "[823] Training loss: 0.038\t Validation loss: 0.037\n",
      "[824] Training loss: 0.038\t Validation loss: 0.037\n",
      "[825] Training loss: 0.037\t Validation loss: 0.037\n",
      "[826] Training loss: 0.037\t Validation loss: 0.037\n",
      "[827] Training loss: 0.037\t Validation loss: 0.036\n",
      "[828] Training loss: 0.037\t Validation loss: 0.036\n",
      "[829] Training loss: 0.037\t Validation loss: 0.036\n",
      "[830] Training loss: 0.037\t Validation loss: 0.036\n",
      "[831] Training loss: 0.037\t Validation loss: 0.036\n",
      "[832] Training loss: 0.037\t Validation loss: 0.036\n",
      "[833] Training loss: 0.037\t Validation loss: 0.036\n",
      "[834] Training loss: 0.037\t Validation loss: 0.036\n",
      "[835] Training loss: 0.037\t Validation loss: 0.036\n",
      "[836] Training loss: 0.037\t Validation loss: 0.036\n",
      "[837] Training loss: 0.037\t Validation loss: 0.036\n",
      "[838] Training loss: 0.037\t Validation loss: 0.036\n",
      "[839] Training loss: 0.037\t Validation loss: 0.036\n",
      "[840] Training loss: 0.037\t Validation loss: 0.036\n",
      "[841] Training loss: 0.037\t Validation loss: 0.036\n",
      "[842] Training loss: 0.037\t Validation loss: 0.036\n",
      "[843] Training loss: 0.036\t Validation loss: 0.036\n",
      "[844] Training loss: 0.036\t Validation loss: 0.036\n",
      "[845] Training loss: 0.036\t Validation loss: 0.036\n",
      "[846] Training loss: 0.036\t Validation loss: 0.036\n",
      "[847] Training loss: 0.036\t Validation loss: 0.035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[848] Training loss: 0.036\t Validation loss: 0.035\n",
      "[849] Training loss: 0.036\t Validation loss: 0.035\n",
      "[850] Training loss: 0.036\t Validation loss: 0.035\n",
      "[851] Training loss: 0.036\t Validation loss: 0.035\n",
      "[852] Training loss: 0.036\t Validation loss: 0.035\n",
      "[853] Training loss: 0.036\t Validation loss: 0.035\n",
      "[854] Training loss: 0.036\t Validation loss: 0.035\n",
      "[855] Training loss: 0.036\t Validation loss: 0.035\n",
      "[856] Training loss: 0.036\t Validation loss: 0.035\n",
      "[857] Training loss: 0.036\t Validation loss: 0.035\n",
      "[858] Training loss: 0.036\t Validation loss: 0.035\n",
      "[859] Training loss: 0.036\t Validation loss: 0.035\n",
      "[860] Training loss: 0.036\t Validation loss: 0.035\n",
      "[861] Training loss: 0.036\t Validation loss: 0.035\n",
      "[862] Training loss: 0.036\t Validation loss: 0.035\n",
      "[863] Training loss: 0.035\t Validation loss: 0.035\n",
      "[864] Training loss: 0.035\t Validation loss: 0.035\n",
      "[865] Training loss: 0.035\t Validation loss: 0.035\n",
      "[866] Training loss: 0.035\t Validation loss: 0.035\n",
      "[867] Training loss: 0.035\t Validation loss: 0.034\n",
      "[868] Training loss: 0.035\t Validation loss: 0.034\n",
      "[869] Training loss: 0.035\t Validation loss: 0.034\n",
      "[870] Training loss: 0.035\t Validation loss: 0.034\n",
      "[871] Training loss: 0.035\t Validation loss: 0.034\n",
      "[872] Training loss: 0.035\t Validation loss: 0.034\n",
      "[873] Training loss: 0.035\t Validation loss: 0.034\n",
      "[874] Training loss: 0.035\t Validation loss: 0.034\n",
      "[875] Training loss: 0.035\t Validation loss: 0.034\n",
      "[876] Training loss: 0.035\t Validation loss: 0.034\n",
      "[877] Training loss: 0.035\t Validation loss: 0.034\n",
      "[878] Training loss: 0.035\t Validation loss: 0.034\n",
      "[879] Training loss: 0.035\t Validation loss: 0.034\n",
      "[880] Training loss: 0.035\t Validation loss: 0.034\n",
      "[881] Training loss: 0.035\t Validation loss: 0.034\n",
      "[882] Training loss: 0.034\t Validation loss: 0.034\n",
      "[883] Training loss: 0.034\t Validation loss: 0.034\n",
      "[884] Training loss: 0.034\t Validation loss: 0.034\n",
      "[885] Training loss: 0.034\t Validation loss: 0.034\n",
      "[886] Training loss: 0.034\t Validation loss: 0.034\n",
      "[887] Training loss: 0.034\t Validation loss: 0.033\n",
      "[888] Training loss: 0.034\t Validation loss: 0.033\n",
      "[889] Training loss: 0.034\t Validation loss: 0.033\n",
      "[890] Training loss: 0.034\t Validation loss: 0.033\n",
      "[891] Training loss: 0.034\t Validation loss: 0.033\n",
      "[892] Training loss: 0.034\t Validation loss: 0.033\n",
      "[893] Training loss: 0.034\t Validation loss: 0.033\n",
      "[894] Training loss: 0.034\t Validation loss: 0.033\n",
      "[895] Training loss: 0.034\t Validation loss: 0.033\n",
      "[896] Training loss: 0.034\t Validation loss: 0.033\n",
      "[897] Training loss: 0.034\t Validation loss: 0.033\n",
      "[898] Training loss: 0.034\t Validation loss: 0.033\n",
      "[899] Training loss: 0.034\t Validation loss: 0.033\n",
      "[900] Training loss: 0.034\t Validation loss: 0.033\n",
      "[901] Training loss: 0.034\t Validation loss: 0.033\n",
      "[902] Training loss: 0.034\t Validation loss: 0.033\n",
      "[903] Training loss: 0.033\t Validation loss: 0.033\n",
      "[904] Training loss: 0.033\t Validation loss: 0.033\n",
      "[905] Training loss: 0.033\t Validation loss: 0.033\n",
      "[906] Training loss: 0.033\t Validation loss: 0.033\n",
      "[907] Training loss: 0.033\t Validation loss: 0.033\n",
      "[908] Training loss: 0.033\t Validation loss: 0.032\n",
      "[909] Training loss: 0.033\t Validation loss: 0.032\n",
      "[910] Training loss: 0.033\t Validation loss: 0.032\n",
      "[911] Training loss: 0.033\t Validation loss: 0.032\n",
      "[912] Training loss: 0.033\t Validation loss: 0.032\n",
      "[913] Training loss: 0.033\t Validation loss: 0.032\n",
      "[914] Training loss: 0.033\t Validation loss: 0.032\n",
      "[915] Training loss: 0.033\t Validation loss: 0.032\n",
      "[916] Training loss: 0.033\t Validation loss: 0.032\n",
      "[917] Training loss: 0.033\t Validation loss: 0.032\n",
      "[918] Training loss: 0.033\t Validation loss: 0.032\n",
      "[919] Training loss: 0.033\t Validation loss: 0.032\n",
      "[920] Training loss: 0.033\t Validation loss: 0.032\n",
      "[921] Training loss: 0.033\t Validation loss: 0.032\n",
      "[922] Training loss: 0.033\t Validation loss: 0.032\n",
      "[923] Training loss: 0.032\t Validation loss: 0.032\n",
      "[924] Training loss: 0.032\t Validation loss: 0.032\n",
      "[925] Training loss: 0.032\t Validation loss: 0.032\n",
      "[926] Training loss: 0.032\t Validation loss: 0.032\n",
      "[927] Training loss: 0.032\t Validation loss: 0.032\n",
      "[928] Training loss: 0.032\t Validation loss: 0.032\n",
      "[929] Training loss: 0.032\t Validation loss: 0.032\n",
      "[930] Training loss: 0.032\t Validation loss: 0.031\n",
      "[931] Training loss: 0.032\t Validation loss: 0.031\n",
      "[932] Training loss: 0.032\t Validation loss: 0.031\n",
      "[933] Training loss: 0.032\t Validation loss: 0.031\n",
      "[934] Training loss: 0.032\t Validation loss: 0.031\n",
      "[935] Training loss: 0.032\t Validation loss: 0.031\n",
      "[936] Training loss: 0.032\t Validation loss: 0.031\n",
      "[937] Training loss: 0.032\t Validation loss: 0.031\n",
      "[938] Training loss: 0.032\t Validation loss: 0.031\n",
      "[939] Training loss: 0.032\t Validation loss: 0.031\n",
      "[940] Training loss: 0.032\t Validation loss: 0.031\n",
      "[941] Training loss: 0.032\t Validation loss: 0.031\n",
      "[942] Training loss: 0.032\t Validation loss: 0.031\n",
      "[943] Training loss: 0.032\t Validation loss: 0.031\n",
      "[944] Training loss: 0.031\t Validation loss: 0.031\n",
      "[945] Training loss: 0.031\t Validation loss: 0.031\n",
      "[946] Training loss: 0.031\t Validation loss: 0.031\n",
      "[947] Training loss: 0.031\t Validation loss: 0.031\n",
      "[948] Training loss: 0.031\t Validation loss: 0.031\n",
      "[949] Training loss: 0.031\t Validation loss: 0.031\n",
      "[950] Training loss: 0.031\t Validation loss: 0.031\n",
      "[951] Training loss: 0.031\t Validation loss: 0.030\n",
      "[952] Training loss: 0.031\t Validation loss: 0.030\n",
      "[953] Training loss: 0.031\t Validation loss: 0.030\n",
      "[954] Training loss: 0.031\t Validation loss: 0.030\n",
      "[955] Training loss: 0.031\t Validation loss: 0.030\n",
      "[956] Training loss: 0.031\t Validation loss: 0.030\n",
      "[957] Training loss: 0.031\t Validation loss: 0.030\n",
      "[958] Training loss: 0.031\t Validation loss: 0.030\n",
      "[959] Training loss: 0.031\t Validation loss: 0.030\n",
      "[960] Training loss: 0.031\t Validation loss: 0.030\n",
      "[961] Training loss: 0.031\t Validation loss: 0.030\n",
      "[962] Training loss: 0.031\t Validation loss: 0.030\n",
      "[963] Training loss: 0.031\t Validation loss: 0.030\n",
      "[964] Training loss: 0.031\t Validation loss: 0.030\n",
      "[965] Training loss: 0.031\t Validation loss: 0.030\n",
      "[966] Training loss: 0.030\t Validation loss: 0.030\n",
      "[967] Training loss: 0.030\t Validation loss: 0.030\n",
      "[968] Training loss: 0.030\t Validation loss: 0.030\n",
      "[969] Training loss: 0.030\t Validation loss: 0.030\n",
      "[970] Training loss: 0.030\t Validation loss: 0.030\n",
      "[971] Training loss: 0.030\t Validation loss: 0.030\n",
      "[972] Training loss: 0.030\t Validation loss: 0.030\n",
      "[973] Training loss: 0.030\t Validation loss: 0.029\n",
      "[974] Training loss: 0.030\t Validation loss: 0.029\n",
      "[975] Training loss: 0.030\t Validation loss: 0.029\n",
      "[976] Training loss: 0.030\t Validation loss: 0.029\n",
      "[977] Training loss: 0.030\t Validation loss: 0.029\n",
      "[978] Training loss: 0.030\t Validation loss: 0.029\n",
      "[979] Training loss: 0.030\t Validation loss: 0.029\n",
      "[980] Training loss: 0.030\t Validation loss: 0.029\n",
      "[981] Training loss: 0.030\t Validation loss: 0.029\n",
      "[982] Training loss: 0.030\t Validation loss: 0.029\n",
      "[983] Training loss: 0.030\t Validation loss: 0.029\n",
      "[984] Training loss: 0.030\t Validation loss: 0.029\n",
      "[985] Training loss: 0.030\t Validation loss: 0.029\n",
      "[986] Training loss: 0.030\t Validation loss: 0.029\n",
      "[987] Training loss: 0.029\t Validation loss: 0.029\n",
      "[988] Training loss: 0.029\t Validation loss: 0.029\n",
      "[989] Training loss: 0.029\t Validation loss: 0.029\n",
      "[990] Training loss: 0.029\t Validation loss: 0.029\n",
      "[991] Training loss: 0.029\t Validation loss: 0.029\n",
      "[992] Training loss: 0.029\t Validation loss: 0.029\n",
      "[993] Training loss: 0.029\t Validation loss: 0.029\n",
      "[994] Training loss: 0.029\t Validation loss: 0.029\n",
      "[995] Training loss: 0.029\t Validation loss: 0.029\n",
      "[996] Training loss: 0.029\t Validation loss: 0.028\n",
      "[997] Training loss: 0.029\t Validation loss: 0.028\n",
      "[998] Training loss: 0.029\t Validation loss: 0.028\n",
      "[999] Training loss: 0.029\t Validation loss: 0.028\n",
      "[1000] Training loss: 0.029\t Validation loss: 0.028\n"
     ]
    }
   ],
   "source": [
    "n_nodes = 20\n",
    "histories = {}\n",
    "p = 2./n_nodes\n",
    "\n",
    "for n_samples in np.int0(np.logspace(np.log10(5e2), np.log10(1e4), 4))[::-1]:\n",
    "    print('%d Samples\\n' % n_samples)\n",
    "    histories[n_samples] = {}\n",
    "    X = make_ER_dataset(n_samples, n_nodes, p = p)\n",
    "    Y = X.sum(-1, keepdims=1)\n",
    "    h = np.ones_like(Y)\n",
    "    \n",
    "    net = GraphConvolution(h.shape[-1], 1).to(device)\n",
    "    print(net)\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    optimizer = optim.Adam(net.parameters(), lr=.001)\n",
    "    train_step = make_train_step(net, loss_fn, optimizer)\n",
    "    \n",
    "    train_loader, val_loader = make_loader([X,h], Y, int(n_samples), .2)\n",
    "    training_losses, validation_losses = train_model(net, device, train_step, 1000, train_loader, val_loader)\n",
    "    validation_loss = min(validation_losses)\n",
    "    training_loss = training_losses[np.argmin(validation_loss)]\n",
    "#         histories[n_samples][units] = {\"loss\": training_loss, \"val_loss\" :validation_loss}\n",
    "    histories[n_samples] = {\"loss\": training_losses, \"val_loss\" :validation_losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 386
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val = array([[k, min(histories[k]['val_loss'])] for k in sorted(histories)])\n",
    "\n",
    "plot(*val.T, marker = '.')\n",
    "yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Samples x Epochs')"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 283,
       "width": 406
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in sorted(histories):\n",
    "    for s in ['val_loss']:\n",
    "        y = histories[k][s]\n",
    "        plot(arange(len(y))*k,y, label = '%.1g samples' %k)\n",
    "\n",
    "title('GCN, single weight, learning degree')\n",
    "legend()\n",
    "yscale('log')\n",
    "xscale('log')\n",
    "\n",
    "ylabel('MSE', size = 14)\n",
    "xlim(1e4,1e6)\n",
    "xlabel('Samples x Epochs', size = 14)\n",
    "#     show()\n",
    "\n",
    "# savefig('../figs/expressivity/gcn-1-N%d-var-samples.pdf' %(n_nodes))\n",
    "# savefig('../figs/expressivity/gcn-1-N%d-var-samples.png' %(n_nodes), dpi = 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
